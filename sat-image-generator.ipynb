{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "from rasterio.plot import reshape_as_image\n",
    "\n",
    "import tensorflow as tf\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "from modules.metadata_reader import img_metadata_to_dict, add_names_to_metadata_dict, dict_to_df\n",
    "\n",
    "# Path to location where individual satellite images are located\n",
    "DATA_PATH = 'data/toulon-laspezia' \n",
    "DATA_PATH_IS_RELATIVE = True\n",
    "DATA_PATH_NPY = 'data/toulon-laspezia-npy' \n",
    "\n",
    "# Name of metadata .xml file\n",
    "METADATA_NAME = 'DeliveryMetadata.xml'\n",
    "\n",
    "# Names of areas covered by satellite imagery\n",
    "AREAS = ['La_Spezia', 'Toulon'] # Spelled like the directory names\n",
    "\n",
    "# Speficy what the xmlns url on top of metadata .xml file is\n",
    "# (should be second line)\n",
    "XMLNS = 'http://xsd.digitalglobe.com/xsd/dm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata parsing from xml to pandas dataframe\n",
    "\n",
    "Every satellite image delivery from Maxar contains a `DeliveryMetadata.xml` file with important specifications for both the multispectral and panchromatic images. The following functions finds all the `DeliveryMetadata.xml` files contained in all subdirectories of a directory and parses them into the *Pandas DataFrame* format which will be used for further descriptive statistics of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_metadata_pan, img_metadata_ms = img_metadata_to_dict(METADATA_NAME, \n",
    "                                                         DATA_PATH, XMLNS, \n",
    "                                                         path_is_relative = DATA_PATH_IS_RELATIVE)\n",
    "\n",
    "img_metadata_pan = add_names_to_metadata_dict(img_metadata_pan, AREAS)\n",
    "img_metadata_ms = add_names_to_metadata_dict(img_metadata_ms, AREAS)\n",
    "\n",
    "img_metadata_pan = dict_to_df(img_metadata_pan)\n",
    "img_metadata_ms = dict_to_df(img_metadata_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly draw 2 images for early trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toulon_wv02_pan = img_metadata_pan[(img_metadata_pan['sensorVehicle'] == 'WV02')\n",
    "                                   & (img_metadata_pan['area_name'] == 'Toulon')]\n",
    "\n",
    "np.random.seed(1)\n",
    "img_names = sorted(toulon_wv02_pan.index.values)\n",
    "np.random.shuffle(img_names)\n",
    "images_for_early_trials = img_names[:2]\n",
    "images_for_early_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert .tif files to .npy for easier loading later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tif_to_npy(path_in, filename, save_to_disk = False, path_out = None):\n",
    "    path_in = pathlib.Path(path_in)\n",
    "    #filename = path_in.stem\n",
    "    with rasterio.open(path_in, 'r') as ds:\n",
    "        img = ds.read()\n",
    "    print(type(img))\n",
    "    img = reshape_as_image(img)\n",
    "    print(img.shape)\n",
    "    if save_to_disk:\n",
    "        np.save(pathlib.Path(path_out, filename), img)\n",
    "        return True\n",
    "    return img\n",
    "\n",
    "def all_tif_to_npy(metadata_pan, metadata_ms, path_out):\n",
    "    \n",
    "    # Saving panchromatic images as .npy files\n",
    "    filenames = metadata_pan.index.values.tolist()\n",
    "    path_out_pan = pathlib.Path(path_out, 'pan')\n",
    "    for filename in filenames:\n",
    "        tif_to_npy(metadata_pan.loc[filename]['tif_path'], \n",
    "                   filename, save_to_disk = True,\n",
    "                   path_out = path_out_pan)\n",
    "        print('Saved', filename, 'in dir', str(path_out_pan))\n",
    "    \n",
    "    # Saving multispectral images as .npy files\n",
    "    filenames = metadata_ms.index.values.tolist()\n",
    "    path_out_ms = pathlib.Path(path_out, 'ms')\n",
    "    for filename in filenames:\n",
    "        tif_to_npy(metadata_ms.loc[filename]['tif_path'], \n",
    "                   filename, save_to_disk = True,\n",
    "                   path_out = path_out_ms)\n",
    "        print('Saved', filename, 'in', str(path_out_ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to actually convert (takes some time):\n",
    "\n",
    "#all_tif_to_npy(img_metadata_pan, img_metadata_ms, DATA_PATH_NPY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding paths to .npy files as column in metadata dataframe\n",
    "\n",
    "The metadata dataframes are kept up to date so that it can be used as a canonical source of information about images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_npy_paths_to_metadata_df(metadata_pan, metadata_ms, path_to_npy):\n",
    "    path_pan = pathlib.Path(pathlib.Path.cwd(), path_to_npy, 'pan')\n",
    "    pan_paths = list(path_pan.glob('**/*.npy'))\n",
    "    pan_names = [path.stem for path in pan_paths]\n",
    "    pan_path_df = pd.DataFrame({'pan_names':pan_names,'npy_path':pan_paths}).set_index('pan_names')\n",
    "    metadata_pan = pd.concat([metadata_pan, pan_path_df],axis=1)\n",
    "    \n",
    "    path_ms = pathlib.Path(pathlib.Path.cwd(), path_to_npy, 'ms')\n",
    "    ms_paths = list(path_ms.glob('**/*.npy'))\n",
    "    ms_names = [path.stem for path in ms_paths]\n",
    "    ms_path_df = pd.DataFrame({'ms_names':ms_names,'npy_path':ms_paths}).set_index('ms_names')\n",
    "    metadata_ms = pd.concat([metadata_ms, ms_path_df],axis=1)\n",
    "    \n",
    "    return metadata_pan, metadata_ms\n",
    "\n",
    "img_metadata_pan, img_metadata_ms = add_npy_paths_to_metadata_df(img_metadata_pan, \n",
    "                                                                 img_metadata_ms, \n",
    "                                                                 DATA_PATH_NPY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading .npy files into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy_to_dict(metadata_df, ID_list = None):\n",
    "    if ID_list == None:\n",
    "        ID_list = list(metadata_df.index.tolist())\n",
    "    d = {}\n",
    "    for ID in ID_list:\n",
    "        d[ID] = np.load(metadata_df.loc[ID]['npy_path'])\n",
    "        print(ID, 'loaded into memory as ndarray with shape', d[ID].shape)\n",
    "    return d\n",
    "\n",
    "def load_npy_to_list(metadata_df, ID_list = None):\n",
    "    if ID_list == None:\n",
    "        ID_list = list(metadata_df.index.tolist())\n",
    "    l = []\n",
    "    for ID in ID_list:\n",
    "        l.append(np.load(metadata_df.loc[ID]['npy_path']))\n",
    "        print(ID, 'loaded into memory as ndarray with shape', l[-1].shape)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load only early trials images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_pan = load_npy_to_list(img_metadata_pan, images_for_early_trials)\n",
    "imgs_ms = load_npy_to_list(img_metadata_ms, images_for_early_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all images\n",
    "Keep a watch on available RAM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs_pan = load_npy_to_list(img_metadata_pan)\n",
    "#imgs_ms = load_npy_to_list(img_metadata_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAN_WIDTH, PAN_HEIGHT = (384, 384)\n",
    "PAN_BANDS = 1\n",
    "\n",
    "SR_FACTOR = 4\n",
    "MS_WIDTH, MS_HEIGHT = (int(PAN_WIDTH/SR_FACTOR), int(PAN_HEIGHT/SR_FACTOR))\n",
    "MS_BANDS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def crop(img, yxhwc_box):\n",
    "    img = tf.image.crop_to_bounding_box(\n",
    "        img, \n",
    "        offset_height = yxhwc_box[0], \n",
    "        offset_width = yxhwc_box[1], \n",
    "        target_height = yxhwc_box[2], \n",
    "        target_width = yxhwc_box[3])\n",
    "    return img\n",
    "\n",
    "def get_random_box(img_shape, crop_size):\n",
    "    maxval_y, maxval_x = img_shape[:2]\n",
    "    maxval_y -= crop_size[0]\n",
    "    maxval_x -= crop_size[1]\n",
    "    print(maxval_y, maxval_x)\n",
    "    rng = np.random.default_rng()\n",
    "    upper_left_yx = rng.integers(0, high=[maxval_y, maxval_x], dtype='int32')\n",
    "    \n",
    "    #returning in yxhwc format\n",
    "    return np.concatenate((upper_left_yx, np.array(crop_size)))\n",
    "\n",
    "def get_hr_box(lr_box, resize_factor, channels):\n",
    "    hr_box = lr_box\n",
    "    hr_box[:4] = lr_box[:4] * resize_factor\n",
    "    hr_box[4] = channels\n",
    "    return hr_box\n",
    "\n",
    "def scale_image(img):\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return img\n",
    "\n",
    "def add_imgID(img_array, imgID):\n",
    "    img_array = np.expand_dims(img_array, 0)\n",
    "    img_array[:,]\n",
    "\n",
    "def preprocess_tiles(imgs_pan, imgs_ms, img_IDs, n_tiles):\n",
    "    n_images = len(img_IDs)\n",
    "    arr_ms = np.zeros((n_tiles, MS_HEIGHT, MS_WIDTH, MS_BANDS))\n",
    "    arr_pan = np.zeros((n_tiles, PAN_HEIGHT, PAN_WIDTH, PAN_BANDS))\n",
    "    print(arr_ms.shape)\n",
    "    tile_imgID_map = []\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    \n",
    "    for i in range(n_tiles):\n",
    "        img_ID_int = rng.integers(0, high=n_images, dtype='int32')\n",
    "        img_ID = img_IDs[img_ID_int]\n",
    "        tile_imgID_map.append(img_ID)\n",
    "        print(img_ID)\n",
    "\n",
    "        img_pan = scale_image(imgs_pan[img_ID_int])\n",
    "        img_ms = scale_image(imgs_ms[img_ID_int])\n",
    "        \n",
    "        box_ms = get_random_box(img_ms.shape, [MS_HEIGHT, MS_WIDTH, MS_BANDS])\n",
    "        print(box_ms)\n",
    "        img_ms_cropped = crop(img_ms, box_ms)\n",
    "        box_pan = get_hr_box(box_ms, SR_FACTOR, PAN_BANDS)\n",
    "        img_pan_cropped = crop(img_pan, box_pan)\n",
    "        arr_ms[i,:,:,:] = img_ms_cropped\n",
    "        arr_pan[i,:,:,:] = img_pan_cropped\n",
    "    \n",
    "    return arr_ms, arr_pan, tile_imgID_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_ms, arr_pan, tile_imgID_map = preprocess_tiles(imgs_pan, imgs_ms, images_for_early_trials, 10)\n",
    "\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "    \n",
    "ax0 = fig.add_subplot(1,2,1)\n",
    "ax0.set_title('MS')\n",
    "ax0 = plt.imshow(arr_ms[0,:,:,0], cmap = 'gray')\n",
    "    \n",
    "ax1 = fig.add_subplot(1,2,2)\n",
    "ax1.set_title('PAN')\n",
    "ax1 = plt.imshow(arr_pan[0,:,:,0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_imgID_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    feature = {\n",
    "        #'img_ID': _bytes_feature(img_ID),\n",
    "        'image_pan': _bytes_feature(img_pan_cropped),\n",
    "        'pan_height': _int64_feature(img_pan_cropped.shape[0]),\n",
    "        'pan_width': _int64_feature(img_pan_cropped.shape[1]),\n",
    "        'pan_channels': _int64_feature(img_pan_cropped.shape[2]),\n",
    "        'image_ms': _bytes_feature(img_ms_cropped),\n",
    "        'ms_height': _int64_feature(img_ms_cropped.shape[0]),\n",
    "        'ms_width': _int64_feature(img_ms_cropped.shape[1]),\n",
    "        'ms_channels': _int64_feature(img_ms_cropped.shape[2])\n",
    "    }\n",
    "    \n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
