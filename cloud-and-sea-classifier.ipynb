{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud and sea tile classifier\n",
    "\n",
    "It has been identified that ESRGAN in both pretrain PSNR mode and GAN mode struggles with super-resoluting satellite image tiles completely covered by either sea surface or opaque clouds. In addition, both areas of interest, the harbors of Toulon and La Spezia, has lots of sea surface (approaching 50%). Left without intervention around 50% of tiles will only consist of sea and opaque clouds. It is assumed that this leads to an unwanted imbalance in what we want the model to be optimized to perform on.\n",
    "\n",
    "There are several ways to mitigate this imbalance. One way would be to manually draw a sea surface polygon in a GIS software and undersample tiles extracted from within this polygon. A downside of this approach is that interesting features (ships) within the sea surface polygon would also be undersampled.\n",
    "\n",
    "Another approach would be to train a cloud and sea tile classifier to detect the the unwanted tiles and discard all or a significant proportion of these tiles before training. This approach has the benefit of addressing the problem head on. The main downside of the approach is that it might be time-consuming to label tiles. However it is hypothesized that relatively little training data is needed to train a modern neural net classifier on such a *simple* classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cuda_version': '64_101',\n",
       " 'cudnn_version': '64_7',\n",
       " 'cuda_compute_capabilities': ['sm_35',\n",
       "  'sm_37',\n",
       "  'sm_52',\n",
       "  'sm_60',\n",
       "  'sm_61',\n",
       "  'compute_70'],\n",
       " 'cpu_compiler': 'C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.26.28801/bin/HostX64/x64/cl.exe',\n",
       " 'is_rocm_build': False,\n",
       " 'is_cuda_build': True,\n",
       " 'msvcp_dll_names': 'msvcp140.dll,msvcp140_1.dll',\n",
       " 'nvcuda_dll_name': 'nvcuda.dll',\n",
       " 'cudart_dll_name': 'cudart64_101.dll',\n",
       " 'cudnn_dll_name': 'cudnn64_7.dll'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import datetime\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "import tensorflow as tf\n",
    "\n",
    "from modules.tile_generator import *\n",
    "from modules.helpers import *\n",
    "from modules.image_utils import *\n",
    "from modules.tile_input_pipeline import *\n",
    "from modules.cloudsea_classifier import *\n",
    "\n",
    "# Check GPUs:\",\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            # Prevent TensorFlow from allocating all memory of all GPUs:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "tf.sysconfig.get_build_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "{96: 500, 128: 1000, 196: 500, 384: 500}\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "# Toggles whether to actually do the generation on this run\n",
    "# Be careful with setting these to True if tiles are already labelled!\n",
    "# New tiles will overwrite old tiles and labels are trash\n",
    "GENERATE_NEW_TILES = False\n",
    "CONVERT_TO_PNG = False\n",
    "CREATE_LABEL_CSV = False\n",
    "\n",
    "with open('metadata_df.pickle', 'rb') as file:\n",
    "    meta = pickle.load(file)\n",
    "# Path to location where individual satellite images are located\n",
    "DATA_PATH = 'data/toulon-laspezia/'\n",
    "DATA_PATH_TILES = 'data/toulon-laspezia-cloud-sea-classifier/'\n",
    "\n",
    "SENSORS = ['WV02', 'GE01', 'WV03_VNIR']\n",
    "AREAS = ['La_Spezia', 'Toulon']\n",
    "meta = meta.loc[meta['sensorVehicle'].isin(SENSORS)]\n",
    "meta = meta.loc[meta['area_name'].isin(AREAS)]\n",
    "\n",
    "N_IMAGES = len(meta.index)\n",
    "\n",
    "#96x96, 128x128, 196x196, 384x384 -- All tiles are squares\n",
    "TILE_SIZES = [96, 128, 196, 384]\n",
    "# number of tiles to generate at each tile size\n",
    "N_TILES = {96: 500, 128: 1000, 196: 500, 384: 500}\n",
    "N_TILES_TOTAL = sum(N_TILES.values())\n",
    "\n",
    "print(N_IMAGES)\n",
    "print(N_TILES)\n",
    "print(N_TILES_TOTAL)\n",
    "\n",
    "TRAIN_TILE_SIZE = 224\n",
    "\n",
    "PAN_OR_MS_OR_BOTH = 'pan'\n",
    "if PAN_OR_MS_OR_BOTH == 'pan':\n",
    "    TRAIN_TILE_BANDS = 1\n",
    "elif PAN_OR_MS_OR_BOTH == 'ms':\n",
    "    TRAIN_TILE_BANDS = 4\n",
    "elif PAN_OR_MS_OR_BOTH == 'both':\n",
    "    TRAIN_TILE_BANDS = 5\n",
    "\n",
    "RESIZE_METHOD = 'bilinear'\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "VAL_SPLIT = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allocate n_tiles to every image (weighted by size of image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_NEW_TILES:\n",
    "    meta = allocate_tiles(meta, by_partition=False, n_tiles_total=N_TILES[96], new_column_name='n_tiles_96')\n",
    "    meta = allocate_tiles(meta, by_partition=False, n_tiles_total=N_TILES[128], new_column_name='n_tiles_128')\n",
    "    meta = allocate_tiles(meta, by_partition=False, n_tiles_total=N_TILES[196], new_column_name='n_tiles_196')\n",
    "    meta = allocate_tiles(meta, by_partition=False, n_tiles_total=N_TILES[384], new_column_name='n_tiles_384')\n",
    "    meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate tiles to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_NEW_TILES:\n",
    "    meta['n_tiles'] = 0\n",
    "    for tile_size in TILE_SIZES:\n",
    "        pathlib.Path(DATA_PATH_TILES).joinpath(str(tile_size)).mkdir()\n",
    "        tile_size_ms = int(tile_size/4)\n",
    "        meta['n_tiles'] = meta[str('n_tiles_'+str(tile_size))]\n",
    "        generate_all_tiles(meta, save_dir = str(DATA_PATH_TILES+'/'+str(tile_size)), \n",
    "                           ms_height_width=(tile_size_ms,tile_size_ms), sr_factor=4, \n",
    "                           cloud_sea_removal=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten the directory structure after generation\n",
    "\n",
    "Lots of foor loops in order to do one change at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tiles generated and present in flat file structure: 2500\n"
     ]
    }
   ],
   "source": [
    "if GENERATE_NEW_TILES:\n",
    "    # Remove train/val/test directories\n",
    "    for tilesize_dir in pathlib.Path(DATA_PATH_TILES).iterdir():\n",
    "        for partition_dir in tilesize_dir.iterdir():\n",
    "            for image_dir in partition_dir.iterdir():\n",
    "                dest = tilesize_dir.joinpath(image_dir.stem)\n",
    "                source = image_dir\n",
    "                source.rename(dest)\n",
    "            partition_dir.rmdir()\n",
    "\n",
    "    # Add tile size to filenames\n",
    "    for tilesize_dir in pathlib.Path(DATA_PATH_TILES).iterdir():\n",
    "        for image_dir in tilesize_dir.iterdir():\n",
    "            for ms_pan_dir in image_dir.iterdir():\n",
    "                for tile in ms_pan_dir.iterdir():\n",
    "                    new_tile_name = str(tilesize_dir.stem+'-'+tile.name)\n",
    "                    new_path = ms_pan_dir.joinpath(new_tile_name)\n",
    "                    tile.rename(new_path)\n",
    "\n",
    "    # Completely flatten file structure, remove tile size directories\n",
    "    for tilesize_dir in pathlib.Path(DATA_PATH_TILES).iterdir():\n",
    "        for image_dir in tilesize_dir.iterdir():\n",
    "            for ms_pan_dir in image_dir.iterdir():\n",
    "                for tile in ms_pan_dir.iterdir():\n",
    "                    new_dir = pathlib.Path(DATA_PATH_TILES).joinpath(image_dir.stem, ms_pan_dir.name)\n",
    "                    new_dir.mkdir(parents=True, exist_ok=True)\n",
    "                    new_path = new_dir.joinpath(tile.name)\n",
    "                    tile.rename(new_path)\n",
    "                ms_pan_dir.rmdir()\n",
    "            image_dir.rmdir()\n",
    "        tilesize_dir.rmdir()\n",
    "\n",
    "    # Add image_int_uid to filenames and flatten structure completely\n",
    "    for image_dir in pathlib.Path(DATA_PATH_TILES).iterdir():\n",
    "        if image_dir.stem == 'ms' or image_dir.stem == 'pan':\n",
    "            continue\n",
    "        for ms_pan_dir in image_dir.iterdir():\n",
    "            for tile in ms_pan_dir.iterdir():\n",
    "                int_uid = get_int_uid(meta, image_dir.stem)\n",
    "                new_tile_name = str(str(int_uid).zfill(2)+'-'+tile.name)\n",
    "                new_dir = pathlib.Path(DATA_PATH_TILES).joinpath(ms_pan_dir.stem)\n",
    "                new_dir.mkdir(parents=True, exist_ok=True)\n",
    "                new_path = new_dir.joinpath(new_tile_name)\n",
    "                tile.rename(new_path)\n",
    "            ms_pan_dir.rmdir()\n",
    "        image_dir.rmdir()\n",
    "\n",
    "# List all tif files\n",
    "tif_paths = [file for file in pathlib.Path(DATA_PATH_TILES).glob('**/*.tif')]\n",
    "tif_paths_ms = tif_paths[:2500]\n",
    "tif_paths_pan = tif_paths[2500:]\n",
    "\n",
    "# Divide by 2 because each tile consists of 1 MS + 1 PAN\n",
    "print('Number of tiles generated and present in flat file structure:', str(int(len(tif_paths)/2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to png\n",
    "While the input to the actual cloud/sea classifier is tif files it is practical to also convert the image tiles to png. This makes labelling easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tiles generated and present in flat file structure: 2500\n"
     ]
    }
   ],
   "source": [
    "if CONVERT_TO_PNG:\n",
    "    for tif_path in tif_paths:\n",
    "        ms_or_pan = tif_path.parent.stem\n",
    "        \n",
    "        # sensor type is needed for conversion of ms to rgb png::\n",
    "        int_uid = int(tif_path.stem[:2])\n",
    "        string_uid = get_string_uid(meta, int_uid)\n",
    "        sensor = get_sensor(meta, string_uid)\n",
    "        \n",
    "        # saves png to disk\n",
    "        geotiff_to_png(tif_path, ms_or_pan=ms_or_pan, scale=True, stretch_img=True, sensor=sensor)\n",
    "\n",
    "# List all png files\n",
    "png_paths = [file for file in pathlib.Path(DATA_PATH_TILES).glob('**/*.png')]\n",
    "\n",
    "# Divide by 2 because each tile consists of 1 MS + 1 PAN\n",
    "print('Number of tiles generated and present in flat file structure:', str(int(len(png_paths)/2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create label csv file\n",
    "Labels are `None` before manual labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREATE_LABEL_CSV:\n",
    "    label_df = pd.DataFrame([tif_path.stem for tif_path in tif_paths[:N_TILES_TOTAL]], columns=['tile_uid'])\n",
    "    label_df['cloud-sea'] = None\n",
    "    label_df.to_csv(pathlib.Path(DATA_PATH_TILES).joinpath('labels-to-be.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelling\n",
    "*... 4 tedious labelling hours later...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the labeled csv\n",
    "\n",
    "Our `load_and_populate_label_df` function also extracts `sensor`, `tile_size` and `img_uid` from the `tile_uid` column. This is used later when preparing data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile_uid</th>\n",
       "      <th>cloud-sea</th>\n",
       "      <th>sensor</th>\n",
       "      <th>tile_size</th>\n",
       "      <th>img_uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00-128-00000</td>\n",
       "      <td>1</td>\n",
       "      <td>GE01</td>\n",
       "      <td>128</td>\n",
       "      <td>GE01_La_Spezia_2009_09_25_011651186010_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00-128-00001</td>\n",
       "      <td>1</td>\n",
       "      <td>GE01</td>\n",
       "      <td>128</td>\n",
       "      <td>GE01_La_Spezia_2009_09_25_011651186010_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00-128-00002</td>\n",
       "      <td>1</td>\n",
       "      <td>GE01</td>\n",
       "      <td>128</td>\n",
       "      <td>GE01_La_Spezia_2009_09_25_011651186010_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00-128-00003</td>\n",
       "      <td>0</td>\n",
       "      <td>GE01</td>\n",
       "      <td>128</td>\n",
       "      <td>GE01_La_Spezia_2009_09_25_011651186010_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00-128-00004</td>\n",
       "      <td>0</td>\n",
       "      <td>GE01</td>\n",
       "      <td>128</td>\n",
       "      <td>GE01_La_Spezia_2009_09_25_011651186010_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>72-96-00007</td>\n",
       "      <td>1</td>\n",
       "      <td>WV03_VNIR</td>\n",
       "      <td>96</td>\n",
       "      <td>WV03_VNIR_Toulon_2019_02_11_011650889010_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>72-96-00008</td>\n",
       "      <td>1</td>\n",
       "      <td>WV03_VNIR</td>\n",
       "      <td>96</td>\n",
       "      <td>WV03_VNIR_Toulon_2019_02_11_011650889010_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>72-96-00009</td>\n",
       "      <td>0</td>\n",
       "      <td>WV03_VNIR</td>\n",
       "      <td>96</td>\n",
       "      <td>WV03_VNIR_Toulon_2019_02_11_011650889010_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>72-96-00010</td>\n",
       "      <td>1</td>\n",
       "      <td>WV03_VNIR</td>\n",
       "      <td>96</td>\n",
       "      <td>WV03_VNIR_Toulon_2019_02_11_011650889010_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>72-96-00011</td>\n",
       "      <td>0</td>\n",
       "      <td>WV03_VNIR</td>\n",
       "      <td>96</td>\n",
       "      <td>WV03_VNIR_Toulon_2019_02_11_011650889010_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tile_uid  cloud-sea     sensor  tile_size  \\\n",
       "0     00-128-00000          1       GE01        128   \n",
       "1     00-128-00001          1       GE01        128   \n",
       "2     00-128-00002          1       GE01        128   \n",
       "3     00-128-00003          0       GE01        128   \n",
       "4     00-128-00004          0       GE01        128   \n",
       "...            ...        ...        ...        ...   \n",
       "2495   72-96-00007          1  WV03_VNIR         96   \n",
       "2496   72-96-00008          1  WV03_VNIR         96   \n",
       "2497   72-96-00009          0  WV03_VNIR         96   \n",
       "2498   72-96-00010          1  WV03_VNIR         96   \n",
       "2499   72-96-00011          0  WV03_VNIR         96   \n",
       "\n",
       "                                         img_uid  \n",
       "0       GE01_La_Spezia_2009_09_25_011651186010_0  \n",
       "1       GE01_La_Spezia_2009_09_25_011651186010_0  \n",
       "2       GE01_La_Spezia_2009_09_25_011651186010_0  \n",
       "3       GE01_La_Spezia_2009_09_25_011651186010_0  \n",
       "4       GE01_La_Spezia_2009_09_25_011651186010_0  \n",
       "...                                          ...  \n",
       "2495  WV03_VNIR_Toulon_2019_02_11_011650889010_0  \n",
       "2496  WV03_VNIR_Toulon_2019_02_11_011650889010_0  \n",
       "2497  WV03_VNIR_Toulon_2019_02_11_011650889010_0  \n",
       "2498  WV03_VNIR_Toulon_2019_02_11_011650889010_0  \n",
       "2499  WV03_VNIR_Toulon_2019_02_11_011650889010_0  \n",
       "\n",
       "[2500 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = load_and_populate_label_df(DATA_PATH_TILES + '/labels.csv', meta)\n",
    "label_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of images and labels\n",
    "\n",
    "Images in have different resolution. Classifier model architecture `EfficientNet` requires fixed image sizes as input so images are resized to `TRAIN_TILE_SIZE_PAN = 224`. [Native EfficientNet image sizes](https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/)\n",
    "\n",
    "Note that `EfficientNet` has rescaling and normalizing layers as their first layers so such preprocessing is not required in advance. In fact it seems like such preprocessing hurts performance of the model. We can therefore keep image tiles with `dtype=uint16`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 1)\n",
      "y.shape: (2500,)\n"
     ]
    }
   ],
   "source": [
    "X, y = prepare_for_training(label_df, tif_paths_pan, tif_paths_ms,\n",
    "                            pan_or_ms_or_both=PAN_OR_MS_OR_BOTH,\n",
    "                            pan_tile_size=TRAIN_TILE_SIZE, ms_tile_size=TRAIN_TILE_SIZE, \n",
    "                            resize_method=RESIZE_METHOD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"EfficientNetB0\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "img_augmentation (Sequential)   (None, 224, 224, 1)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "rescaling (Rescaling)           (None, 224, 224, 1)  0           img_augmentation[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 224, 224, 1)  3           rescaling[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv_pad (ZeroPadding2D)   (None, 225, 225, 1)  0           normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 112, 112, 32) 288         stem_conv_pad[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 112, 112, 32) 128         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 112, 112, 32) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 112, 112, 32) 288         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 112, 112, 32) 128         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 112, 112, 32) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 32)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 112, 112, 32) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 112, 112, 16) 512         block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 112, 112, 16) 64          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 112, 112, 96) 1536        block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 112, 112, 96) 384         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 112, 112, 96) 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv_pad (ZeroPadding (None, 113, 113, 96) 0           block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 56, 56, 96)   864         block2a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 56, 56, 96)   384         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 56, 56, 96)   0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 96)           0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 56, 56, 96)   0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 56, 56, 24)   2304        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 56, 56, 24)   96          block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 56, 56, 144)  3456        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 56, 56, 144)  576         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 56, 56, 144)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 56, 56, 144)  1296        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 56, 56, 144)  576         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 56, 56, 144)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 144)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 56, 56, 144)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 56, 56, 24)   3456        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 56, 56, 24)   96          block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (Dropout)          (None, 56, 56, 24)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 56, 56, 24)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 56, 56, 144)  3456        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 56, 56, 144)  576         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 56, 56, 144)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv_pad (ZeroPadding (None, 59, 59, 144)  0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 28, 28, 144)  3600        block3a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 28, 28, 144)  576         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 28, 28, 144)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 144)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 28, 28, 144)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 28, 28, 40)   5760        block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 28, 28, 40)   160         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 28, 28, 240)  9600        block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 28, 28, 240)  960         block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 28, 28, 240)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 28, 28, 240)  6000        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 28, 28, 240)  960         block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 28, 28, 240)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 240)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 28, 28, 240)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 28, 28, 40)   9600        block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 28, 28, 40)   160         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (Dropout)          (None, 28, 28, 40)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 28, 28, 40)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 28, 28, 240)  9600        block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 28, 28, 240)  960         block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 28, 28, 240)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv_pad (ZeroPadding (None, 29, 29, 240)  0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 14, 14, 240)  2160        block4a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 14, 14, 240)  960         block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 14, 14, 240)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 240)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 14, 14, 240)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 14, 14, 80)   19200       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 14, 14, 80)   320         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 14, 14, 480)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 14, 14, 480)  4320        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 14, 14, 480)  1920        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 14, 14, 480)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 480)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 14, 14, 480)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 14, 14, 80)   38400       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 14, 14, 80)   320         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (Dropout)          (None, 14, 14, 80)   0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 14, 14, 80)   0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 14, 14, 480)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 14, 14, 480)  4320        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 14, 14, 480)  1920        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 14, 14, 480)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 480)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 14, 14, 480)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 14, 14, 80)   38400       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 14, 14, 80)   320         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (Dropout)          (None, 14, 14, 80)   0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 14, 14, 80)   0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 14, 14, 480)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 14, 14, 480)  12000       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 14, 14, 480)  1920        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 14, 14, 480)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 480)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 14, 14, 480)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 14, 14, 112)  53760       block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 14, 14, 112)  448         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 14, 14, 672)  0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 14, 14, 672)  16800       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 14, 14, 672)  2688        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 14, 14, 672)  0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 672)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 14, 14, 672)  0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 14, 14, 112)  75264       block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 14, 14, 112)  448         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (Dropout)          (None, 14, 14, 112)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 14, 14, 112)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 14, 14, 672)  0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 14, 14, 672)  16800       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 14, 14, 672)  2688        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 14, 14, 672)  0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 672)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 14, 14, 672)  0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 14, 14, 112)  75264       block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 14, 14, 112)  448         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (Dropout)          (None, 14, 14, 112)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 14, 14, 112)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 14, 14, 672)  0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv_pad (ZeroPadding (None, 17, 17, 672)  0           block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 7, 7, 672)    16800       block6a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 7, 7, 672)    2688        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 7, 7, 672)    0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 672)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 7, 7, 672)    0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 7, 7, 192)    129024      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 7, 7, 192)    768         block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 7, 7, 1152)   0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 7, 7, 1152)   0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1152)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 7, 7, 192)    768         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (Dropout)          (None, 7, 7, 192)    0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 7, 7, 192)    0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 7, 7, 1152)   0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 7, 7, 1152)   0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1152)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 7, 7, 192)    768         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (Dropout)          (None, 7, 7, 192)    0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 7, 7, 192)    0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 7, 7, 1152)   0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 7, 7, 1152)   0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1152)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 7, 7, 192)    768         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (Dropout)          (None, 7, 7, 192)    0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 7, 7, 192)    0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 7, 7, 1152)   0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   10368       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 7, 7, 1152)   0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1152)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 7, 7, 1152)   0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 7, 7, 320)    368640      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 7, 7, 320)    1280        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 7, 7, 1280)   409600      block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 7, 7, 1280)   5120        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 7, 7, 1280)   0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1280)         0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "top_dropout (Dropout)           (None, 1280)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1)            1281        top_dropout[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 4,050,272\n",
      "Trainable params: 4,008,253\n",
      "Non-trainable params: 42,019\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(augment=True, input_shape=(TRAIN_TILE_SIZE, TRAIN_TILE_SIZE, TRAIN_TILE_BANDS))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_model_name = str('cloud-sea-classifier-effnetb0-pan-augm')\n",
    "log_dir = pathlib.Path(str('logs/cloud-sea-classifier/fit/' + pretrain_model_name \n",
    "                           + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, \n",
    "                                                      histogram_freq=10, \n",
    "                                                      write_graph=False, \n",
    "                                                      write_images=False,\n",
    "                                                      update_freq='epoch')\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = str('models/cloud-sea-classifier/' + pretrain_model_name + '-{epoch:02d}-{val_loss:.6f}.h5'), \n",
    "    monitor = \"val_acc\",\n",
    "    save_best_only = False,\n",
    "    save_weights_only = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "model.fit(X, y, batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "          validation_split=VAL_SPLIT, initial_epoch=0,\n",
    "          callbacks=[checkpoint_callback, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 1)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  1/110 [..............................] - ETA: 0s - loss: 1.8317 - accuracy: 0.3750WARNING:tensorflow:From c:\\users\\ono008\\master\\multispectral-super-resolution\\env\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/110 [..............................] - ETA: 31s - loss: 10.9276 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1017s vs `on_train_batch_end` time: 0.4892s). Check your callbacks.\n",
      "110/110 [==============================] - 19s 171ms/step - loss: 1.4963 - accuracy: 0.6846 - val_loss: 1.0087 - val_accuracy: 0.3720\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.6414 - accuracy: 0.7457 - val_loss: 2.0951 - val_accuracy: 0.3720\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.6486 - accuracy: 0.7377 - val_loss: 0.9608 - val_accuracy: 0.5427\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.4540 - accuracy: 0.8120 - val_loss: 1.4814 - val_accuracy: 0.5933\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.3969 - accuracy: 0.8309 - val_loss: 0.8480 - val_accuracy: 0.7693\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.3200 - accuracy: 0.8766 - val_loss: 0.3935 - val_accuracy: 0.8387\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.3359 - accuracy: 0.8731 - val_loss: 0.6695 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2722 - accuracy: 0.8960 - val_loss: 0.2824 - val_accuracy: 0.8907\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2532 - accuracy: 0.9063 - val_loss: 0.3498 - val_accuracy: 0.8720\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2621 - accuracy: 0.9177 - val_loss: 0.4405 - val_accuracy: 0.8853\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.2602 - accuracy: 0.9171 - val_loss: 0.2870 - val_accuracy: 0.8960\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2049 - accuracy: 0.9314 - val_loss: 0.2157 - val_accuracy: 0.9227\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2481 - accuracy: 0.9160 - val_loss: 0.3885 - val_accuracy: 0.8627\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2222 - accuracy: 0.9200 - val_loss: 0.2513 - val_accuracy: 0.9093\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2151 - accuracy: 0.9326 - val_loss: 0.2414 - val_accuracy: 0.9253\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1944 - accuracy: 0.9286 - val_loss: 0.2307 - val_accuracy: 0.9093\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1930 - accuracy: 0.9360 - val_loss: 0.2180 - val_accuracy: 0.9307\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2305 - accuracy: 0.9469 - val_loss: 0.2265 - val_accuracy: 0.8987\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 19s 170ms/step - loss: 0.2471 - accuracy: 0.9314 - val_loss: 0.3589 - val_accuracy: 0.8640\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1805 - accuracy: 0.9417 - val_loss: 0.2953 - val_accuracy: 0.9040\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.3649 - accuracy: 0.8880 - val_loss: 0.3544 - val_accuracy: 0.8453\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2549 - accuracy: 0.9103 - val_loss: 0.3517 - val_accuracy: 0.8720\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2856 - accuracy: 0.9074 - val_loss: 0.3943 - val_accuracy: 0.8373\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.3082 - accuracy: 0.9029 - val_loss: 0.3277 - val_accuracy: 0.8747\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2269 - accuracy: 0.9194 - val_loss: 0.3031 - val_accuracy: 0.9040\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1931 - accuracy: 0.9354 - val_loss: 0.1870 - val_accuracy: 0.9267\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2185 - accuracy: 0.9257 - val_loss: 0.2298 - val_accuracy: 0.9200\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.3274 - accuracy: 0.9011 - val_loss: 0.3447 - val_accuracy: 0.8680\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.2238 - accuracy: 0.9160 - val_loss: 0.2029 - val_accuracy: 0.9333\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2118 - accuracy: 0.9314 - val_loss: 0.2432 - val_accuracy: 0.9067\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1928 - accuracy: 0.9371 - val_loss: 0.2420 - val_accuracy: 0.9213\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1846 - accuracy: 0.9383 - val_loss: 0.2673 - val_accuracy: 0.9187\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1775 - accuracy: 0.9491 - val_loss: 0.2090 - val_accuracy: 0.9227\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2090 - accuracy: 0.9383 - val_loss: 0.2541 - val_accuracy: 0.9147\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1725 - accuracy: 0.9526 - val_loss: 0.3317 - val_accuracy: 0.9000\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1709 - accuracy: 0.9451 - val_loss: 0.2107 - val_accuracy: 0.9360\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1768 - accuracy: 0.9451 - val_loss: 0.2254 - val_accuracy: 0.9240\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1859 - accuracy: 0.9469 - val_loss: 0.2217 - val_accuracy: 0.9213\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1643 - accuracy: 0.9446 - val_loss: 0.2554 - val_accuracy: 0.9133\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1676 - accuracy: 0.9514 - val_loss: 0.1940 - val_accuracy: 0.9347\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1568 - accuracy: 0.9549 - val_loss: 0.2351 - val_accuracy: 0.9333\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1660 - accuracy: 0.9474 - val_loss: 0.2695 - val_accuracy: 0.9187\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1448 - accuracy: 0.9566 - val_loss: 0.2469 - val_accuracy: 0.9307\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1474 - accuracy: 0.9491 - val_loss: 0.2080 - val_accuracy: 0.9333\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1560 - accuracy: 0.9543 - val_loss: 0.2632 - val_accuracy: 0.9253\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1387 - accuracy: 0.9617 - val_loss: 0.2110 - val_accuracy: 0.9360\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1499 - accuracy: 0.9577 - val_loss: 0.2386 - val_accuracy: 0.9133\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1635 - accuracy: 0.9497 - val_loss: 0.3280 - val_accuracy: 0.9173\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1851 - accuracy: 0.9411 - val_loss: 2.3358 - val_accuracy: 0.8787\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1547 - accuracy: 0.9526 - val_loss: 0.2160 - val_accuracy: 0.9333\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1970 - accuracy: 0.9480 - val_loss: 0.2051 - val_accuracy: 0.9307\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1583 - accuracy: 0.9509 - val_loss: 0.2442 - val_accuracy: 0.9253\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1457 - accuracy: 0.9520 - val_loss: 0.1913 - val_accuracy: 0.9427\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1585 - accuracy: 0.9491 - val_loss: 0.1936 - val_accuracy: 0.9333\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1735 - accuracy: 0.9503 - val_loss: 0.1957 - val_accuracy: 0.9307\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1584 - accuracy: 0.9531 - val_loss: 0.2423 - val_accuracy: 0.9320\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1375 - accuracy: 0.9617 - val_loss: 0.2092 - val_accuracy: 0.9387\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1320 - accuracy: 0.9611 - val_loss: 0.2129 - val_accuracy: 0.9347\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1287 - accuracy: 0.9634 - val_loss: 0.2698 - val_accuracy: 0.9280\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1567 - accuracy: 0.9566 - val_loss: 0.2092 - val_accuracy: 0.9360\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.1475 - accuracy: 0.9549 - val_loss: 0.1932 - val_accuracy: 0.9400\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1197 - accuracy: 0.9623 - val_loss: 0.1580 - val_accuracy: 0.9493\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1387 - accuracy: 0.9549 - val_loss: 0.1806 - val_accuracy: 0.9427\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1275 - accuracy: 0.9634 - val_loss: 0.1811 - val_accuracy: 0.9360\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1296 - accuracy: 0.9623 - val_loss: 0.1866 - val_accuracy: 0.9400\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1461 - accuracy: 0.9651 - val_loss: 0.2380 - val_accuracy: 0.9387\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2139 - accuracy: 0.9446 - val_loss: 0.4988 - val_accuracy: 0.8387\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1878 - accuracy: 0.9509 - val_loss: 0.2334 - val_accuracy: 0.9213\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1462 - accuracy: 0.9583 - val_loss: 0.2151 - val_accuracy: 0.9320\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1287 - accuracy: 0.9600 - val_loss: 0.1629 - val_accuracy: 0.9427\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1400 - accuracy: 0.9543 - val_loss: 0.2406 - val_accuracy: 0.9413\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1173 - accuracy: 0.9629 - val_loss: 0.2072 - val_accuracy: 0.9453\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1366 - accuracy: 0.9623 - val_loss: 0.1686 - val_accuracy: 0.9427\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1276 - accuracy: 0.9600 - val_loss: 0.1967 - val_accuracy: 0.9533\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1202 - accuracy: 0.9617 - val_loss: 0.1902 - val_accuracy: 0.9493\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1191 - accuracy: 0.9657 - val_loss: 0.2380 - val_accuracy: 0.9227\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1433 - accuracy: 0.9577 - val_loss: 0.2609 - val_accuracy: 0.9000\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1412 - accuracy: 0.9537 - val_loss: 0.2125 - val_accuracy: 0.9360\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1854 - accuracy: 0.9571 - val_loss: 0.1575 - val_accuracy: 0.9440\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1401 - accuracy: 0.9617 - val_loss: 0.1577 - val_accuracy: 0.9427\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1200 - accuracy: 0.9657 - val_loss: 0.1503 - val_accuracy: 0.9560\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1010 - accuracy: 0.9669 - val_loss: 0.2749 - val_accuracy: 0.9253\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1315 - accuracy: 0.9611 - val_loss: 0.2682 - val_accuracy: 0.9227\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1064 - accuracy: 0.9697 - val_loss: 0.2052 - val_accuracy: 0.9440\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1131 - accuracy: 0.9651 - val_loss: 0.2220 - val_accuracy: 0.9427\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1193 - accuracy: 0.9663 - val_loss: 0.1529 - val_accuracy: 0.9507\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1656 - accuracy: 0.9497 - val_loss: 0.3260 - val_accuracy: 0.8960\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1391 - accuracy: 0.9589 - val_loss: 0.2703 - val_accuracy: 0.9240\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1312 - accuracy: 0.9589 - val_loss: 0.1615 - val_accuracy: 0.9453\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1357 - accuracy: 0.9594 - val_loss: 0.1798 - val_accuracy: 0.9533\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1368 - accuracy: 0.9606 - val_loss: 0.2058 - val_accuracy: 0.9373\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1186 - accuracy: 0.9657 - val_loss: 0.1777 - val_accuracy: 0.9440\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1172 - accuracy: 0.9606 - val_loss: 0.1866 - val_accuracy: 0.9400\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1097 - accuracy: 0.9663 - val_loss: 0.1918 - val_accuracy: 0.9480\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1907 - accuracy: 0.9480 - val_loss: 0.1568 - val_accuracy: 0.9467\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1439 - accuracy: 0.9594 - val_loss: 0.2121 - val_accuracy: 0.9413\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1556 - accuracy: 0.9537 - val_loss: 0.1683 - val_accuracy: 0.9387\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1106 - accuracy: 0.9691 - val_loss: 0.1977 - val_accuracy: 0.9347\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1193 - accuracy: 0.9674 - val_loss: 0.1614 - val_accuracy: 0.9507\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1092 - accuracy: 0.9674 - val_loss: 0.1787 - val_accuracy: 0.9427\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1163 - accuracy: 0.9651 - val_loss: 0.1575 - val_accuracy: 0.9493\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1065 - accuracy: 0.9726 - val_loss: 0.1864 - val_accuracy: 0.9400\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1121 - accuracy: 0.9686 - val_loss: 0.2069 - val_accuracy: 0.9453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1037 - accuracy: 0.9697 - val_loss: 0.1750 - val_accuracy: 0.9453\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0858 - accuracy: 0.9737 - val_loss: 0.2044 - val_accuracy: 0.9373\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0978 - accuracy: 0.9749 - val_loss: 0.1700 - val_accuracy: 0.9507\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1052 - accuracy: 0.9674 - val_loss: 0.1739 - val_accuracy: 0.9520\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0979 - accuracy: 0.9731 - val_loss: 0.1835 - val_accuracy: 0.9413\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1121 - accuracy: 0.9709 - val_loss: 0.1939 - val_accuracy: 0.9427\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0977 - accuracy: 0.9680 - val_loss: 0.1821 - val_accuracy: 0.9520\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 17s 153ms/step - loss: 0.0982 - accuracy: 0.9737 - val_loss: 0.1700 - val_accuracy: 0.9507\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0883 - accuracy: 0.9766 - val_loss: 0.1983 - val_accuracy: 0.9467\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1160 - accuracy: 0.9674 - val_loss: 0.1788 - val_accuracy: 0.9387\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1186 - accuracy: 0.9663 - val_loss: 0.2549 - val_accuracy: 0.9133\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1192 - accuracy: 0.9709 - val_loss: 0.1569 - val_accuracy: 0.9520\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1048 - accuracy: 0.9651 - val_loss: 0.1946 - val_accuracy: 0.9480\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1309 - accuracy: 0.9623 - val_loss: 0.1624 - val_accuracy: 0.9493\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1010 - accuracy: 0.9760 - val_loss: 0.1954 - val_accuracy: 0.9360\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0900 - accuracy: 0.9731 - val_loss: 0.2465 - val_accuracy: 0.9320\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1056 - accuracy: 0.9669 - val_loss: 0.2001 - val_accuracy: 0.9387\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.1414 - accuracy: 0.9669 - val_loss: 0.2535 - val_accuracy: 0.9267\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1408 - accuracy: 0.9549 - val_loss: 0.2033 - val_accuracy: 0.9373\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1137 - accuracy: 0.9657 - val_loss: 0.1775 - val_accuracy: 0.9387\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1135 - accuracy: 0.9703 - val_loss: 0.2074 - val_accuracy: 0.9440\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0961 - accuracy: 0.9714 - val_loss: 0.1706 - val_accuracy: 0.9533\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0918 - accuracy: 0.9686 - val_loss: 0.1663 - val_accuracy: 0.9520\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0853 - accuracy: 0.9794 - val_loss: 0.1701 - val_accuracy: 0.9547\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0985 - accuracy: 0.9709 - val_loss: 0.1949 - val_accuracy: 0.9493\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0949 - accuracy: 0.9743 - val_loss: 0.1734 - val_accuracy: 0.9413\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0970 - accuracy: 0.9714 - val_loss: 0.2489 - val_accuracy: 0.9267\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.0927 - accuracy: 0.9737 - val_loss: 0.1308 - val_accuracy: 0.9560\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0857 - accuracy: 0.9737 - val_loss: 0.1676 - val_accuracy: 0.9507\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0973 - accuracy: 0.9743 - val_loss: 0.1622 - val_accuracy: 0.9587\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0842 - accuracy: 0.9789 - val_loss: 0.1382 - val_accuracy: 0.9520\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0806 - accuracy: 0.9743 - val_loss: 0.1560 - val_accuracy: 0.9587\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0931 - accuracy: 0.9771 - val_loss: 0.1568 - val_accuracy: 0.9507\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0891 - accuracy: 0.9737 - val_loss: 0.1459 - val_accuracy: 0.9480\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1055 - accuracy: 0.9709 - val_loss: 0.2851 - val_accuracy: 0.9200\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1142 - accuracy: 0.9651 - val_loss: 0.1226 - val_accuracy: 0.9560\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1114 - accuracy: 0.9663 - val_loss: 0.1559 - val_accuracy: 0.9600\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.0968 - accuracy: 0.9720 - val_loss: 0.1774 - val_accuracy: 0.9493\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0941 - accuracy: 0.9720 - val_loss: 0.1344 - val_accuracy: 0.9520\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0780 - accuracy: 0.9777 - val_loss: 0.1401 - val_accuracy: 0.9493\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0932 - accuracy: 0.9731 - val_loss: 0.1655 - val_accuracy: 0.9467\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0784 - accuracy: 0.9754 - val_loss: 0.1342 - val_accuracy: 0.9560\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0933 - accuracy: 0.9737 - val_loss: 0.1447 - val_accuracy: 0.9520\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0830 - accuracy: 0.9754 - val_loss: 0.1352 - val_accuracy: 0.9573\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0926 - accuracy: 0.9731 - val_loss: 0.1399 - val_accuracy: 0.9520\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1010 - accuracy: 0.9669 - val_loss: 0.1814 - val_accuracy: 0.9560\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0669 - accuracy: 0.9800 - val_loss: 0.1454 - val_accuracy: 0.9560\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.0823 - accuracy: 0.9766 - val_loss: 0.1603 - val_accuracy: 0.9613\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1058 - accuracy: 0.9731 - val_loss: 0.2585 - val_accuracy: 0.9467\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0946 - accuracy: 0.9726 - val_loss: 0.2045 - val_accuracy: 0.9320\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0849 - accuracy: 0.9754 - val_loss: 0.1122 - val_accuracy: 0.9587\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1180 - accuracy: 0.9709 - val_loss: 0.2482 - val_accuracy: 0.9227\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0937 - accuracy: 0.9720 - val_loss: 0.1656 - val_accuracy: 0.9467\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0781 - accuracy: 0.9754 - val_loss: 0.1184 - val_accuracy: 0.9640\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0640 - accuracy: 0.9829 - val_loss: 0.1429 - val_accuracy: 0.9533\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0869 - accuracy: 0.9777 - val_loss: 0.1347 - val_accuracy: 0.9560\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0764 - accuracy: 0.9806 - val_loss: 0.1641 - val_accuracy: 0.9587\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.0857 - accuracy: 0.9777 - val_loss: 0.1449 - val_accuracy: 0.9533\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0726 - accuracy: 0.9771 - val_loss: 0.1442 - val_accuracy: 0.9493\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0994 - accuracy: 0.9766 - val_loss: 0.1393 - val_accuracy: 0.9600\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0923 - accuracy: 0.9737 - val_loss: 0.2022 - val_accuracy: 0.9293\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1139 - accuracy: 0.9634 - val_loss: 0.1446 - val_accuracy: 0.9520\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0999 - accuracy: 0.9657 - val_loss: 0.1253 - val_accuracy: 0.9560\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0988 - accuracy: 0.9714 - val_loss: 0.1393 - val_accuracy: 0.9560\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0962 - accuracy: 0.9709 - val_loss: 0.1199 - val_accuracy: 0.9573\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1015 - accuracy: 0.9691 - val_loss: 0.1546 - val_accuracy: 0.9533\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0808 - accuracy: 0.9760 - val_loss: 0.1403 - val_accuracy: 0.9533\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.0792 - accuracy: 0.9783 - val_loss: 0.1222 - val_accuracy: 0.9573\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0737 - accuracy: 0.9777 - val_loss: 0.1706 - val_accuracy: 0.9547\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0817 - accuracy: 0.9754 - val_loss: 0.1337 - val_accuracy: 0.9520\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0820 - accuracy: 0.9760 - val_loss: 0.1240 - val_accuracy: 0.9573\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0756 - accuracy: 0.9800 - val_loss: 0.1154 - val_accuracy: 0.9600\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0796 - accuracy: 0.9794 - val_loss: 0.1352 - val_accuracy: 0.9587\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0805 - accuracy: 0.9789 - val_loss: 0.1306 - val_accuracy: 0.9613\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0741 - accuracy: 0.9783 - val_loss: 0.1251 - val_accuracy: 0.9680\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0691 - accuracy: 0.9806 - val_loss: 0.1206 - val_accuracy: 0.9627\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0786 - accuracy: 0.9743 - val_loss: 0.1456 - val_accuracy: 0.9613\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.0776 - accuracy: 0.9800 - val_loss: 0.1901 - val_accuracy: 0.9547\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0773 - accuracy: 0.9794 - val_loss: 0.1297 - val_accuracy: 0.9640\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0846 - accuracy: 0.9777 - val_loss: 0.1215 - val_accuracy: 0.9667\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0680 - accuracy: 0.9811 - val_loss: 0.1197 - val_accuracy: 0.9613\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0685 - accuracy: 0.9783 - val_loss: 0.1368 - val_accuracy: 0.9613\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0806 - accuracy: 0.9760 - val_loss: 0.1210 - val_accuracy: 0.9627\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0739 - accuracy: 0.9783 - val_loss: 0.1393 - val_accuracy: 0.9560\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0695 - accuracy: 0.9789 - val_loss: 0.1285 - val_accuracy: 0.9600\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0713 - accuracy: 0.9806 - val_loss: 0.1277 - val_accuracy: 0.9573\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0726 - accuracy: 0.9817 - val_loss: 0.1279 - val_accuracy: 0.9627\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.0823 - accuracy: 0.9789 - val_loss: 0.1546 - val_accuracy: 0.9507\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0879 - accuracy: 0.9749 - val_loss: 0.1955 - val_accuracy: 0.9320\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0746 - accuracy: 0.9783 - val_loss: 0.1185 - val_accuracy: 0.9560\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0995 - accuracy: 0.9783 - val_loss: 0.1788 - val_accuracy: 0.9467\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0778 - accuracy: 0.9777 - val_loss: 0.1235 - val_accuracy: 0.9600\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0838 - accuracy: 0.9789 - val_loss: 0.1391 - val_accuracy: 0.9587\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0758 - accuracy: 0.9777 - val_loss: 0.1312 - val_accuracy: 0.9547\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0799 - accuracy: 0.9783 - val_loss: 0.1884 - val_accuracy: 0.9427\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0671 - accuracy: 0.9823 - val_loss: 0.1353 - val_accuracy: 0.9600\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0593 - accuracy: 0.9823 - val_loss: 0.1690 - val_accuracy: 0.9573\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 1)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 49s - loss: 1.4691 - accuracy: 0.6250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0876s vs `on_train_batch_end` time: 0.7811s). Check your callbacks.\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 1.0539 - accuracy: 0.6920 - val_loss: 0.7973 - val_accuracy: 0.3720\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.6998 - accuracy: 0.7389 - val_loss: 1.4729 - val_accuracy: 0.3720\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.6162 - accuracy: 0.7566 - val_loss: 0.5353 - val_accuracy: 0.6280\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.8122 - accuracy: 0.7434 - val_loss: 2.8019 - val_accuracy: 0.5547\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.4805 - accuracy: 0.8040 - val_loss: 0.4026 - val_accuracy: 0.7920\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.4416 - accuracy: 0.8143 - val_loss: 0.4682 - val_accuracy: 0.7827\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.4060 - accuracy: 0.8491 - val_loss: 0.5532 - val_accuracy: 0.7867\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3639 - accuracy: 0.8549 - val_loss: 0.5696 - val_accuracy: 0.7973\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3703 - accuracy: 0.8434 - val_loss: 0.4288 - val_accuracy: 0.8280\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.3164 - accuracy: 0.8817 - val_loss: 0.5379 - val_accuracy: 0.8000\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.2859 - accuracy: 0.8874 - val_loss: 0.4682 - val_accuracy: 0.8240\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2809 - accuracy: 0.8914 - val_loss: 0.5330 - val_accuracy: 0.7587\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2623 - accuracy: 0.9051 - val_loss: 0.2703 - val_accuracy: 0.8920\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.4200 - accuracy: 0.8989 - val_loss: 0.3194 - val_accuracy: 0.8960\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3551 - accuracy: 0.9040 - val_loss: 0.3476 - val_accuracy: 0.8840\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.3824 - accuracy: 0.9143 - val_loss: 0.2819 - val_accuracy: 0.9093\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.3144 - accuracy: 0.9063 - val_loss: 0.2340 - val_accuracy: 0.9040\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2235 - accuracy: 0.9251 - val_loss: 0.2311 - val_accuracy: 0.9080\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2438 - accuracy: 0.9086 - val_loss: 0.1999 - val_accuracy: 0.9373\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.2416 - accuracy: 0.9229 - val_loss: 0.2410 - val_accuracy: 0.9200\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.2185 - accuracy: 0.9394 - val_loss: 0.2439 - val_accuracy: 0.9160\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.4109 - accuracy: 0.9011 - val_loss: 0.2348 - val_accuracy: 0.9173\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1986 - accuracy: 0.9314 - val_loss: 0.1989 - val_accuracy: 0.9387\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2034 - accuracy: 0.9320 - val_loss: 0.1924 - val_accuracy: 0.9333\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1979 - accuracy: 0.9371 - val_loss: 0.2248 - val_accuracy: 0.9160\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1918 - accuracy: 0.9349 - val_loss: 0.2109 - val_accuracy: 0.9333\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1957 - accuracy: 0.9309 - val_loss: 0.2107 - val_accuracy: 0.9280\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2043 - accuracy: 0.9309 - val_loss: 0.2143 - val_accuracy: 0.9293\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1911 - accuracy: 0.9349 - val_loss: 0.1945 - val_accuracy: 0.9333\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1864 - accuracy: 0.9389 - val_loss: 0.2256 - val_accuracy: 0.9333\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.2129 - accuracy: 0.9394 - val_loss: 0.2698 - val_accuracy: 0.9160\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1810 - accuracy: 0.9394 - val_loss: 0.2366 - val_accuracy: 0.9253\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2117 - accuracy: 0.9337 - val_loss: 0.2161 - val_accuracy: 0.9253\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1853 - accuracy: 0.9383 - val_loss: 0.1634 - val_accuracy: 0.9467\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1637 - accuracy: 0.9491 - val_loss: 0.2445 - val_accuracy: 0.9253\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1900 - accuracy: 0.9406 - val_loss: 0.2707 - val_accuracy: 0.9293\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1755 - accuracy: 0.9383 - val_loss: 0.2246 - val_accuracy: 0.9280\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1825 - accuracy: 0.9411 - val_loss: 0.2017 - val_accuracy: 0.9293\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1722 - accuracy: 0.9509 - val_loss: 0.1892 - val_accuracy: 0.9253\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1674 - accuracy: 0.9434 - val_loss: 0.1926 - val_accuracy: 0.9307\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1620 - accuracy: 0.9549 - val_loss: 0.2807 - val_accuracy: 0.9067\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2043 - accuracy: 0.9440 - val_loss: 0.2314 - val_accuracy: 0.9253\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1690 - accuracy: 0.9440 - val_loss: 0.1851 - val_accuracy: 0.9267\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1597 - accuracy: 0.9491 - val_loss: 0.1802 - val_accuracy: 0.9347\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1527 - accuracy: 0.9503 - val_loss: 0.2516 - val_accuracy: 0.9093\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1402 - accuracy: 0.9503 - val_loss: 0.1756 - val_accuracy: 0.9387\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1449 - accuracy: 0.9509 - val_loss: 0.2267 - val_accuracy: 0.9253\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1528 - accuracy: 0.9509 - val_loss: 0.2475 - val_accuracy: 0.9347\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1415 - accuracy: 0.9549 - val_loss: 0.2272 - val_accuracy: 0.9333\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1493 - accuracy: 0.9526 - val_loss: 0.2083 - val_accuracy: 0.9347\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1255 - accuracy: 0.9634 - val_loss: 0.1965 - val_accuracy: 0.9373\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1400 - accuracy: 0.9543 - val_loss: 0.1971 - val_accuracy: 0.9333\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1241 - accuracy: 0.9583 - val_loss: 0.2035 - val_accuracy: 0.9320\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1329 - accuracy: 0.9543 - val_loss: 0.1772 - val_accuracy: 0.9360\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1388 - accuracy: 0.9634 - val_loss: 0.2494 - val_accuracy: 0.9120\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1934 - accuracy: 0.9560 - val_loss: 0.2800 - val_accuracy: 0.8973\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1660 - accuracy: 0.9491 - val_loss: 0.2340 - val_accuracy: 0.9253\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1591 - accuracy: 0.9560 - val_loss: 0.1987 - val_accuracy: 0.9387\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1450 - accuracy: 0.9503 - val_loss: 0.1888 - val_accuracy: 0.9427\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1363 - accuracy: 0.9577 - val_loss: 0.2256 - val_accuracy: 0.9293\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1227 - accuracy: 0.9594 - val_loss: 0.1732 - val_accuracy: 0.9427\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1356 - accuracy: 0.9571 - val_loss: 0.1904 - val_accuracy: 0.9333\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1788 - accuracy: 0.9514 - val_loss: 0.2375 - val_accuracy: 0.9267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1527 - accuracy: 0.9474 - val_loss: 0.1851 - val_accuracy: 0.9360\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1351 - accuracy: 0.9640 - val_loss: 0.1769 - val_accuracy: 0.9440\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1472 - accuracy: 0.9549 - val_loss: 0.2124 - val_accuracy: 0.9360\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1304 - accuracy: 0.9646 - val_loss: 0.1878 - val_accuracy: 0.9373\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1840 - accuracy: 0.9566 - val_loss: 0.1520 - val_accuracy: 0.9453\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1811 - accuracy: 0.9503 - val_loss: 0.1822 - val_accuracy: 0.9387\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1186 - accuracy: 0.9617 - val_loss: 0.2208 - val_accuracy: 0.9387\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1190 - accuracy: 0.9629 - val_loss: 0.2060 - val_accuracy: 0.9333\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1199 - accuracy: 0.9646 - val_loss: 0.1651 - val_accuracy: 0.9573\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1176 - accuracy: 0.9674 - val_loss: 0.2121 - val_accuracy: 0.9333\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1088 - accuracy: 0.9657 - val_loss: 0.2439 - val_accuracy: 0.9173\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1072 - accuracy: 0.9651 - val_loss: 0.1919 - val_accuracy: 0.9373\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1285 - accuracy: 0.9663 - val_loss: 0.1660 - val_accuracy: 0.9453\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1123 - accuracy: 0.9703 - val_loss: 0.3420 - val_accuracy: 0.9427\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1364 - accuracy: 0.9594 - val_loss: 0.2766 - val_accuracy: 0.8773\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1537 - accuracy: 0.9469 - val_loss: 0.2392 - val_accuracy: 0.9173\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1071 - accuracy: 0.9657 - val_loss: 0.1932 - val_accuracy: 0.9400\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1122 - accuracy: 0.9686 - val_loss: 0.2082 - val_accuracy: 0.9387\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1382 - accuracy: 0.9629 - val_loss: 0.3183 - val_accuracy: 0.9080\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1339 - accuracy: 0.9594 - val_loss: 0.2215 - val_accuracy: 0.9333\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1141 - accuracy: 0.9634 - val_loss: 0.2368 - val_accuracy: 0.9267\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1286 - accuracy: 0.9686 - val_loss: 0.1688 - val_accuracy: 0.9427\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1008 - accuracy: 0.9714 - val_loss: 0.1709 - val_accuracy: 0.9507\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1149 - accuracy: 0.9611 - val_loss: 0.2152 - val_accuracy: 0.9253\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1027 - accuracy: 0.9703 - val_loss: 0.1655 - val_accuracy: 0.9493\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1201 - accuracy: 0.9640 - val_loss: 0.2211 - val_accuracy: 0.9333\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1469 - accuracy: 0.9634 - val_loss: 0.1659 - val_accuracy: 0.9427\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1003 - accuracy: 0.9697 - val_loss: 0.1605 - val_accuracy: 0.9400\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1045 - accuracy: 0.9691 - val_loss: 0.1795 - val_accuracy: 0.9427\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1069 - accuracy: 0.9657 - val_loss: 0.1399 - val_accuracy: 0.9520\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1018 - accuracy: 0.9703 - val_loss: 0.2086 - val_accuracy: 0.9307\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1247 - accuracy: 0.9651 - val_loss: 0.1359 - val_accuracy: 0.9547\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0954 - accuracy: 0.9703 - val_loss: 0.1607 - val_accuracy: 0.9493\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1511 - accuracy: 0.9474 - val_loss: 0.3010 - val_accuracy: 0.9000\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1254 - accuracy: 0.9594 - val_loss: 0.1722 - val_accuracy: 0.9373\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1178 - accuracy: 0.9674 - val_loss: 0.2089 - val_accuracy: 0.9333\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1047 - accuracy: 0.9663 - val_loss: 0.1803 - val_accuracy: 0.9413\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1059 - accuracy: 0.9709 - val_loss: 0.1612 - val_accuracy: 0.9453\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1048 - accuracy: 0.9691 - val_loss: 0.1513 - val_accuracy: 0.9520\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0996 - accuracy: 0.9691 - val_loss: 0.1705 - val_accuracy: 0.9427\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1004 - accuracy: 0.9646 - val_loss: 0.1602 - val_accuracy: 0.9440\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0931 - accuracy: 0.9737 - val_loss: 0.1605 - val_accuracy: 0.9493\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0998 - accuracy: 0.9737 - val_loss: 0.1965 - val_accuracy: 0.9387\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1017 - accuracy: 0.9709 - val_loss: 0.1947 - val_accuracy: 0.9413\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1084 - accuracy: 0.9703 - val_loss: 0.2092 - val_accuracy: 0.9347\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1121 - accuracy: 0.9680 - val_loss: 0.1299 - val_accuracy: 0.9520\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0893 - accuracy: 0.9703 - val_loss: 0.1723 - val_accuracy: 0.9427\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0931 - accuracy: 0.9691 - val_loss: 0.2301 - val_accuracy: 0.9253\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0987 - accuracy: 0.9703 - val_loss: 0.1352 - val_accuracy: 0.9533\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0964 - accuracy: 0.9697 - val_loss: 0.1853 - val_accuracy: 0.9413\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0963 - accuracy: 0.9731 - val_loss: 0.1851 - val_accuracy: 0.9400\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0923 - accuracy: 0.9743 - val_loss: 0.1485 - val_accuracy: 0.9507\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1073 - accuracy: 0.9680 - val_loss: 0.1307 - val_accuracy: 0.9493\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0961 - accuracy: 0.9726 - val_loss: 0.1528 - val_accuracy: 0.9440\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0884 - accuracy: 0.9697 - val_loss: 0.1371 - val_accuracy: 0.9533\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0859 - accuracy: 0.9766 - val_loss: 0.1973 - val_accuracy: 0.9333\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1143 - accuracy: 0.9600 - val_loss: 0.2257 - val_accuracy: 0.9213\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.0958 - accuracy: 0.9720 - val_loss: 0.1731 - val_accuracy: 0.9413\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1087 - accuracy: 0.9680 - val_loss: 0.1506 - val_accuracy: 0.9520\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0970 - accuracy: 0.9703 - val_loss: 0.1523 - val_accuracy: 0.9507\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1639 - accuracy: 0.9600 - val_loss: 0.1374 - val_accuracy: 0.9560\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1048 - accuracy: 0.9697 - val_loss: 0.1327 - val_accuracy: 0.9560\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1054 - accuracy: 0.9680 - val_loss: 0.1539 - val_accuracy: 0.9400\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0939 - accuracy: 0.9686 - val_loss: 0.1447 - val_accuracy: 0.9507\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0832 - accuracy: 0.9766 - val_loss: 0.1159 - val_accuracy: 0.9627\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0952 - accuracy: 0.9737 - val_loss: 0.1383 - val_accuracy: 0.9493\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0760 - accuracy: 0.9754 - val_loss: 0.1827 - val_accuracy: 0.9400\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.0876 - accuracy: 0.9737 - val_loss: 0.1562 - val_accuracy: 0.9507\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0887 - accuracy: 0.9737 - val_loss: 0.1859 - val_accuracy: 0.9427\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0880 - accuracy: 0.9754 - val_loss: 0.1533 - val_accuracy: 0.9467\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1061 - accuracy: 0.9663 - val_loss: 0.1346 - val_accuracy: 0.9600\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0765 - accuracy: 0.9766 - val_loss: 0.1823 - val_accuracy: 0.9427\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0852 - accuracy: 0.9760 - val_loss: 0.1270 - val_accuracy: 0.9533\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0850 - accuracy: 0.9754 - val_loss: 0.1435 - val_accuracy: 0.9547\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0798 - accuracy: 0.9789 - val_loss: 0.1628 - val_accuracy: 0.9467\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0855 - accuracy: 0.9749 - val_loss: 0.1343 - val_accuracy: 0.9493\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1000 - accuracy: 0.9674 - val_loss: 0.1725 - val_accuracy: 0.9467\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.0851 - accuracy: 0.9749 - val_loss: 0.1136 - val_accuracy: 0.9640\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0835 - accuracy: 0.9714 - val_loss: 0.1489 - val_accuracy: 0.9587\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0732 - accuracy: 0.9794 - val_loss: 0.1163 - val_accuracy: 0.9627\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0835 - accuracy: 0.9726 - val_loss: 0.1295 - val_accuracy: 0.9573\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0912 - accuracy: 0.9749 - val_loss: 0.1554 - val_accuracy: 0.9413\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0797 - accuracy: 0.9783 - val_loss: 0.1468 - val_accuracy: 0.9507\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0785 - accuracy: 0.9771 - val_loss: 0.1465 - val_accuracy: 0.9507\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0781 - accuracy: 0.9737 - val_loss: 0.1469 - val_accuracy: 0.9533\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0885 - accuracy: 0.9726 - val_loss: 0.1161 - val_accuracy: 0.9600\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0852 - accuracy: 0.9731 - val_loss: 0.1324 - val_accuracy: 0.9520\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0893 - accuracy: 0.9703 - val_loss: 0.1752 - val_accuracy: 0.9427\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0859 - accuracy: 0.9714 - val_loss: 0.1268 - val_accuracy: 0.9547\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0835 - accuracy: 0.9771 - val_loss: 0.1231 - val_accuracy: 0.9547\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0742 - accuracy: 0.9794 - val_loss: 0.1271 - val_accuracy: 0.9560\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0796 - accuracy: 0.9731 - val_loss: 0.1611 - val_accuracy: 0.9520\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0923 - accuracy: 0.9726 - val_loss: 0.1499 - val_accuracy: 0.9440\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0893 - accuracy: 0.9760 - val_loss: 0.1389 - val_accuracy: 0.9587\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0732 - accuracy: 0.9789 - val_loss: 0.1396 - val_accuracy: 0.9547\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0903 - accuracy: 0.9731 - val_loss: 0.1687 - val_accuracy: 0.9453\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0892 - accuracy: 0.9749 - val_loss: 0.1639 - val_accuracy: 0.9427\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0723 - accuracy: 0.9743 - val_loss: 0.1566 - val_accuracy: 0.9507\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0677 - accuracy: 0.9800 - val_loss: 0.1112 - val_accuracy: 0.9627\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0827 - accuracy: 0.9771 - val_loss: 0.1319 - val_accuracy: 0.9627\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0848 - accuracy: 0.9749 - val_loss: 0.1181 - val_accuracy: 0.9613\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0686 - accuracy: 0.9789 - val_loss: 0.1481 - val_accuracy: 0.9560\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0806 - accuracy: 0.9777 - val_loss: 0.1306 - val_accuracy: 0.9573\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0807 - accuracy: 0.9789 - val_loss: 0.1203 - val_accuracy: 0.9613\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0750 - accuracy: 0.9771 - val_loss: 0.1317 - val_accuracy: 0.9573\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0751 - accuracy: 0.9771 - val_loss: 0.1296 - val_accuracy: 0.9600\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0864 - accuracy: 0.9691 - val_loss: 0.1514 - val_accuracy: 0.9533\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.0681 - accuracy: 0.9811 - val_loss: 0.1589 - val_accuracy: 0.9493\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0855 - accuracy: 0.9754 - val_loss: 0.1381 - val_accuracy: 0.9573\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0760 - accuracy: 0.9731 - val_loss: 0.1134 - val_accuracy: 0.9600\n",
      "Epoch 174/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0705 - accuracy: 0.9817 - val_loss: 0.1198 - val_accuracy: 0.9560\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0693 - accuracy: 0.9811 - val_loss: 0.1361 - val_accuracy: 0.9520\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0731 - accuracy: 0.9783 - val_loss: 0.1428 - val_accuracy: 0.9533\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0745 - accuracy: 0.9777 - val_loss: 0.1393 - val_accuracy: 0.9533\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0725 - accuracy: 0.9771 - val_loss: 0.1437 - val_accuracy: 0.9547\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0719 - accuracy: 0.9737 - val_loss: 0.1529 - val_accuracy: 0.9480\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0844 - accuracy: 0.9749 - val_loss: 0.1247 - val_accuracy: 0.9547\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.0655 - accuracy: 0.9840 - val_loss: 0.1252 - val_accuracy: 0.9560\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0737 - accuracy: 0.9766 - val_loss: 0.1330 - val_accuracy: 0.9613\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0767 - accuracy: 0.9794 - val_loss: 0.1362 - val_accuracy: 0.9587\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0646 - accuracy: 0.9800 - val_loss: 0.1243 - val_accuracy: 0.9573\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0784 - accuracy: 0.9771 - val_loss: 0.1496 - val_accuracy: 0.9507\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0728 - accuracy: 0.9789 - val_loss: 0.1372 - val_accuracy: 0.9547\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1041 - accuracy: 0.9726 - val_loss: 0.1376 - val_accuracy: 0.9547\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0769 - accuracy: 0.9771 - val_loss: 0.1409 - val_accuracy: 0.9560\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0647 - accuracy: 0.9800 - val_loss: 0.1409 - val_accuracy: 0.9560\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0660 - accuracy: 0.9811 - val_loss: 0.1385 - val_accuracy: 0.9547\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0882 - accuracy: 0.9731 - val_loss: 0.1533 - val_accuracy: 0.9467\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0720 - accuracy: 0.9811 - val_loss: 0.1650 - val_accuracy: 0.9560\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0840 - accuracy: 0.9766 - val_loss: 0.1602 - val_accuracy: 0.9507\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0838 - accuracy: 0.9731 - val_loss: 0.1333 - val_accuracy: 0.9560\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0943 - accuracy: 0.9760 - val_loss: 0.1614 - val_accuracy: 0.9533\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0749 - accuracy: 0.9777 - val_loss: 0.1438 - val_accuracy: 0.9560\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0828 - accuracy: 0.9806 - val_loss: 0.1303 - val_accuracy: 0.9547\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0811 - accuracy: 0.9766 - val_loss: 0.1227 - val_accuracy: 0.9547\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0636 - accuracy: 0.9840 - val_loss: 0.1244 - val_accuracy: 0.9533\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0747 - accuracy: 0.9789 - val_loss: 0.1256 - val_accuracy: 0.9547\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 1)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 50s - loss: 1.7139 - accuracy: 0.5312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0870s vs `on_train_batch_end` time: 0.7811s). Check your callbacks.\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 1.2839 - accuracy: 0.6349 - val_loss: 0.7166 - val_accuracy: 0.3720\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.6576 - accuracy: 0.7349 - val_loss: 0.7146 - val_accuracy: 0.3987\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.6354 - accuracy: 0.7406 - val_loss: 0.6045 - val_accuracy: 0.6013\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.6332 - accuracy: 0.7234 - val_loss: 0.7202 - val_accuracy: 0.5880\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.6470 - accuracy: 0.7343 - val_loss: 0.4895 - val_accuracy: 0.6893\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.6222 - accuracy: 0.7349 - val_loss: 0.7110 - val_accuracy: 0.6453\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.6287 - accuracy: 0.7531 - val_loss: 0.4304 - val_accuracy: 0.8027\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.5121 - accuracy: 0.7709 - val_loss: 0.5190 - val_accuracy: 0.7107\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.6359 - accuracy: 0.7549 - val_loss: 1.2175 - val_accuracy: 0.8027\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.5930 - accuracy: 0.7669 - val_loss: 0.7572 - val_accuracy: 0.7920\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.5632 - accuracy: 0.7549 - val_loss: 0.3864 - val_accuracy: 0.8640\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.5209 - accuracy: 0.7977 - val_loss: 0.4442 - val_accuracy: 0.7587\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.4734 - accuracy: 0.7926 - val_loss: 0.4867 - val_accuracy: 0.7467\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.5344 - accuracy: 0.7886 - val_loss: 0.5231 - val_accuracy: 0.7520\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.5659 - accuracy: 0.7789 - val_loss: 0.4605 - val_accuracy: 0.8227\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.5700 - accuracy: 0.7720 - val_loss: 0.4549 - val_accuracy: 0.8333\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.4785 - accuracy: 0.7994 - val_loss: 0.4786 - val_accuracy: 0.7960\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.5613 - accuracy: 0.7977 - val_loss: 0.5140 - val_accuracy: 0.8360\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.4300 - accuracy: 0.8074 - val_loss: 0.4539 - val_accuracy: 0.7747\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.4379 - accuracy: 0.8143 - val_loss: 0.5082 - val_accuracy: 0.8133\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.5106 - accuracy: 0.7920 - val_loss: 0.5281 - val_accuracy: 0.7653\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.4649 - accuracy: 0.8097 - val_loss: 0.3614 - val_accuracy: 0.8320\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.5425 - accuracy: 0.7857 - val_loss: 0.6795 - val_accuracy: 0.7427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.4490 - accuracy: 0.8137 - val_loss: 0.3856 - val_accuracy: 0.8093\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.4307 - accuracy: 0.8274 - val_loss: 0.3790 - val_accuracy: 0.8280\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.4348 - accuracy: 0.8286 - val_loss: 0.4042 - val_accuracy: 0.8147\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3919 - accuracy: 0.8326 - val_loss: 0.3606 - val_accuracy: 0.8520\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.4254 - accuracy: 0.8234 - val_loss: 0.5071 - val_accuracy: 0.8000\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3867 - accuracy: 0.8411 - val_loss: 0.4154 - val_accuracy: 0.8187\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.4105 - accuracy: 0.8371 - val_loss: 0.7991 - val_accuracy: 0.7853\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.4251 - accuracy: 0.8280 - val_loss: 0.4611 - val_accuracy: 0.7867\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.4553 - accuracy: 0.8280 - val_loss: 0.3930 - val_accuracy: 0.8293\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.4082 - accuracy: 0.8263 - val_loss: 1.9018 - val_accuracy: 0.7933\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3751 - accuracy: 0.8503 - val_loss: 0.3869 - val_accuracy: 0.8213\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.4309 - accuracy: 0.8463 - val_loss: 0.3440 - val_accuracy: 0.8613\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.4155 - accuracy: 0.8469 - val_loss: 0.2980 - val_accuracy: 0.8627\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.4090 - accuracy: 0.8446 - val_loss: 0.2923 - val_accuracy: 0.8880\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.3355 - accuracy: 0.8617 - val_loss: 0.4065 - val_accuracy: 0.8373\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3677 - accuracy: 0.8526 - val_loss: 0.3699 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.3426 - accuracy: 0.8646 - val_loss: 0.3909 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.3353 - accuracy: 0.8657 - val_loss: 0.2608 - val_accuracy: 0.8880\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3525 - accuracy: 0.8571 - val_loss: 0.3767 - val_accuracy: 0.8347\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.3215 - accuracy: 0.8703 - val_loss: 0.4546 - val_accuracy: 0.8253\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3616 - accuracy: 0.8749 - val_loss: 0.2743 - val_accuracy: 0.8760\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3492 - accuracy: 0.8720 - val_loss: 0.3686 - val_accuracy: 0.8560\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.3259 - accuracy: 0.8617 - val_loss: 0.3343 - val_accuracy: 0.8627\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2840 - accuracy: 0.8949 - val_loss: 0.3582 - val_accuracy: 0.8560\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.3286 - accuracy: 0.8714 - val_loss: 0.3167 - val_accuracy: 0.8627\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3025 - accuracy: 0.8869 - val_loss: 0.4909 - val_accuracy: 0.8400\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.3796 - accuracy: 0.8640 - val_loss: 0.6603 - val_accuracy: 0.8160\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.2959 - accuracy: 0.8811 - val_loss: 0.4190 - val_accuracy: 0.8440\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2834 - accuracy: 0.9006 - val_loss: 0.3810 - val_accuracy: 0.8520\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.3216 - accuracy: 0.8709 - val_loss: 0.4617 - val_accuracy: 0.8347\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2867 - accuracy: 0.8983 - val_loss: 0.4541 - val_accuracy: 0.8453\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2774 - accuracy: 0.8840 - val_loss: 0.4422 - val_accuracy: 0.8440\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.3119 - accuracy: 0.8880 - val_loss: 0.6388 - val_accuracy: 0.8240\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.2770 - accuracy: 0.8857 - val_loss: 0.3260 - val_accuracy: 0.8573\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.3333 - accuracy: 0.8857 - val_loss: 0.5786 - val_accuracy: 0.8240\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2646 - accuracy: 0.8960 - val_loss: 0.5656 - val_accuracy: 0.8267\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2945 - accuracy: 0.8914 - val_loss: 0.3795 - val_accuracy: 0.8587\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.2529 - accuracy: 0.9006 - val_loss: 0.4261 - val_accuracy: 0.8507\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2567 - accuracy: 0.8989 - val_loss: 0.3580 - val_accuracy: 0.8560\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2916 - accuracy: 0.8989 - val_loss: 0.3234 - val_accuracy: 0.8600\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2644 - accuracy: 0.9051 - val_loss: 0.3984 - val_accuracy: 0.8587\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.2395 - accuracy: 0.9120 - val_loss: 0.3781 - val_accuracy: 0.8507\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2768 - accuracy: 0.9154 - val_loss: 0.4276 - val_accuracy: 0.8493\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2611 - accuracy: 0.9029 - val_loss: 0.3882 - val_accuracy: 0.8667\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2499 - accuracy: 0.9091 - val_loss: 0.3868 - val_accuracy: 0.8560\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2422 - accuracy: 0.9097 - val_loss: 0.4599 - val_accuracy: 0.8613\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2629 - accuracy: 0.8983 - val_loss: 0.3712 - val_accuracy: 0.8653\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.2478 - accuracy: 0.9171 - val_loss: 0.3190 - val_accuracy: 0.8747\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2530 - accuracy: 0.9086 - val_loss: 0.4148 - val_accuracy: 0.8480\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.2281 - accuracy: 0.9183 - val_loss: 0.3621 - val_accuracy: 0.8787\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2353 - accuracy: 0.9206 - val_loss: 0.2840 - val_accuracy: 0.8813\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2229 - accuracy: 0.9229 - val_loss: 0.3455 - val_accuracy: 0.8760\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2177 - accuracy: 0.9211 - val_loss: 0.3475 - val_accuracy: 0.8707\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2416 - accuracy: 0.9149 - val_loss: 0.2934 - val_accuracy: 0.8733\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1908 - accuracy: 0.9337 - val_loss: 0.2687 - val_accuracy: 0.9040\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2137 - accuracy: 0.9269 - val_loss: 0.2742 - val_accuracy: 0.8893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2278 - accuracy: 0.9257 - val_loss: 0.2477 - val_accuracy: 0.9013\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.2061 - accuracy: 0.9269 - val_loss: 0.2084 - val_accuracy: 0.9133\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1972 - accuracy: 0.9291 - val_loss: 0.2985 - val_accuracy: 0.8893\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2241 - accuracy: 0.9217 - val_loss: 0.3165 - val_accuracy: 0.8933\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2135 - accuracy: 0.9246 - val_loss: 0.2572 - val_accuracy: 0.9053\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2144 - accuracy: 0.9263 - val_loss: 0.2506 - val_accuracy: 0.9013\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.2356 - accuracy: 0.9154 - val_loss: 0.2462 - val_accuracy: 0.9120\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2297 - accuracy: 0.9211 - val_loss: 0.2712 - val_accuracy: 0.9013\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.2130 - accuracy: 0.9280 - val_loss: 0.3378 - val_accuracy: 0.8933\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1936 - accuracy: 0.9303 - val_loss: 0.2358 - val_accuracy: 0.9107\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1975 - accuracy: 0.9326 - val_loss: 0.2212 - val_accuracy: 0.9200\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1987 - accuracy: 0.9331 - val_loss: 0.2554 - val_accuracy: 0.9107\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1894 - accuracy: 0.9331 - val_loss: 0.2030 - val_accuracy: 0.9200\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2064 - accuracy: 0.9320 - val_loss: 0.3143 - val_accuracy: 0.9027\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1932 - accuracy: 0.9337 - val_loss: 0.3601 - val_accuracy: 0.8880\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1942 - accuracy: 0.9349 - val_loss: 0.2142 - val_accuracy: 0.9200\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2043 - accuracy: 0.9343 - val_loss: 0.1964 - val_accuracy: 0.9200\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1842 - accuracy: 0.9337 - val_loss: 0.3013 - val_accuracy: 0.8973\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1758 - accuracy: 0.9423 - val_loss: 0.2864 - val_accuracy: 0.9000\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2065 - accuracy: 0.9371 - val_loss: 0.2639 - val_accuracy: 0.9187\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1767 - accuracy: 0.9434 - val_loss: 0.1936 - val_accuracy: 0.9267\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1828 - accuracy: 0.9400 - val_loss: 0.2241 - val_accuracy: 0.9187\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1684 - accuracy: 0.9389 - val_loss: 0.2453 - val_accuracy: 0.9187\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1769 - accuracy: 0.9417 - val_loss: 0.2611 - val_accuracy: 0.9080\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2038 - accuracy: 0.9291 - val_loss: 0.1695 - val_accuracy: 0.9373\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1762 - accuracy: 0.9389 - val_loss: 0.2331 - val_accuracy: 0.9240\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1755 - accuracy: 0.9429 - val_loss: 0.2419 - val_accuracy: 0.9200\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1878 - accuracy: 0.9366 - val_loss: 0.2343 - val_accuracy: 0.9173\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1740 - accuracy: 0.9429 - val_loss: 0.2404 - val_accuracy: 0.9133\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1469 - accuracy: 0.9520 - val_loss: 0.2515 - val_accuracy: 0.9107\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1810 - accuracy: 0.9349 - val_loss: 0.2274 - val_accuracy: 0.9160\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1784 - accuracy: 0.9383 - val_loss: 0.2123 - val_accuracy: 0.9253\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1658 - accuracy: 0.9457 - val_loss: 0.2061 - val_accuracy: 0.9200\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1568 - accuracy: 0.9446 - val_loss: 0.2212 - val_accuracy: 0.9240\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1627 - accuracy: 0.9497 - val_loss: 0.1826 - val_accuracy: 0.9333\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1634 - accuracy: 0.9411 - val_loss: 0.2275 - val_accuracy: 0.9187\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1678 - accuracy: 0.9451 - val_loss: 0.3575 - val_accuracy: 0.8880\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2209 - accuracy: 0.9440 - val_loss: 0.2022 - val_accuracy: 0.9320\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1531 - accuracy: 0.9503 - val_loss: 0.2015 - val_accuracy: 0.9293\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1725 - accuracy: 0.9383 - val_loss: 0.1881 - val_accuracy: 0.9333\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1630 - accuracy: 0.9457 - val_loss: 0.2553 - val_accuracy: 0.9200\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1573 - accuracy: 0.9497 - val_loss: 0.1727 - val_accuracy: 0.9413\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1460 - accuracy: 0.9491 - val_loss: 0.2539 - val_accuracy: 0.9240\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1670 - accuracy: 0.9434 - val_loss: 0.1690 - val_accuracy: 0.9373\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1672 - accuracy: 0.9457 - val_loss: 0.2110 - val_accuracy: 0.9320\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1524 - accuracy: 0.9486 - val_loss: 0.2314 - val_accuracy: 0.9173\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1773 - accuracy: 0.9429 - val_loss: 0.2317 - val_accuracy: 0.9160\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1710 - accuracy: 0.9411 - val_loss: 0.2122 - val_accuracy: 0.9253\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1557 - accuracy: 0.9480 - val_loss: 0.2186 - val_accuracy: 0.9347\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1769 - accuracy: 0.9486 - val_loss: 0.1974 - val_accuracy: 0.9307\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1605 - accuracy: 0.9491 - val_loss: 0.1978 - val_accuracy: 0.9280\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1590 - accuracy: 0.9429 - val_loss: 0.2399 - val_accuracy: 0.9133\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1541 - accuracy: 0.9503 - val_loss: 0.2399 - val_accuracy: 0.9227\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1539 - accuracy: 0.9486 - val_loss: 0.2531 - val_accuracy: 0.9187\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1428 - accuracy: 0.9509 - val_loss: 0.2094 - val_accuracy: 0.9293\n",
      "Epoch 135/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1448 - accuracy: 0.9520 - val_loss: 0.2569 - val_accuracy: 0.9213\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1556 - accuracy: 0.9469 - val_loss: 0.1830 - val_accuracy: 0.9347\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1243 - accuracy: 0.9606 - val_loss: 0.1896 - val_accuracy: 0.9360\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1483 - accuracy: 0.9537 - val_loss: 0.1897 - val_accuracy: 0.9360\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1441 - accuracy: 0.9537 - val_loss: 0.1875 - val_accuracy: 0.9347\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1328 - accuracy: 0.9520 - val_loss: 0.2348 - val_accuracy: 0.9307\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1395 - accuracy: 0.9606 - val_loss: 0.2069 - val_accuracy: 0.9280\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1316 - accuracy: 0.9594 - val_loss: 0.2349 - val_accuracy: 0.9187\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1364 - accuracy: 0.9549 - val_loss: 0.1971 - val_accuracy: 0.9320\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1417 - accuracy: 0.9554 - val_loss: 0.1942 - val_accuracy: 0.9320\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1416 - accuracy: 0.9526 - val_loss: 0.1862 - val_accuracy: 0.9373\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1276 - accuracy: 0.9583 - val_loss: 0.2102 - val_accuracy: 0.9387\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1252 - accuracy: 0.9531 - val_loss: 0.2585 - val_accuracy: 0.9240\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1385 - accuracy: 0.9543 - val_loss: 0.1682 - val_accuracy: 0.9400\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1337 - accuracy: 0.9554 - val_loss: 0.2010 - val_accuracy: 0.9360\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1718 - accuracy: 0.9509 - val_loss: 0.1963 - val_accuracy: 0.9360\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1331 - accuracy: 0.9571 - val_loss: 0.1633 - val_accuracy: 0.9440\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1477 - accuracy: 0.9526 - val_loss: 0.1634 - val_accuracy: 0.9440\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1381 - accuracy: 0.9577 - val_loss: 0.2066 - val_accuracy: 0.9320\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1726 - accuracy: 0.9509 - val_loss: 0.2404 - val_accuracy: 0.9253\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1360 - accuracy: 0.9543 - val_loss: 0.1716 - val_accuracy: 0.9400\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1205 - accuracy: 0.9629 - val_loss: 0.1676 - val_accuracy: 0.9480\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1353 - accuracy: 0.9583 - val_loss: 0.1638 - val_accuracy: 0.9480\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1333 - accuracy: 0.9589 - val_loss: 0.1686 - val_accuracy: 0.9413\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1205 - accuracy: 0.9623 - val_loss: 0.1803 - val_accuracy: 0.9373\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1536 - accuracy: 0.9526 - val_loss: 0.2452 - val_accuracy: 0.9307\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1259 - accuracy: 0.9566 - val_loss: 0.2272 - val_accuracy: 0.9293\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1219 - accuracy: 0.9640 - val_loss: 0.1616 - val_accuracy: 0.9387\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1304 - accuracy: 0.9571 - val_loss: 0.2041 - val_accuracy: 0.9293\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1081 - accuracy: 0.9709 - val_loss: 0.1985 - val_accuracy: 0.9293\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.1188 - accuracy: 0.9629 - val_loss: 0.1953 - val_accuracy: 0.9387\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1277 - accuracy: 0.9589 - val_loss: 0.1749 - val_accuracy: 0.9467\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1245 - accuracy: 0.9634 - val_loss: 0.1559 - val_accuracy: 0.9440\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1263 - accuracy: 0.9554 - val_loss: 0.1702 - val_accuracy: 0.9373\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1491 - accuracy: 0.9560 - val_loss: 0.2317 - val_accuracy: 0.9160\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1497 - accuracy: 0.9514 - val_loss: 0.1734 - val_accuracy: 0.9360\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1217 - accuracy: 0.9600 - val_loss: 0.1598 - val_accuracy: 0.9467\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1164 - accuracy: 0.9606 - val_loss: 0.1655 - val_accuracy: 0.9427\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1271 - accuracy: 0.9611 - val_loss: 0.1507 - val_accuracy: 0.9520\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1293 - accuracy: 0.9611 - val_loss: 0.1417 - val_accuracy: 0.9520\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1189 - accuracy: 0.9629 - val_loss: 0.1508 - val_accuracy: 0.9467\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1173 - accuracy: 0.9680 - val_loss: 0.1552 - val_accuracy: 0.9453\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1118 - accuracy: 0.9634 - val_loss: 0.1852 - val_accuracy: 0.9400\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1189 - accuracy: 0.9611 - val_loss: 0.1756 - val_accuracy: 0.9427\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1158 - accuracy: 0.9640 - val_loss: 0.1702 - val_accuracy: 0.9387\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1303 - accuracy: 0.9646 - val_loss: 0.2664 - val_accuracy: 0.9187\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1300 - accuracy: 0.9589 - val_loss: 0.1678 - val_accuracy: 0.9507\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1232 - accuracy: 0.9629 - val_loss: 0.1887 - val_accuracy: 0.9347\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0984 - accuracy: 0.9697 - val_loss: 0.1559 - val_accuracy: 0.9467\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1097 - accuracy: 0.9651 - val_loss: 0.1660 - val_accuracy: 0.9373\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1077 - accuracy: 0.9646 - val_loss: 0.1643 - val_accuracy: 0.9440\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1265 - accuracy: 0.9594 - val_loss: 0.1908 - val_accuracy: 0.9440\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1163 - accuracy: 0.9623 - val_loss: 0.2234 - val_accuracy: 0.9240\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1113 - accuracy: 0.9634 - val_loss: 0.1517 - val_accuracy: 0.9480\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1058 - accuracy: 0.9691 - val_loss: 0.1829 - val_accuracy: 0.9413\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1090 - accuracy: 0.9611 - val_loss: 0.1706 - val_accuracy: 0.9480\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1108 - accuracy: 0.9686 - val_loss: 0.1671 - val_accuracy: 0.9507\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1113 - accuracy: 0.9651 - val_loss: 0.1793 - val_accuracy: 0.9480\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1209 - accuracy: 0.9640 - val_loss: 0.1723 - val_accuracy: 0.9440\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1088 - accuracy: 0.9617 - val_loss: 0.1455 - val_accuracy: 0.9507\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1125 - accuracy: 0.9669 - val_loss: 0.2266 - val_accuracy: 0.9307\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1096 - accuracy: 0.9657 - val_loss: 0.1864 - val_accuracy: 0.9373\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0997 - accuracy: 0.9686 - val_loss: 0.1565 - val_accuracy: 0.9507\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0946 - accuracy: 0.9674 - val_loss: 0.2175 - val_accuracy: 0.9347\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1541 - accuracy: 0.9686 - val_loss: 0.1726 - val_accuracy: 0.9453\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1204 - accuracy: 0.9606 - val_loss: 0.1487 - val_accuracy: 0.9493\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 4)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 47s - loss: 6.1308 - accuracy: 0.6250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0968s vs `on_train_batch_end` time: 0.7811s). Check your callbacks.\n",
      "110/110 [==============================] - 19s 175ms/step - loss: 1.6730 - accuracy: 0.7457 - val_loss: 1.8407 - val_accuracy: 0.3720\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 17s 156ms/step - loss: 0.4526 - accuracy: 0.8137 - val_loss: 0.8453 - val_accuracy: 0.4187\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.4013 - accuracy: 0.8451 - val_loss: 0.9740 - val_accuracy: 0.3933\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.4593 - accuracy: 0.8491 - val_loss: 0.7221 - val_accuracy: 0.5893\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.3324 - accuracy: 0.8771 - val_loss: 0.6346 - val_accuracy: 0.7467\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2797 - accuracy: 0.8920 - val_loss: 0.5117 - val_accuracy: 0.7640\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.2556 - accuracy: 0.9143 - val_loss: 0.7220 - val_accuracy: 0.7013\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2727 - accuracy: 0.9240 - val_loss: 0.9506 - val_accuracy: 0.8147\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2463 - accuracy: 0.9206 - val_loss: 0.6414 - val_accuracy: 0.7173\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2525 - accuracy: 0.9246 - val_loss: 0.6159 - val_accuracy: 0.7453\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2409 - accuracy: 0.9246 - val_loss: 0.8524 - val_accuracy: 0.7440\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2007 - accuracy: 0.9343 - val_loss: 0.4679 - val_accuracy: 0.8227\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2119 - accuracy: 0.9417 - val_loss: 0.5610 - val_accuracy: 0.7267\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2263 - accuracy: 0.9360 - val_loss: 0.3811 - val_accuracy: 0.8253\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1989 - accuracy: 0.9406 - val_loss: 0.6404 - val_accuracy: 0.7240\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1811 - accuracy: 0.9423 - val_loss: 0.6732 - val_accuracy: 0.7507\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1727 - accuracy: 0.9469 - val_loss: 0.5338 - val_accuracy: 0.7520\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1738 - accuracy: 0.9480 - val_loss: 0.5976 - val_accuracy: 0.7240\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1832 - accuracy: 0.9411 - val_loss: 0.5415 - val_accuracy: 0.7427\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2440 - accuracy: 0.9389 - val_loss: 10.9834 - val_accuracy: 0.7613\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2569 - accuracy: 0.9206 - val_loss: 0.4190 - val_accuracy: 0.8413\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.2266 - accuracy: 0.9320 - val_loss: 0.2834 - val_accuracy: 0.9000\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2158 - accuracy: 0.9383 - val_loss: 0.4441 - val_accuracy: 0.8013\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1691 - accuracy: 0.9451 - val_loss: 0.4329 - val_accuracy: 0.8240\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1588 - accuracy: 0.9560 - val_loss: 0.3374 - val_accuracy: 0.8680\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 17s 156ms/step - loss: 0.1860 - accuracy: 0.9423 - val_loss: 0.4532 - val_accuracy: 0.8013\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1738 - accuracy: 0.9469 - val_loss: 0.3747 - val_accuracy: 0.8573\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1540 - accuracy: 0.9463 - val_loss: 0.5240 - val_accuracy: 0.7973\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1334 - accuracy: 0.9520 - val_loss: 0.4489 - val_accuracy: 0.8227\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1439 - accuracy: 0.9583 - val_loss: 0.3999 - val_accuracy: 0.8493\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1690 - accuracy: 0.9571 - val_loss: 0.4791 - val_accuracy: 0.8160\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1482 - accuracy: 0.9583 - val_loss: 0.6490 - val_accuracy: 0.8053\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1977 - accuracy: 0.9394 - val_loss: 0.2833 - val_accuracy: 0.8773\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1917 - accuracy: 0.9383 - val_loss: 0.5495 - val_accuracy: 0.8360\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1733 - accuracy: 0.9446 - val_loss: 0.4816 - val_accuracy: 0.8533\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1796 - accuracy: 0.9463 - val_loss: 0.3603 - val_accuracy: 0.8627\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1727 - accuracy: 0.9457 - val_loss: 0.4351 - val_accuracy: 0.8360\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1616 - accuracy: 0.9503 - val_loss: 0.4830 - val_accuracy: 0.8333\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1484 - accuracy: 0.9531 - val_loss: 0.5108 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1452 - accuracy: 0.9526 - val_loss: 0.4001 - val_accuracy: 0.8333\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1613 - accuracy: 0.9571 - val_loss: 0.7429 - val_accuracy: 0.7693\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1912 - accuracy: 0.9440 - val_loss: 0.5310 - val_accuracy: 0.8213\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2442 - accuracy: 0.9497 - val_loss: 0.4286 - val_accuracy: 0.8693\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1673 - accuracy: 0.9486 - val_loss: 0.4027 - val_accuracy: 0.8493\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1501 - accuracy: 0.9566 - val_loss: 0.6257 - val_accuracy: 0.7907\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1441 - accuracy: 0.9606 - val_loss: 0.7230 - val_accuracy: 0.7720\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1549 - accuracy: 0.9566 - val_loss: 0.4712 - val_accuracy: 0.8240\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1331 - accuracy: 0.9589 - val_loss: 0.4482 - val_accuracy: 0.8120\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1557 - accuracy: 0.9543 - val_loss: 0.7649 - val_accuracy: 0.7760\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1377 - accuracy: 0.9623 - val_loss: 0.5863 - val_accuracy: 0.8187\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1112 - accuracy: 0.9646 - val_loss: 0.4363 - val_accuracy: 0.8267\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1685 - accuracy: 0.9554 - val_loss: 0.5818 - val_accuracy: 0.8387\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1289 - accuracy: 0.9560 - val_loss: 0.6397 - val_accuracy: 0.8133\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1302 - accuracy: 0.9606 - val_loss: 0.7336 - val_accuracy: 0.7347\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1303 - accuracy: 0.9617 - val_loss: 0.5340 - val_accuracy: 0.7973\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1152 - accuracy: 0.9680 - val_loss: 1.0163 - val_accuracy: 0.7120\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1355 - accuracy: 0.9600 - val_loss: 0.6994 - val_accuracy: 0.6880\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1233 - accuracy: 0.9571 - val_loss: 0.4225 - val_accuracy: 0.8227\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1609 - accuracy: 0.9480 - val_loss: 0.7441 - val_accuracy: 0.7440\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1693 - accuracy: 0.9503 - val_loss: 0.6892 - val_accuracy: 0.7480\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2496 - accuracy: 0.9103 - val_loss: 0.8552 - val_accuracy: 0.7920\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2028 - accuracy: 0.9320 - val_loss: 0.6224 - val_accuracy: 0.7587\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 17s 156ms/step - loss: 0.1683 - accuracy: 0.9411 - val_loss: 0.6077 - val_accuracy: 0.7960\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1773 - accuracy: 0.9446 - val_loss: 0.4247 - val_accuracy: 0.8467\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1697 - accuracy: 0.9451 - val_loss: 0.5923 - val_accuracy: 0.7720\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1711 - accuracy: 0.9469 - val_loss: 0.5314 - val_accuracy: 0.8027\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1566 - accuracy: 0.9503 - val_loss: 0.4766 - val_accuracy: 0.8240\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1376 - accuracy: 0.9571 - val_loss: 0.4684 - val_accuracy: 0.8400\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1604 - accuracy: 0.9509 - val_loss: 0.6744 - val_accuracy: 0.7840\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1574 - accuracy: 0.9480 - val_loss: 0.7041 - val_accuracy: 0.7693\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1479 - accuracy: 0.9583 - val_loss: 0.6418 - val_accuracy: 0.7973\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1340 - accuracy: 0.9566 - val_loss: 0.4684 - val_accuracy: 0.8387\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1413 - accuracy: 0.9549 - val_loss: 0.5768 - val_accuracy: 0.8093\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1322 - accuracy: 0.9583 - val_loss: 0.6251 - val_accuracy: 0.7840\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1237 - accuracy: 0.9566 - val_loss: 0.4070 - val_accuracy: 0.8240\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1087 - accuracy: 0.9640 - val_loss: 0.4834 - val_accuracy: 0.8147\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1299 - accuracy: 0.9577 - val_loss: 0.7705 - val_accuracy: 0.7493\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1242 - accuracy: 0.9594 - val_loss: 0.4010 - val_accuracy: 0.8467\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1408 - accuracy: 0.9531 - val_loss: 0.6110 - val_accuracy: 0.7880\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1091 - accuracy: 0.9617 - val_loss: 0.5436 - val_accuracy: 0.8093\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1392 - accuracy: 0.9594 - val_loss: 0.7430 - val_accuracy: 0.7680\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1243 - accuracy: 0.9594 - val_loss: 0.6171 - val_accuracy: 0.8080\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1101 - accuracy: 0.9634 - val_loss: 0.4710 - val_accuracy: 0.8333\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1156 - accuracy: 0.9623 - val_loss: 0.5334 - val_accuracy: 0.8080\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1064 - accuracy: 0.9640 - val_loss: 0.7414 - val_accuracy: 0.7627\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1228 - accuracy: 0.9606 - val_loss: 0.4896 - val_accuracy: 0.8360\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1147 - accuracy: 0.9594 - val_loss: 0.4335 - val_accuracy: 0.8360\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1213 - accuracy: 0.9651 - val_loss: 0.4152 - val_accuracy: 0.8533\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1211 - accuracy: 0.9623 - val_loss: 0.6566 - val_accuracy: 0.8187\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1090 - accuracy: 0.9657 - val_loss: 0.3972 - val_accuracy: 0.8613\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1194 - accuracy: 0.9589 - val_loss: 1.2211 - val_accuracy: 0.8013\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1376 - accuracy: 0.9674 - val_loss: 0.3870 - val_accuracy: 0.8600\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1145 - accuracy: 0.9623 - val_loss: 0.3690 - val_accuracy: 0.8147\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1050 - accuracy: 0.9640 - val_loss: 2.5394 - val_accuracy: 0.8213\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1053 - accuracy: 0.9669 - val_loss: 4.4374 - val_accuracy: 0.8360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2008 - accuracy: 0.9549 - val_loss: 0.5308 - val_accuracy: 0.9027\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1389 - accuracy: 0.9623 - val_loss: 0.4682 - val_accuracy: 0.8373\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1193 - accuracy: 0.9629 - val_loss: 0.4827 - val_accuracy: 0.8507\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1152 - accuracy: 0.9600 - val_loss: 0.3572 - val_accuracy: 0.8147\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1067 - accuracy: 0.9686 - val_loss: 1.6180 - val_accuracy: 0.7533\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0915 - accuracy: 0.9726 - val_loss: 0.3953 - val_accuracy: 0.8427\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0950 - accuracy: 0.9731 - val_loss: 0.5270 - val_accuracy: 0.8267\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1150 - accuracy: 0.9657 - val_loss: 3.7212 - val_accuracy: 0.7653\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0900 - accuracy: 0.9743 - val_loss: 0.6993 - val_accuracy: 0.7960\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1272 - accuracy: 0.9600 - val_loss: 0.5761 - val_accuracy: 0.7813\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1306 - accuracy: 0.9571 - val_loss: 0.3768 - val_accuracy: 0.8573\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1079 - accuracy: 0.9686 - val_loss: 0.3799 - val_accuracy: 0.8400\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1348 - accuracy: 0.9629 - val_loss: 0.5669 - val_accuracy: 0.7813\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1095 - accuracy: 0.9680 - val_loss: 0.4186 - val_accuracy: 0.8560\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1291 - accuracy: 0.9600 - val_loss: 0.3714 - val_accuracy: 0.8613\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1024 - accuracy: 0.9651 - val_loss: 0.4453 - val_accuracy: 0.8360\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0887 - accuracy: 0.9743 - val_loss: 0.4461 - val_accuracy: 0.8533\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1039 - accuracy: 0.9669 - val_loss: 0.5210 - val_accuracy: 0.8267\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1112 - accuracy: 0.9669 - val_loss: 0.3514 - val_accuracy: 0.8587\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1316 - accuracy: 0.9617 - val_loss: 0.5044 - val_accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1242 - accuracy: 0.9594 - val_loss: 0.4983 - val_accuracy: 0.8267\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1098 - accuracy: 0.9686 - val_loss: 0.4685 - val_accuracy: 0.8227\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0808 - accuracy: 0.9754 - val_loss: 0.5278 - val_accuracy: 0.8053\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1020 - accuracy: 0.9691 - val_loss: 0.5400 - val_accuracy: 0.8093\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0978 - accuracy: 0.9743 - val_loss: 0.5086 - val_accuracy: 0.8213\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1286 - accuracy: 0.9634 - val_loss: 0.7447 - val_accuracy: 0.7813\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1239 - accuracy: 0.9634 - val_loss: 0.5573 - val_accuracy: 0.8320\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1043 - accuracy: 0.9674 - val_loss: 0.7770 - val_accuracy: 0.8400\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1132 - accuracy: 0.9640 - val_loss: 0.6133 - val_accuracy: 0.8347\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0959 - accuracy: 0.9714 - val_loss: 0.4402 - val_accuracy: 0.8520\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0866 - accuracy: 0.9731 - val_loss: 1.2524 - val_accuracy: 0.8253\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0846 - accuracy: 0.9777 - val_loss: 1.3809 - val_accuracy: 0.8387\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1089 - accuracy: 0.9657 - val_loss: 0.4732 - val_accuracy: 0.8400\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1034 - accuracy: 0.9646 - val_loss: 0.6075 - val_accuracy: 0.7760\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0951 - accuracy: 0.9714 - val_loss: 0.7568 - val_accuracy: 0.7573\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1191 - accuracy: 0.9697 - val_loss: 0.7660 - val_accuracy: 0.7333\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0952 - accuracy: 0.9709 - val_loss: 0.6910 - val_accuracy: 0.7693\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0978 - accuracy: 0.9669 - val_loss: 0.9695 - val_accuracy: 0.6587\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1107 - accuracy: 0.9623 - val_loss: 0.4659 - val_accuracy: 0.8253\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0967 - accuracy: 0.9703 - val_loss: 0.5665 - val_accuracy: 0.7640\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0968 - accuracy: 0.9720 - val_loss: 0.6679 - val_accuracy: 0.7707\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0876 - accuracy: 0.9697 - val_loss: 0.7634 - val_accuracy: 0.7133\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1204 - accuracy: 0.9674 - val_loss: 0.6438 - val_accuracy: 0.7400\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0869 - accuracy: 0.9714 - val_loss: 0.7669 - val_accuracy: 0.7440\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0933 - accuracy: 0.9697 - val_loss: 0.4987 - val_accuracy: 0.8013\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0949 - accuracy: 0.9720 - val_loss: 0.9488 - val_accuracy: 0.8240\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1011 - accuracy: 0.9726 - val_loss: 0.7203 - val_accuracy: 0.7440\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0924 - accuracy: 0.9754 - val_loss: 0.4670 - val_accuracy: 0.8160\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0735 - accuracy: 0.9777 - val_loss: 0.4513 - val_accuracy: 0.8413\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 17s 156ms/step - loss: 0.0982 - accuracy: 0.9731 - val_loss: 0.7908 - val_accuracy: 0.7453\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1041 - accuracy: 0.9657 - val_loss: 0.8616 - val_accuracy: 0.6787\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0892 - accuracy: 0.9766 - val_loss: 0.7006 - val_accuracy: 0.7773\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0941 - accuracy: 0.9726 - val_loss: 0.8589 - val_accuracy: 0.7413\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0913 - accuracy: 0.9720 - val_loss: 0.6118 - val_accuracy: 0.7867\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0940 - accuracy: 0.9743 - val_loss: 0.4867 - val_accuracy: 0.8133\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1027 - accuracy: 0.9680 - val_loss: 0.4288 - val_accuracy: 0.8093\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0785 - accuracy: 0.9783 - val_loss: 1.5363 - val_accuracy: 0.8240\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0902 - accuracy: 0.9754 - val_loss: 0.8149 - val_accuracy: 0.7493\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1054 - accuracy: 0.9663 - val_loss: 0.6428 - val_accuracy: 0.8133\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0887 - accuracy: 0.9766 - val_loss: 0.5858 - val_accuracy: 0.8000\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0860 - accuracy: 0.9720 - val_loss: 0.5593 - val_accuracy: 0.8213\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0873 - accuracy: 0.9743 - val_loss: 7.2325 - val_accuracy: 0.8547\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0833 - accuracy: 0.9783 - val_loss: 0.8405 - val_accuracy: 0.7280\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1019 - accuracy: 0.9703 - val_loss: 0.5762 - val_accuracy: 0.8013\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0910 - accuracy: 0.9789 - val_loss: 0.8953 - val_accuracy: 0.6920\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0778 - accuracy: 0.9771 - val_loss: 0.7348 - val_accuracy: 0.7480\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0751 - accuracy: 0.9783 - val_loss: 0.3704 - val_accuracy: 0.8480\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0882 - accuracy: 0.9760 - val_loss: 0.6953 - val_accuracy: 0.7560\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0849 - accuracy: 0.9749 - val_loss: 0.6691 - val_accuracy: 0.6947\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0809 - accuracy: 0.9754 - val_loss: 0.5105 - val_accuracy: 0.8213\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0817 - accuracy: 0.9771 - val_loss: 0.7936 - val_accuracy: 0.7747\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0717 - accuracy: 0.9771 - val_loss: 0.7950 - val_accuracy: 0.7133\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1278 - accuracy: 0.9611 - val_loss: 0.5462 - val_accuracy: 0.7973\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1016 - accuracy: 0.9697 - val_loss: 0.5985 - val_accuracy: 0.7787\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0877 - accuracy: 0.9749 - val_loss: 1.1656 - val_accuracy: 0.6707\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0846 - accuracy: 0.9737 - val_loss: 0.5488 - val_accuracy: 0.7947\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0793 - accuracy: 0.9760 - val_loss: 0.9341 - val_accuracy: 0.7080\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0712 - accuracy: 0.9806 - val_loss: 1.1160 - val_accuracy: 0.7107\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0921 - accuracy: 0.9726 - val_loss: 0.7439 - val_accuracy: 0.7387\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0751 - accuracy: 0.9789 - val_loss: 0.5422 - val_accuracy: 0.8067\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0708 - accuracy: 0.9777 - val_loss: 1.0163 - val_accuracy: 0.7373\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0944 - accuracy: 0.9766 - val_loss: 0.7543 - val_accuracy: 0.7427\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0904 - accuracy: 0.9760 - val_loss: 0.7385 - val_accuracy: 0.7707\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0794 - accuracy: 0.9760 - val_loss: 0.7922 - val_accuracy: 0.7600\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0720 - accuracy: 0.9800 - val_loss: 0.9316 - val_accuracy: 0.7227\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0717 - accuracy: 0.9800 - val_loss: 0.6922 - val_accuracy: 0.7747\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0817 - accuracy: 0.9766 - val_loss: 0.8824 - val_accuracy: 0.7280\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0773 - accuracy: 0.9749 - val_loss: 0.9824 - val_accuracy: 0.7120\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0720 - accuracy: 0.9823 - val_loss: 1.0368 - val_accuracy: 0.7067\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0770 - accuracy: 0.9766 - val_loss: 0.9996 - val_accuracy: 0.6960\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0759 - accuracy: 0.9749 - val_loss: 1.0010 - val_accuracy: 0.7200\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0738 - accuracy: 0.9777 - val_loss: 0.9982 - val_accuracy: 0.6693\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0814 - accuracy: 0.9766 - val_loss: 0.9510 - val_accuracy: 0.7240\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0767 - accuracy: 0.9766 - val_loss: 0.8957 - val_accuracy: 0.7453\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0747 - accuracy: 0.9789 - val_loss: 0.6992 - val_accuracy: 0.7573\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0720 - accuracy: 0.9783 - val_loss: 0.9194 - val_accuracy: 0.7160\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0879 - accuracy: 0.9737 - val_loss: 1.1071 - val_accuracy: 0.6787\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0819 - accuracy: 0.9766 - val_loss: 0.9015 - val_accuracy: 0.7147\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0890 - accuracy: 0.9743 - val_loss: 0.8279 - val_accuracy: 0.7080\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0757 - accuracy: 0.9777 - val_loss: 0.8106 - val_accuracy: 0.7293\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0751 - accuracy: 0.9794 - val_loss: 0.8706 - val_accuracy: 0.7440\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0635 - accuracy: 0.9823 - val_loss: 0.7387 - val_accuracy: 0.7693\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0689 - accuracy: 0.9800 - val_loss: 0.8255 - val_accuracy: 0.7360\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0599 - accuracy: 0.9834 - val_loss: 0.4621 - val_accuracy: 0.7987\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 17s 156ms/step - loss: 0.0741 - accuracy: 0.9811 - val_loss: 0.6103 - val_accuracy: 0.7573\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 4)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 48s - loss: 3.5357 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0905s vs `on_train_batch_end` time: 0.7654s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 19s 175ms/step - loss: 0.9528 - accuracy: 0.7371 - val_loss: 0.8657 - val_accuracy: 0.6280\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.7404 - accuracy: 0.7977 - val_loss: 0.6937 - val_accuracy: 0.5253\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.6485 - accuracy: 0.8074 - val_loss: 0.5825 - val_accuracy: 0.6547\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.5676 - accuracy: 0.8354 - val_loss: 1.5696 - val_accuracy: 0.6080\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.5005 - accuracy: 0.8366 - val_loss: 0.8396 - val_accuracy: 0.7240\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.4089 - accuracy: 0.8617 - val_loss: 0.8100 - val_accuracy: 0.7160\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3222 - accuracy: 0.8674 - val_loss: 0.8500 - val_accuracy: 0.7027\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3205 - accuracy: 0.8760 - val_loss: 0.8234 - val_accuracy: 0.6973\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2915 - accuracy: 0.8977 - val_loss: 0.6964 - val_accuracy: 0.6853\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2753 - accuracy: 0.8960 - val_loss: 0.8551 - val_accuracy: 0.7267\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2512 - accuracy: 0.9177 - val_loss: 0.5373 - val_accuracy: 0.7667\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2414 - accuracy: 0.9274 - val_loss: 0.6425 - val_accuracy: 0.7280\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2879 - accuracy: 0.9154 - val_loss: 1.1530 - val_accuracy: 0.7240\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2812 - accuracy: 0.9126 - val_loss: 0.8733 - val_accuracy: 0.7400\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3468 - accuracy: 0.9131 - val_loss: 0.5205 - val_accuracy: 0.7253\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3229 - accuracy: 0.9240 - val_loss: 3.2979 - val_accuracy: 0.7453\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.2150 - accuracy: 0.9211 - val_loss: 0.5373 - val_accuracy: 0.7853\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2063 - accuracy: 0.9331 - val_loss: 0.4263 - val_accuracy: 0.8120\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1884 - accuracy: 0.9360 - val_loss: 0.4939 - val_accuracy: 0.8173\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2085 - accuracy: 0.9360 - val_loss: 0.5654 - val_accuracy: 0.7773\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2202 - accuracy: 0.9469 - val_loss: 0.6303 - val_accuracy: 0.7907\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1639 - accuracy: 0.9497 - val_loss: 0.5844 - val_accuracy: 0.7800\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.2226 - accuracy: 0.9383 - val_loss: 0.6767 - val_accuracy: 0.8560\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2084 - accuracy: 0.9326 - val_loss: 0.4370 - val_accuracy: 0.8520\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1795 - accuracy: 0.9440 - val_loss: 0.5533 - val_accuracy: 0.7933\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1928 - accuracy: 0.9434 - val_loss: 0.6097 - val_accuracy: 0.7747\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1718 - accuracy: 0.9497 - val_loss: 0.7468 - val_accuracy: 0.7333\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1713 - accuracy: 0.9434 - val_loss: 0.5881 - val_accuracy: 0.7667\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1580 - accuracy: 0.9497 - val_loss: 0.6486 - val_accuracy: 0.7640\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1851 - accuracy: 0.9486 - val_loss: 0.6448 - val_accuracy: 0.7587\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1744 - accuracy: 0.9417 - val_loss: 0.5135 - val_accuracy: 0.7893\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1518 - accuracy: 0.9526 - val_loss: 0.6537 - val_accuracy: 0.7427\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1536 - accuracy: 0.9566 - val_loss: 0.5937 - val_accuracy: 0.7653\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1495 - accuracy: 0.9503 - val_loss: 0.5328 - val_accuracy: 0.7933\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1395 - accuracy: 0.9543 - val_loss: 0.6786 - val_accuracy: 0.7707\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1440 - accuracy: 0.9520 - val_loss: 0.5472 - val_accuracy: 0.7573\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1775 - accuracy: 0.9531 - val_loss: 0.6863 - val_accuracy: 0.7360\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1437 - accuracy: 0.9486 - val_loss: 0.7587 - val_accuracy: 0.7573\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1740 - accuracy: 0.9566 - val_loss: 0.5305 - val_accuracy: 0.7827\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1733 - accuracy: 0.9577 - val_loss: 0.6631 - val_accuracy: 0.7733\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1697 - accuracy: 0.9526 - val_loss: 0.5615 - val_accuracy: 0.7707\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1255 - accuracy: 0.9577 - val_loss: 0.3982 - val_accuracy: 0.8387\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1588 - accuracy: 0.9611 - val_loss: 0.7502 - val_accuracy: 0.6920\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1321 - accuracy: 0.9617 - val_loss: 0.5822 - val_accuracy: 0.7533\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1854 - accuracy: 0.9503 - val_loss: 0.7672 - val_accuracy: 0.6933\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1479 - accuracy: 0.9629 - val_loss: 0.6898 - val_accuracy: 0.7253\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1402 - accuracy: 0.9640 - val_loss: 1.3903 - val_accuracy: 0.6653\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1667 - accuracy: 0.9571 - val_loss: 0.5771 - val_accuracy: 0.7653\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1616 - accuracy: 0.9611 - val_loss: 1.0192 - val_accuracy: 0.6400\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1635 - accuracy: 0.9646 - val_loss: 0.5940 - val_accuracy: 0.7800\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1413 - accuracy: 0.9646 - val_loss: 0.6923 - val_accuracy: 0.7080\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1363 - accuracy: 0.9600 - val_loss: 0.4372 - val_accuracy: 0.8120\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1285 - accuracy: 0.9686 - val_loss: 0.8806 - val_accuracy: 0.7080\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1435 - accuracy: 0.9623 - val_loss: 0.9512 - val_accuracy: 0.6813\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1453 - accuracy: 0.9617 - val_loss: 0.8812 - val_accuracy: 0.6827\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1103 - accuracy: 0.9663 - val_loss: 0.9179 - val_accuracy: 0.6893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1431 - accuracy: 0.9594 - val_loss: 0.6032 - val_accuracy: 0.7653\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1046 - accuracy: 0.9714 - val_loss: 0.6768 - val_accuracy: 0.7133\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1224 - accuracy: 0.9583 - val_loss: 1.2051 - val_accuracy: 0.6680\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1300 - accuracy: 0.9594 - val_loss: 0.7022 - val_accuracy: 0.7360\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1130 - accuracy: 0.9640 - val_loss: 0.8499 - val_accuracy: 0.7480\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1243 - accuracy: 0.9537 - val_loss: 0.6981 - val_accuracy: 0.7400\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1164 - accuracy: 0.9651 - val_loss: 0.4302 - val_accuracy: 0.8267\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1178 - accuracy: 0.9646 - val_loss: 0.4849 - val_accuracy: 0.8067\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1165 - accuracy: 0.9634 - val_loss: 0.4701 - val_accuracy: 0.8280\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1462 - accuracy: 0.9651 - val_loss: 0.5517 - val_accuracy: 0.7813\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1319 - accuracy: 0.9640 - val_loss: 0.6089 - val_accuracy: 0.7227\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1493 - accuracy: 0.9657 - val_loss: 0.6675 - val_accuracy: 0.7213\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1400 - accuracy: 0.9617 - val_loss: 0.5552 - val_accuracy: 0.7853\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1190 - accuracy: 0.9680 - val_loss: 0.9582 - val_accuracy: 0.6720\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1471 - accuracy: 0.9606 - val_loss: 0.7021 - val_accuracy: 0.7453\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1143 - accuracy: 0.9646 - val_loss: 0.7137 - val_accuracy: 0.7507\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1261 - accuracy: 0.9606 - val_loss: 0.4260 - val_accuracy: 0.8240\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1018 - accuracy: 0.9697 - val_loss: 0.4504 - val_accuracy: 0.8080\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1381 - accuracy: 0.9634 - val_loss: 0.4398 - val_accuracy: 0.8240\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1075 - accuracy: 0.9680 - val_loss: 0.7448 - val_accuracy: 0.7400\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0915 - accuracy: 0.9703 - val_loss: 0.9684 - val_accuracy: 0.6987\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2339 - accuracy: 0.9537 - val_loss: 1.4921 - val_accuracy: 0.6640\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1681 - accuracy: 0.9531 - val_loss: 2.1854 - val_accuracy: 0.7960\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1378 - accuracy: 0.9549 - val_loss: 0.4056 - val_accuracy: 0.8533\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2731 - accuracy: 0.9417 - val_loss: 0.5855 - val_accuracy: 0.8533\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2294 - accuracy: 0.9411 - val_loss: 0.5217 - val_accuracy: 0.8147\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1487 - accuracy: 0.9549 - val_loss: 0.3692 - val_accuracy: 0.8307\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1711 - accuracy: 0.9577 - val_loss: 0.4826 - val_accuracy: 0.8227\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1069 - accuracy: 0.9657 - val_loss: 0.7848 - val_accuracy: 0.7707\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1034 - accuracy: 0.9657 - val_loss: 0.6553 - val_accuracy: 0.8040\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1047 - accuracy: 0.9680 - val_loss: 1.0794 - val_accuracy: 0.7240\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1142 - accuracy: 0.9657 - val_loss: 0.6837 - val_accuracy: 0.7840\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1122 - accuracy: 0.9629 - val_loss: 0.6793 - val_accuracy: 0.7613\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1301 - accuracy: 0.9629 - val_loss: 0.6627 - val_accuracy: 0.7960\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1036 - accuracy: 0.9669 - val_loss: 0.7303 - val_accuracy: 0.7520\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1033 - accuracy: 0.9663 - val_loss: 0.9135 - val_accuracy: 0.7453\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1204 - accuracy: 0.9634 - val_loss: 0.6253 - val_accuracy: 0.7947\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1047 - accuracy: 0.9663 - val_loss: 0.6310 - val_accuracy: 0.7813\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0931 - accuracy: 0.9714 - val_loss: 0.7151 - val_accuracy: 0.7893\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0924 - accuracy: 0.9726 - val_loss: 0.5837 - val_accuracy: 0.8000\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0932 - accuracy: 0.9714 - val_loss: 0.8042 - val_accuracy: 0.7547\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0941 - accuracy: 0.9680 - val_loss: 0.9503 - val_accuracy: 0.7107\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1057 - accuracy: 0.9686 - val_loss: 0.6596 - val_accuracy: 0.7600\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0966 - accuracy: 0.9691 - val_loss: 0.7581 - val_accuracy: 0.7453\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0982 - accuracy: 0.9697 - val_loss: 0.8760 - val_accuracy: 0.6973\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0932 - accuracy: 0.9726 - val_loss: 0.9791 - val_accuracy: 0.7267\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1277 - accuracy: 0.9617 - val_loss: 0.7669 - val_accuracy: 0.7493\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0902 - accuracy: 0.9754 - val_loss: 0.9710 - val_accuracy: 0.6880\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0966 - accuracy: 0.9726 - val_loss: 1.2856 - val_accuracy: 0.6707\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0889 - accuracy: 0.9726 - val_loss: 1.0544 - val_accuracy: 0.6680\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0946 - accuracy: 0.9703 - val_loss: 0.7504 - val_accuracy: 0.7107\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0853 - accuracy: 0.9726 - val_loss: 0.8106 - val_accuracy: 0.6880\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0739 - accuracy: 0.9771 - val_loss: 0.6141 - val_accuracy: 0.7267\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0843 - accuracy: 0.9737 - val_loss: 0.9062 - val_accuracy: 0.6813\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0856 - accuracy: 0.9720 - val_loss: 0.9024 - val_accuracy: 0.6840\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0928 - accuracy: 0.9743 - val_loss: 0.6628 - val_accuracy: 0.7333\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0774 - accuracy: 0.9800 - val_loss: 0.8286 - val_accuracy: 0.7053\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1096 - accuracy: 0.9686 - val_loss: 0.9253 - val_accuracy: 0.6920\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0699 - accuracy: 0.9840 - val_loss: 0.9809 - val_accuracy: 0.7067\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1178 - accuracy: 0.9691 - val_loss: 0.8040 - val_accuracy: 0.7093\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0992 - accuracy: 0.9686 - val_loss: 1.0231 - val_accuracy: 0.7013\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0935 - accuracy: 0.9709 - val_loss: 0.9392 - val_accuracy: 0.6960\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1081 - accuracy: 0.9749 - val_loss: 1.0395 - val_accuracy: 0.7027\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1055 - accuracy: 0.9669 - val_loss: 0.9209 - val_accuracy: 0.6800\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1334 - accuracy: 0.9640 - val_loss: 0.6469 - val_accuracy: 0.7307\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1246 - accuracy: 0.9629 - val_loss: 0.9613 - val_accuracy: 0.6747\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1046 - accuracy: 0.9680 - val_loss: 1.1006 - val_accuracy: 0.6787\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0990 - accuracy: 0.9714 - val_loss: 1.0504 - val_accuracy: 0.6760\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0932 - accuracy: 0.9709 - val_loss: 0.7612 - val_accuracy: 0.7360\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1452 - accuracy: 0.9566 - val_loss: 0.6010 - val_accuracy: 0.7840\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1482 - accuracy: 0.9543 - val_loss: 0.5681 - val_accuracy: 0.7853\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0981 - accuracy: 0.9651 - val_loss: 0.6515 - val_accuracy: 0.7920\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0924 - accuracy: 0.9703 - val_loss: 0.5071 - val_accuracy: 0.8173\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0950 - accuracy: 0.9749 - val_loss: 1.0423 - val_accuracy: 0.6880\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1049 - accuracy: 0.9703 - val_loss: 0.7827 - val_accuracy: 0.7760\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0937 - accuracy: 0.9714 - val_loss: 0.5763 - val_accuracy: 0.7880\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0768 - accuracy: 0.9766 - val_loss: 0.5344 - val_accuracy: 0.7840\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0897 - accuracy: 0.9731 - val_loss: 0.4506 - val_accuracy: 0.7987\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0873 - accuracy: 0.9754 - val_loss: 0.5990 - val_accuracy: 0.7680\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0897 - accuracy: 0.9720 - val_loss: 0.8146 - val_accuracy: 0.7107\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1004 - accuracy: 0.9709 - val_loss: 0.7609 - val_accuracy: 0.7493\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0919 - accuracy: 0.9749 - val_loss: 0.7539 - val_accuracy: 0.7333\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0939 - accuracy: 0.9686 - val_loss: 0.5567 - val_accuracy: 0.7653\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0836 - accuracy: 0.9731 - val_loss: 0.6790 - val_accuracy: 0.7547\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0867 - accuracy: 0.9731 - val_loss: 0.5781 - val_accuracy: 0.7573\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0895 - accuracy: 0.9720 - val_loss: 0.5903 - val_accuracy: 0.7173\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0748 - accuracy: 0.9771 - val_loss: 0.5783 - val_accuracy: 0.7693\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0823 - accuracy: 0.9760 - val_loss: 0.5926 - val_accuracy: 0.7853\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0756 - accuracy: 0.9766 - val_loss: 0.4756 - val_accuracy: 0.8133\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0805 - accuracy: 0.9771 - val_loss: 0.7529 - val_accuracy: 0.7533\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1024 - accuracy: 0.9709 - val_loss: 0.7781 - val_accuracy: 0.7453\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0730 - accuracy: 0.9726 - val_loss: 0.5331 - val_accuracy: 0.7867\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0922 - accuracy: 0.9714 - val_loss: 0.5205 - val_accuracy: 0.7787\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0784 - accuracy: 0.9760 - val_loss: 0.5360 - val_accuracy: 0.7707\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0790 - accuracy: 0.9771 - val_loss: 0.5079 - val_accuracy: 0.7893\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0793 - accuracy: 0.9754 - val_loss: 0.6001 - val_accuracy: 0.8027\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0760 - accuracy: 0.9771 - val_loss: 0.7821 - val_accuracy: 0.7587\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0686 - accuracy: 0.9834 - val_loss: 0.7154 - val_accuracy: 0.7573\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1167 - accuracy: 0.9720 - val_loss: 0.6950 - val_accuracy: 0.7733\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0842 - accuracy: 0.9720 - val_loss: 0.6411 - val_accuracy: 0.7387\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0637 - accuracy: 0.9823 - val_loss: 0.7917 - val_accuracy: 0.7387\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0782 - accuracy: 0.9783 - val_loss: 0.6245 - val_accuracy: 0.7653\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0699 - accuracy: 0.9783 - val_loss: 0.7106 - val_accuracy: 0.7307\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0773 - accuracy: 0.9749 - val_loss: 0.6825 - val_accuracy: 0.7253\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0790 - accuracy: 0.9777 - val_loss: 0.8016 - val_accuracy: 0.7373\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0909 - accuracy: 0.9743 - val_loss: 0.7124 - val_accuracy: 0.7293\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0858 - accuracy: 0.9737 - val_loss: 0.4924 - val_accuracy: 0.8027\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0837 - accuracy: 0.9754 - val_loss: 0.7303 - val_accuracy: 0.7360\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0811 - accuracy: 0.9771 - val_loss: 0.6932 - val_accuracy: 0.7627\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0656 - accuracy: 0.9829 - val_loss: 0.3578 - val_accuracy: 0.8427\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1042 - accuracy: 0.9760 - val_loss: 0.7899 - val_accuracy: 0.7147\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0751 - accuracy: 0.9760 - val_loss: 0.5748 - val_accuracy: 0.7827\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0806 - accuracy: 0.9771 - val_loss: 0.5600 - val_accuracy: 0.7693\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0857 - accuracy: 0.9737 - val_loss: 0.7345 - val_accuracy: 0.7093\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0830 - accuracy: 0.9760 - val_loss: 0.6827 - val_accuracy: 0.7693\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0874 - accuracy: 0.9709 - val_loss: 0.5702 - val_accuracy: 0.7493\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0748 - accuracy: 0.9783 - val_loss: 0.5398 - val_accuracy: 0.7840\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0701 - accuracy: 0.9800 - val_loss: 0.5044 - val_accuracy: 0.8000\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0660 - accuracy: 0.9806 - val_loss: 0.8148 - val_accuracy: 0.7320\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0800 - accuracy: 0.9766 - val_loss: 0.6358 - val_accuracy: 0.7480\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0797 - accuracy: 0.9783 - val_loss: 0.7965 - val_accuracy: 0.7120\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0697 - accuracy: 0.9789 - val_loss: 0.7783 - val_accuracy: 0.7107\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0740 - accuracy: 0.9789 - val_loss: 0.7020 - val_accuracy: 0.7333\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0781 - accuracy: 0.9754 - val_loss: 0.5355 - val_accuracy: 0.7693\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0805 - accuracy: 0.9720 - val_loss: 0.5697 - val_accuracy: 0.7533\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0867 - accuracy: 0.9794 - val_loss: 0.9590 - val_accuracy: 0.6893\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0762 - accuracy: 0.9789 - val_loss: 0.6020 - val_accuracy: 0.7520\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0734 - accuracy: 0.9817 - val_loss: 0.6868 - val_accuracy: 0.7520\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0802 - accuracy: 0.9754 - val_loss: 0.6267 - val_accuracy: 0.7480\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0774 - accuracy: 0.9794 - val_loss: 0.6885 - val_accuracy: 0.7493\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0636 - accuracy: 0.9783 - val_loss: 0.6033 - val_accuracy: 0.7600\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0785 - accuracy: 0.9771 - val_loss: 0.4945 - val_accuracy: 0.7507\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0740 - accuracy: 0.9783 - val_loss: 0.7046 - val_accuracy: 0.7427\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0681 - accuracy: 0.9794 - val_loss: 0.8606 - val_accuracy: 0.7280\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0604 - accuracy: 0.9829 - val_loss: 1.0573 - val_accuracy: 0.6947\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0837 - accuracy: 0.9754 - val_loss: 0.8208 - val_accuracy: 0.7027\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0556 - accuracy: 0.9840 - val_loss: 0.7184 - val_accuracy: 0.7293\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0729 - accuracy: 0.9794 - val_loss: 0.8942 - val_accuracy: 0.7067\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0610 - accuracy: 0.9829 - val_loss: 0.6567 - val_accuracy: 0.7360\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0684 - accuracy: 0.9817 - val_loss: 0.4636 - val_accuracy: 0.8107\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0615 - accuracy: 0.9823 - val_loss: 0.4950 - val_accuracy: 0.7920\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0582 - accuracy: 0.9834 - val_loss: 0.5367 - val_accuracy: 0.7960\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0669 - accuracy: 0.9811 - val_loss: 0.4642 - val_accuracy: 0.8000\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0675 - accuracy: 0.9794 - val_loss: 0.5278 - val_accuracy: 0.8067\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 4)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 49s - loss: 2.2587 - accuracy: 0.5625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0936s vs `on_train_batch_end` time: 0.7654s). Check your callbacks.\n",
      "110/110 [==============================] - 19s 176ms/step - loss: 0.8516 - accuracy: 0.6937 - val_loss: 0.6634 - val_accuracy: 0.6280\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.6317 - accuracy: 0.7674 - val_loss: 0.6889 - val_accuracy: 0.4627\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.6157 - accuracy: 0.7829 - val_loss: 0.8228 - val_accuracy: 0.4653\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.5445 - accuracy: 0.7949 - val_loss: 0.4347 - val_accuracy: 0.7920\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.4549 - accuracy: 0.8137 - val_loss: 0.4569 - val_accuracy: 0.7933\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.4645 - accuracy: 0.8446 - val_loss: 0.3965 - val_accuracy: 0.8320\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.5796 - accuracy: 0.8080 - val_loss: 0.5094 - val_accuracy: 0.7773\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.4464 - accuracy: 0.8366 - val_loss: 0.4848 - val_accuracy: 0.7667\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.4037 - accuracy: 0.8429 - val_loss: 0.4573 - val_accuracy: 0.7920\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.3666 - accuracy: 0.8657 - val_loss: 0.9346 - val_accuracy: 0.6240\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.4378 - accuracy: 0.8423 - val_loss: 0.8740 - val_accuracy: 0.7093\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3536 - accuracy: 0.8577 - val_loss: 1.1692 - val_accuracy: 0.6267\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3608 - accuracy: 0.8623 - val_loss: 0.4872 - val_accuracy: 0.7933\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.4006 - accuracy: 0.8486 - val_loss: 0.6874 - val_accuracy: 0.6613\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3912 - accuracy: 0.8497 - val_loss: 0.6887 - val_accuracy: 0.7907\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.3865 - accuracy: 0.8434 - val_loss: 0.4622 - val_accuracy: 0.8093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.4569 - accuracy: 0.8417 - val_loss: 0.7184 - val_accuracy: 0.6667\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.3695 - accuracy: 0.8537 - val_loss: 0.5873 - val_accuracy: 0.7373\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.3665 - accuracy: 0.8531 - val_loss: 0.6709 - val_accuracy: 0.7427\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3671 - accuracy: 0.8623 - val_loss: 0.6095 - val_accuracy: 0.7053\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.3099 - accuracy: 0.8749 - val_loss: 0.5517 - val_accuracy: 0.7227\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.3033 - accuracy: 0.8811 - val_loss: 0.8344 - val_accuracy: 0.6747\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3608 - accuracy: 0.8651 - val_loss: 0.6510 - val_accuracy: 0.7333\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3222 - accuracy: 0.8806 - val_loss: 1.1361 - val_accuracy: 0.6907\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3278 - accuracy: 0.8743 - val_loss: 1.1924 - val_accuracy: 0.6893\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3527 - accuracy: 0.8743 - val_loss: 0.4906 - val_accuracy: 0.7720\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.4137 - accuracy: 0.8474 - val_loss: 0.5268 - val_accuracy: 0.7413\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3319 - accuracy: 0.8789 - val_loss: 0.8334 - val_accuracy: 0.6853\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3367 - accuracy: 0.8846 - val_loss: 1.4653 - val_accuracy: 0.6333\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.2869 - accuracy: 0.8931 - val_loss: 0.8109 - val_accuracy: 0.6853\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.3089 - accuracy: 0.8731 - val_loss: 0.7239 - val_accuracy: 0.6893\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.2933 - accuracy: 0.8846 - val_loss: 0.6947 - val_accuracy: 0.7080\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3489 - accuracy: 0.8771 - val_loss: 0.7730 - val_accuracy: 0.7547\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3146 - accuracy: 0.8789 - val_loss: 0.6862 - val_accuracy: 0.6987\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2970 - accuracy: 0.8891 - val_loss: 1.1996 - val_accuracy: 0.6467\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3347 - accuracy: 0.8834 - val_loss: 0.9366 - val_accuracy: 0.6827\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2835 - accuracy: 0.8840 - val_loss: 0.7063 - val_accuracy: 0.7453\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2736 - accuracy: 0.8949 - val_loss: 0.7478 - val_accuracy: 0.7067\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.2966 - accuracy: 0.8989 - val_loss: 0.6576 - val_accuracy: 0.7320\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3278 - accuracy: 0.8960 - val_loss: 1.1747 - val_accuracy: 0.7333\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2861 - accuracy: 0.8943 - val_loss: 1.0920 - val_accuracy: 0.6693\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.3089 - accuracy: 0.8989 - val_loss: 0.8509 - val_accuracy: 0.6720\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2990 - accuracy: 0.8857 - val_loss: 1.1493 - val_accuracy: 0.7000\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2642 - accuracy: 0.8994 - val_loss: 0.6274 - val_accuracy: 0.7707\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2463 - accuracy: 0.9126 - val_loss: 1.1018 - val_accuracy: 0.6747\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2851 - accuracy: 0.9029 - val_loss: 0.8517 - val_accuracy: 0.6960\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.2558 - accuracy: 0.9131 - val_loss: 0.6531 - val_accuracy: 0.7360\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3216 - accuracy: 0.9114 - val_loss: 0.6601 - val_accuracy: 0.7400\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2392 - accuracy: 0.9154 - val_loss: 0.5529 - val_accuracy: 0.7547\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2425 - accuracy: 0.9149 - val_loss: 0.5774 - val_accuracy: 0.7520\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2341 - accuracy: 0.9143 - val_loss: 0.6123 - val_accuracy: 0.7293\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2260 - accuracy: 0.9206 - val_loss: 0.7489 - val_accuracy: 0.7067\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2372 - accuracy: 0.9126 - val_loss: 0.5890 - val_accuracy: 0.7800\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2431 - accuracy: 0.9120 - val_loss: 0.6153 - val_accuracy: 0.7427\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2269 - accuracy: 0.9246 - val_loss: 0.5668 - val_accuracy: 0.7627\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.2220 - accuracy: 0.9223 - val_loss: 0.5941 - val_accuracy: 0.7573\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.2719 - accuracy: 0.9086 - val_loss: 0.8300 - val_accuracy: 0.7400\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2698 - accuracy: 0.9166 - val_loss: 0.5107 - val_accuracy: 0.7747\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2186 - accuracy: 0.9291 - val_loss: 0.5157 - val_accuracy: 0.7573\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.2023 - accuracy: 0.9286 - val_loss: 0.5905 - val_accuracy: 0.7520\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2097 - accuracy: 0.9246 - val_loss: 0.6118 - val_accuracy: 0.7533\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1994 - accuracy: 0.9263 - val_loss: 0.7647 - val_accuracy: 0.6760\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2041 - accuracy: 0.9297 - val_loss: 0.5917 - val_accuracy: 0.7213\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1978 - accuracy: 0.9337 - val_loss: 1.5721 - val_accuracy: 0.7640\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2159 - accuracy: 0.9223 - val_loss: 0.5836 - val_accuracy: 0.7800\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2097 - accuracy: 0.9280 - val_loss: 0.7406 - val_accuracy: 0.7067\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1969 - accuracy: 0.9349 - val_loss: 0.6496 - val_accuracy: 0.7387\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2191 - accuracy: 0.9411 - val_loss: 0.6741 - val_accuracy: 0.7427\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1852 - accuracy: 0.9400 - val_loss: 0.7952 - val_accuracy: 0.7213\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1932 - accuracy: 0.9371 - val_loss: 0.8012 - val_accuracy: 0.7107\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1755 - accuracy: 0.9383 - val_loss: 0.5312 - val_accuracy: 0.7667\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1853 - accuracy: 0.9423 - val_loss: 0.9665 - val_accuracy: 0.7213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1723 - accuracy: 0.9406 - val_loss: 0.6003 - val_accuracy: 0.7693\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1706 - accuracy: 0.9457 - val_loss: 0.7919 - val_accuracy: 0.7040\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1720 - accuracy: 0.9446 - val_loss: 0.8308 - val_accuracy: 0.7440\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1797 - accuracy: 0.9383 - val_loss: 0.5981 - val_accuracy: 0.7853\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1681 - accuracy: 0.9446 - val_loss: 0.9906 - val_accuracy: 0.7213\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1698 - accuracy: 0.9451 - val_loss: 0.9074 - val_accuracy: 0.7320\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1535 - accuracy: 0.9503 - val_loss: 0.7617 - val_accuracy: 0.7520\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1820 - accuracy: 0.9389 - val_loss: 0.9015 - val_accuracy: 0.7507\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1718 - accuracy: 0.9417 - val_loss: 0.6538 - val_accuracy: 0.7640\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1601 - accuracy: 0.9503 - val_loss: 0.8761 - val_accuracy: 0.7333\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1628 - accuracy: 0.9486 - val_loss: 0.7520 - val_accuracy: 0.7147\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1656 - accuracy: 0.9417 - val_loss: 0.9084 - val_accuracy: 0.7507\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1469 - accuracy: 0.9554 - val_loss: 0.9324 - val_accuracy: 0.7173\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1593 - accuracy: 0.9509 - val_loss: 0.8372 - val_accuracy: 0.7547\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1637 - accuracy: 0.9469 - val_loss: 0.8787 - val_accuracy: 0.7373\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1776 - accuracy: 0.9469 - val_loss: 0.5342 - val_accuracy: 0.8000\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1599 - accuracy: 0.9491 - val_loss: 0.7501 - val_accuracy: 0.7627\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1776 - accuracy: 0.9486 - val_loss: 1.0096 - val_accuracy: 0.7333\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1692 - accuracy: 0.9457 - val_loss: 0.9357 - val_accuracy: 0.6760\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1881 - accuracy: 0.9497 - val_loss: 0.8394 - val_accuracy: 0.7133\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1620 - accuracy: 0.9514 - val_loss: 0.5852 - val_accuracy: 0.7813\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1372 - accuracy: 0.9577 - val_loss: 0.7588 - val_accuracy: 0.7267\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1676 - accuracy: 0.9503 - val_loss: 0.8114 - val_accuracy: 0.7333\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1695 - accuracy: 0.9549 - val_loss: 0.7885 - val_accuracy: 0.7867\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1446 - accuracy: 0.9549 - val_loss: 0.6891 - val_accuracy: 0.7733\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1496 - accuracy: 0.9543 - val_loss: 0.6708 - val_accuracy: 0.7693\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1456 - accuracy: 0.9526 - val_loss: 0.9130 - val_accuracy: 0.7133\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1523 - accuracy: 0.9520 - val_loss: 0.8022 - val_accuracy: 0.7467\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1277 - accuracy: 0.9531 - val_loss: 0.9287 - val_accuracy: 0.7333\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1423 - accuracy: 0.9526 - val_loss: 1.0292 - val_accuracy: 0.7253\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1373 - accuracy: 0.9549 - val_loss: 0.9744 - val_accuracy: 0.7493\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1494 - accuracy: 0.9486 - val_loss: 0.7089 - val_accuracy: 0.7547\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1216 - accuracy: 0.9589 - val_loss: 1.1427 - val_accuracy: 0.7507\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1436 - accuracy: 0.9549 - val_loss: 0.9180 - val_accuracy: 0.7507\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1439 - accuracy: 0.9537 - val_loss: 0.6821 - val_accuracy: 0.7560\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1398 - accuracy: 0.9543 - val_loss: 0.8700 - val_accuracy: 0.7387\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1372 - accuracy: 0.9491 - val_loss: 0.9379 - val_accuracy: 0.7587\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1261 - accuracy: 0.9560 - val_loss: 1.0227 - val_accuracy: 0.7120\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1249 - accuracy: 0.9646 - val_loss: 0.9117 - val_accuracy: 0.7493\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1361 - accuracy: 0.9554 - val_loss: 0.8792 - val_accuracy: 0.7453\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1229 - accuracy: 0.9560 - val_loss: 1.0035 - val_accuracy: 0.7133\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1414 - accuracy: 0.9577 - val_loss: 0.8995 - val_accuracy: 0.7133\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1406 - accuracy: 0.9566 - val_loss: 0.9652 - val_accuracy: 0.7280\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1353 - accuracy: 0.9560 - val_loss: 0.7450 - val_accuracy: 0.7467\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1214 - accuracy: 0.9589 - val_loss: 0.7986 - val_accuracy: 0.7600\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1294 - accuracy: 0.9583 - val_loss: 0.8196 - val_accuracy: 0.7480\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1360 - accuracy: 0.9594 - val_loss: 0.7048 - val_accuracy: 0.7493\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1335 - accuracy: 0.9606 - val_loss: 0.6522 - val_accuracy: 0.7587\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1198 - accuracy: 0.9611 - val_loss: 0.7825 - val_accuracy: 0.7600\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1338 - accuracy: 0.9589 - val_loss: 0.7244 - val_accuracy: 0.7867\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1267 - accuracy: 0.9634 - val_loss: 0.8522 - val_accuracy: 0.7827\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1326 - accuracy: 0.9606 - val_loss: 0.8754 - val_accuracy: 0.7507\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1246 - accuracy: 0.9629 - val_loss: 0.9077 - val_accuracy: 0.7520\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1072 - accuracy: 0.9657 - val_loss: 0.8652 - val_accuracy: 0.7573\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1232 - accuracy: 0.9634 - val_loss: 0.7901 - val_accuracy: 0.7560\n",
      "Epoch 128/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1308 - accuracy: 0.9531 - val_loss: 0.6716 - val_accuracy: 0.7640\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1186 - accuracy: 0.9629 - val_loss: 0.8039 - val_accuracy: 0.7467\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1416 - accuracy: 0.9589 - val_loss: 0.9335 - val_accuracy: 0.7773\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1215 - accuracy: 0.9623 - val_loss: 0.5168 - val_accuracy: 0.8213\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1335 - accuracy: 0.9549 - val_loss: 0.7451 - val_accuracy: 0.7520\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1321 - accuracy: 0.9549 - val_loss: 0.7830 - val_accuracy: 0.7640\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1338 - accuracy: 0.9566 - val_loss: 0.5613 - val_accuracy: 0.7760\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1036 - accuracy: 0.9663 - val_loss: 0.7433 - val_accuracy: 0.7680\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1287 - accuracy: 0.9583 - val_loss: 0.7549 - val_accuracy: 0.7480\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1086 - accuracy: 0.9634 - val_loss: 0.6581 - val_accuracy: 0.7733\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1333 - accuracy: 0.9571 - val_loss: 1.0484 - val_accuracy: 0.7080\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1100 - accuracy: 0.9640 - val_loss: 0.7444 - val_accuracy: 0.7640\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1096 - accuracy: 0.9657 - val_loss: 1.0551 - val_accuracy: 0.8147\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1155 - accuracy: 0.9651 - val_loss: 0.8717 - val_accuracy: 0.7453\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1107 - accuracy: 0.9657 - val_loss: 0.8716 - val_accuracy: 0.7507\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1117 - accuracy: 0.9663 - val_loss: 1.0573 - val_accuracy: 0.7373\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0993 - accuracy: 0.9669 - val_loss: 0.7884 - val_accuracy: 0.7627\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1233 - accuracy: 0.9617 - val_loss: 0.7661 - val_accuracy: 0.7293\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1296 - accuracy: 0.9583 - val_loss: 1.0793 - val_accuracy: 0.7467\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0926 - accuracy: 0.9714 - val_loss: 0.9159 - val_accuracy: 0.7507\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1125 - accuracy: 0.9640 - val_loss: 1.0171 - val_accuracy: 0.7480\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0850 - accuracy: 0.9720 - val_loss: 1.2007 - val_accuracy: 0.7560\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1115 - accuracy: 0.9651 - val_loss: 0.9126 - val_accuracy: 0.7347\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0997 - accuracy: 0.9691 - val_loss: 0.8585 - val_accuracy: 0.7787\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1108 - accuracy: 0.9714 - val_loss: 0.7786 - val_accuracy: 0.7573\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1067 - accuracy: 0.9640 - val_loss: 0.8366 - val_accuracy: 0.7427\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1139 - accuracy: 0.9657 - val_loss: 0.7510 - val_accuracy: 0.7320\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1125 - accuracy: 0.9651 - val_loss: 0.7618 - val_accuracy: 0.7347\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1162 - accuracy: 0.9600 - val_loss: 0.5384 - val_accuracy: 0.7813\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1006 - accuracy: 0.9657 - val_loss: 0.4939 - val_accuracy: 0.7947\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1161 - accuracy: 0.9646 - val_loss: 0.5752 - val_accuracy: 0.8013\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1111 - accuracy: 0.9646 - val_loss: 0.5731 - val_accuracy: 0.7693\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0927 - accuracy: 0.9697 - val_loss: 0.7865 - val_accuracy: 0.7493\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1010 - accuracy: 0.9651 - val_loss: 0.9437 - val_accuracy: 0.7413\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1053 - accuracy: 0.9680 - val_loss: 0.7856 - val_accuracy: 0.7480\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0969 - accuracy: 0.9726 - val_loss: 0.7226 - val_accuracy: 0.7560\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0929 - accuracy: 0.9697 - val_loss: 0.8228 - val_accuracy: 0.7347\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1116 - accuracy: 0.9663 - val_loss: 0.7563 - val_accuracy: 0.7680\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1002 - accuracy: 0.9714 - val_loss: 0.6171 - val_accuracy: 0.7800\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1067 - accuracy: 0.9629 - val_loss: 0.7160 - val_accuracy: 0.7813\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0982 - accuracy: 0.9674 - val_loss: 0.6900 - val_accuracy: 0.7600\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0939 - accuracy: 0.9697 - val_loss: 1.9462 - val_accuracy: 0.8067\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1001 - accuracy: 0.9686 - val_loss: 1.1301 - val_accuracy: 0.7680\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0850 - accuracy: 0.9737 - val_loss: 1.3374 - val_accuracy: 0.7840\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0935 - accuracy: 0.9720 - val_loss: 0.7941 - val_accuracy: 0.7573\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0976 - accuracy: 0.9669 - val_loss: 0.7135 - val_accuracy: 0.7813\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1522 - accuracy: 0.9617 - val_loss: 0.5607 - val_accuracy: 0.7867\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0925 - accuracy: 0.9714 - val_loss: 1.3094 - val_accuracy: 0.7733\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1046 - accuracy: 0.9669 - val_loss: 1.4541 - val_accuracy: 0.7560\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1000 - accuracy: 0.9680 - val_loss: 0.8229 - val_accuracy: 0.7773\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0885 - accuracy: 0.9726 - val_loss: 0.8342 - val_accuracy: 0.7947\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0921 - accuracy: 0.9709 - val_loss: 0.5474 - val_accuracy: 0.8107\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0949 - accuracy: 0.9709 - val_loss: 0.5693 - val_accuracy: 0.7880\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0985 - accuracy: 0.9680 - val_loss: 0.5916 - val_accuracy: 0.7747\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0883 - accuracy: 0.9703 - val_loss: 0.6486 - val_accuracy: 0.7707\n",
      "Epoch 183/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1028 - accuracy: 0.9680 - val_loss: 0.8622 - val_accuracy: 0.7893\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1014 - accuracy: 0.9686 - val_loss: 0.7908 - val_accuracy: 0.7253\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0870 - accuracy: 0.9731 - val_loss: 0.9661 - val_accuracy: 0.7307\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0866 - accuracy: 0.9680 - val_loss: 0.7358 - val_accuracy: 0.7613\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0997 - accuracy: 0.9686 - val_loss: 0.8863 - val_accuracy: 0.7627\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0922 - accuracy: 0.9703 - val_loss: 1.2255 - val_accuracy: 0.7413\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0954 - accuracy: 0.9686 - val_loss: 1.8367 - val_accuracy: 0.7573\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0803 - accuracy: 0.9749 - val_loss: 0.8214 - val_accuracy: 0.8080\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1067 - accuracy: 0.9737 - val_loss: 0.7234 - val_accuracy: 0.7480\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0878 - accuracy: 0.9697 - val_loss: 0.8801 - val_accuracy: 0.7413\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0848 - accuracy: 0.9749 - val_loss: 0.8083 - val_accuracy: 0.7707\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0836 - accuracy: 0.9726 - val_loss: 0.7815 - val_accuracy: 0.7547\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1022 - accuracy: 0.9651 - val_loss: 0.6744 - val_accuracy: 0.8213\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0972 - accuracy: 0.9680 - val_loss: 0.8547 - val_accuracy: 0.8213\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0680 - accuracy: 0.9806 - val_loss: 0.6983 - val_accuracy: 0.7787\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1244 - accuracy: 0.9703 - val_loss: 1.0854 - val_accuracy: 0.8107\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1007 - accuracy: 0.9697 - val_loss: 0.6198 - val_accuracy: 0.8147\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0879 - accuracy: 0.9731 - val_loss: 0.7671 - val_accuracy: 0.7693\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 5)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 49s - loss: 8.0811 - accuracy: 0.2500   WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0950s vs `on_train_batch_end` time: 0.7966s). Check your callbacks.\n",
      "110/110 [==============================] - 20s 182ms/step - loss: 1.4741 - accuracy: 0.7537 - val_loss: 0.9841 - val_accuracy: 0.3720\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.5425 - accuracy: 0.8160 - val_loss: 0.9275 - val_accuracy: 0.4013\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.3992 - accuracy: 0.8457 - val_loss: 2.2051 - val_accuracy: 0.4507\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.4073 - accuracy: 0.8600 - val_loss: 1.2327 - val_accuracy: 0.6480\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.3664 - accuracy: 0.8720 - val_loss: 1.4867 - val_accuracy: 0.6787\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.3853 - accuracy: 0.8989 - val_loss: 0.8730 - val_accuracy: 0.7787\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2699 - accuracy: 0.9211 - val_loss: 2.8227 - val_accuracy: 0.7520\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2794 - accuracy: 0.9269 - val_loss: 6.9877 - val_accuracy: 0.7760\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2697 - accuracy: 0.9211 - val_loss: 1.5034 - val_accuracy: 0.7653\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2085 - accuracy: 0.9377 - val_loss: 0.7500 - val_accuracy: 0.7680\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2104 - accuracy: 0.9423 - val_loss: 0.5730 - val_accuracy: 0.7573\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2664 - accuracy: 0.9366 - val_loss: 1.5223 - val_accuracy: 0.7973\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2946 - accuracy: 0.9286 - val_loss: 0.4171 - val_accuracy: 0.8293\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2215 - accuracy: 0.9303 - val_loss: 0.3847 - val_accuracy: 0.8413\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1614 - accuracy: 0.9549 - val_loss: 0.8135 - val_accuracy: 0.7693\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1775 - accuracy: 0.9480 - val_loss: 0.5119 - val_accuracy: 0.8027\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1657 - accuracy: 0.9520 - val_loss: 0.5646 - val_accuracy: 0.7880\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1952 - accuracy: 0.9440 - val_loss: 1.2422 - val_accuracy: 0.7880\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2160 - accuracy: 0.9320 - val_loss: 0.3255 - val_accuracy: 0.8547\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2134 - accuracy: 0.9331 - val_loss: 74.8306 - val_accuracy: 0.7093\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1865 - accuracy: 0.9406 - val_loss: 0.4440 - val_accuracy: 0.8160\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1576 - accuracy: 0.9491 - val_loss: 0.5355 - val_accuracy: 0.7733\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1942 - accuracy: 0.9423 - val_loss: 0.5539 - val_accuracy: 0.8093\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1445 - accuracy: 0.9566 - val_loss: 0.4344 - val_accuracy: 0.8587\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1387 - accuracy: 0.9589 - val_loss: 0.4128 - val_accuracy: 0.8600\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1636 - accuracy: 0.9566 - val_loss: 0.3710 - val_accuracy: 0.8693\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1452 - accuracy: 0.9589 - val_loss: 0.3139 - val_accuracy: 0.8733\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1491 - accuracy: 0.9583 - val_loss: 0.4704 - val_accuracy: 0.8373\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1380 - accuracy: 0.9611 - val_loss: 0.5236 - val_accuracy: 0.8440\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1449 - accuracy: 0.9606 - val_loss: 0.3432 - val_accuracy: 0.8800\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.1595 - accuracy: 0.9634 - val_loss: 0.7588 - val_accuracy: 0.7947\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1348 - accuracy: 0.9594 - val_loss: 0.2598 - val_accuracy: 0.9013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1493 - accuracy: 0.9634 - val_loss: 0.5003 - val_accuracy: 0.8427\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1253 - accuracy: 0.9611 - val_loss: 0.4492 - val_accuracy: 0.8307\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1240 - accuracy: 0.9617 - val_loss: 0.6160 - val_accuracy: 0.8040\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1646 - accuracy: 0.9669 - val_loss: 0.2883 - val_accuracy: 0.9107\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1767 - accuracy: 0.9537 - val_loss: 0.4312 - val_accuracy: 0.8573\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1457 - accuracy: 0.9577 - val_loss: 0.4843 - val_accuracy: 0.8200\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1470 - accuracy: 0.9634 - val_loss: 0.4627 - val_accuracy: 0.8560\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1371 - accuracy: 0.9703 - val_loss: 0.5116 - val_accuracy: 0.8480\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1114 - accuracy: 0.9686 - val_loss: 0.2974 - val_accuracy: 0.8707\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1205 - accuracy: 0.9640 - val_loss: 0.6935 - val_accuracy: 0.7800\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1092 - accuracy: 0.9657 - val_loss: 0.3399 - val_accuracy: 0.8813\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1176 - accuracy: 0.9657 - val_loss: 0.3661 - val_accuracy: 0.8653\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1414 - accuracy: 0.9623 - val_loss: 0.3760 - val_accuracy: 0.8507\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1312 - accuracy: 0.9663 - val_loss: 0.4849 - val_accuracy: 0.8587\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1169 - accuracy: 0.9669 - val_loss: 0.2984 - val_accuracy: 0.8893\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1920 - accuracy: 0.9571 - val_loss: 0.2854 - val_accuracy: 0.9040\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1373 - accuracy: 0.9606 - val_loss: 0.2949 - val_accuracy: 0.9000\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1227 - accuracy: 0.9640 - val_loss: 0.4695 - val_accuracy: 0.8587\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1172 - accuracy: 0.9669 - val_loss: 0.2831 - val_accuracy: 0.8933\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1272 - accuracy: 0.9697 - val_loss: 0.3780 - val_accuracy: 0.8627\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1196 - accuracy: 0.9697 - val_loss: 0.3150 - val_accuracy: 0.8853\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0953 - accuracy: 0.9720 - val_loss: 0.4630 - val_accuracy: 0.8600\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1137 - accuracy: 0.9674 - val_loss: 0.2721 - val_accuracy: 0.9173\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1138 - accuracy: 0.9680 - val_loss: 0.6447 - val_accuracy: 0.8027\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1063 - accuracy: 0.9663 - val_loss: 0.5446 - val_accuracy: 0.8200\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1057 - accuracy: 0.9726 - val_loss: 0.3193 - val_accuracy: 0.8907\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1175 - accuracy: 0.9629 - val_loss: 0.2966 - val_accuracy: 0.9053\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1128 - accuracy: 0.9674 - val_loss: 0.4409 - val_accuracy: 0.8747\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0920 - accuracy: 0.9691 - val_loss: 0.4518 - val_accuracy: 0.8533\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1029 - accuracy: 0.9657 - val_loss: 0.4191 - val_accuracy: 0.8480\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1023 - accuracy: 0.9749 - val_loss: 0.3323 - val_accuracy: 0.8680\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1131 - accuracy: 0.9686 - val_loss: 0.4059 - val_accuracy: 0.8720\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1370 - accuracy: 0.9600 - val_loss: 0.4097 - val_accuracy: 0.8587\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1306 - accuracy: 0.9617 - val_loss: 0.2929 - val_accuracy: 0.9000\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1272 - accuracy: 0.9629 - val_loss: 0.3795 - val_accuracy: 0.8587\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0983 - accuracy: 0.9686 - val_loss: 0.4768 - val_accuracy: 0.8533\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1072 - accuracy: 0.9680 - val_loss: 0.4857 - val_accuracy: 0.8507\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1475 - accuracy: 0.9623 - val_loss: 0.5003 - val_accuracy: 0.8387\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1113 - accuracy: 0.9686 - val_loss: 0.4158 - val_accuracy: 0.8520\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1181 - accuracy: 0.9669 - val_loss: 0.7733 - val_accuracy: 0.8360\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1664 - accuracy: 0.9537 - val_loss: 0.5437 - val_accuracy: 0.8387\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1066 - accuracy: 0.9720 - val_loss: 0.4627 - val_accuracy: 0.8413\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1424 - accuracy: 0.9680 - val_loss: 0.7688 - val_accuracy: 0.8067\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1506 - accuracy: 0.9611 - val_loss: 0.5963 - val_accuracy: 0.8360\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1628 - accuracy: 0.9566 - val_loss: 0.5271 - val_accuracy: 0.8160\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1037 - accuracy: 0.9709 - val_loss: 0.6219 - val_accuracy: 0.8253\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1565 - accuracy: 0.9549 - val_loss: 0.3438 - val_accuracy: 0.8827\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1184 - accuracy: 0.9703 - val_loss: 0.5565 - val_accuracy: 0.8520\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1188 - accuracy: 0.9703 - val_loss: 0.4678 - val_accuracy: 0.8253\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1322 - accuracy: 0.9646 - val_loss: 0.6260 - val_accuracy: 0.8027\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0912 - accuracy: 0.9737 - val_loss: 0.3558 - val_accuracy: 0.8627\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1028 - accuracy: 0.9697 - val_loss: 0.3525 - val_accuracy: 0.8733\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1241 - accuracy: 0.9697 - val_loss: 0.3970 - val_accuracy: 0.8507\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1069 - accuracy: 0.9686 - val_loss: 0.3933 - val_accuracy: 0.8867\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0937 - accuracy: 0.9709 - val_loss: 0.3179 - val_accuracy: 0.8880\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0937 - accuracy: 0.9709 - val_loss: 0.5296 - val_accuracy: 0.8560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1043 - accuracy: 0.9657 - val_loss: 0.4140 - val_accuracy: 0.8760\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0897 - accuracy: 0.9749 - val_loss: 0.4279 - val_accuracy: 0.8653\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0903 - accuracy: 0.9743 - val_loss: 0.4680 - val_accuracy: 0.8840\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0935 - accuracy: 0.9749 - val_loss: 0.4409 - val_accuracy: 0.8667\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0788 - accuracy: 0.9760 - val_loss: 0.3299 - val_accuracy: 0.9027\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0915 - accuracy: 0.9766 - val_loss: 0.3146 - val_accuracy: 0.8933\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0803 - accuracy: 0.9777 - val_loss: 0.4133 - val_accuracy: 0.8680\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0811 - accuracy: 0.9783 - val_loss: 0.7282 - val_accuracy: 0.7600\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0830 - accuracy: 0.9760 - val_loss: 0.5281 - val_accuracy: 0.8240\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0719 - accuracy: 0.9794 - val_loss: 0.4137 - val_accuracy: 0.8400\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0872 - accuracy: 0.9777 - val_loss: 0.4320 - val_accuracy: 0.8613\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0846 - accuracy: 0.9771 - val_loss: 0.2856 - val_accuracy: 0.9027\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0798 - accuracy: 0.9771 - val_loss: 0.3636 - val_accuracy: 0.8920\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0995 - accuracy: 0.9731 - val_loss: 0.5056 - val_accuracy: 0.8320\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0826 - accuracy: 0.9760 - val_loss: 0.4037 - val_accuracy: 0.8747\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0870 - accuracy: 0.9760 - val_loss: 0.6462 - val_accuracy: 0.8360\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0779 - accuracy: 0.9783 - val_loss: 0.5159 - val_accuracy: 0.8627\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0978 - accuracy: 0.9737 - val_loss: 0.2537 - val_accuracy: 0.9120\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0831 - accuracy: 0.9794 - val_loss: 0.3299 - val_accuracy: 0.8800\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0744 - accuracy: 0.9783 - val_loss: 0.3320 - val_accuracy: 0.8853\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0768 - accuracy: 0.9766 - val_loss: 0.4634 - val_accuracy: 0.8440\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0820 - accuracy: 0.9754 - val_loss: 0.3797 - val_accuracy: 0.8680\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0861 - accuracy: 0.9800 - val_loss: 0.5542 - val_accuracy: 0.8320\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0920 - accuracy: 0.9771 - val_loss: 0.4478 - val_accuracy: 0.8707\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0831 - accuracy: 0.9754 - val_loss: 0.8068 - val_accuracy: 0.7853\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0921 - accuracy: 0.9743 - val_loss: 0.3796 - val_accuracy: 0.8653\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0771 - accuracy: 0.9800 - val_loss: 0.4823 - val_accuracy: 0.8507\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0705 - accuracy: 0.9811 - val_loss: 0.4890 - val_accuracy: 0.8293\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0828 - accuracy: 0.9789 - val_loss: 0.6426 - val_accuracy: 0.8013\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1545 - accuracy: 0.9634 - val_loss: 0.4949 - val_accuracy: 0.8533\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0969 - accuracy: 0.9720 - val_loss: 0.4077 - val_accuracy: 0.8720\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0996 - accuracy: 0.9714 - val_loss: 0.2493 - val_accuracy: 0.9147\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.0922 - accuracy: 0.9760 - val_loss: 0.4157 - val_accuracy: 0.8667\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0806 - accuracy: 0.9754 - val_loss: 0.4765 - val_accuracy: 0.8507\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0955 - accuracy: 0.9754 - val_loss: 0.4813 - val_accuracy: 0.8507\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0865 - accuracy: 0.9697 - val_loss: 0.7044 - val_accuracy: 0.8000\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0847 - accuracy: 0.9754 - val_loss: 0.6201 - val_accuracy: 0.8080\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0744 - accuracy: 0.9794 - val_loss: 0.3273 - val_accuracy: 0.8867\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0658 - accuracy: 0.9840 - val_loss: 0.6332 - val_accuracy: 0.8240\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0784 - accuracy: 0.9777 - val_loss: 0.4922 - val_accuracy: 0.8347\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0692 - accuracy: 0.9789 - val_loss: 0.4412 - val_accuracy: 0.8573\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0685 - accuracy: 0.9794 - val_loss: 0.4687 - val_accuracy: 0.8507\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 19s 168ms/step - loss: 0.0673 - accuracy: 0.9811 - val_loss: 0.4069 - val_accuracy: 0.8600\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0867 - accuracy: 0.9789 - val_loss: 0.3181 - val_accuracy: 0.8853\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0814 - accuracy: 0.9743 - val_loss: 0.5440 - val_accuracy: 0.8453\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0864 - accuracy: 0.9743 - val_loss: 0.4568 - val_accuracy: 0.8560\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0898 - accuracy: 0.9743 - val_loss: 0.4223 - val_accuracy: 0.8707\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0700 - accuracy: 0.9794 - val_loss: 0.2187 - val_accuracy: 0.9360\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0642 - accuracy: 0.9863 - val_loss: 0.4899 - val_accuracy: 0.8587\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0668 - accuracy: 0.9829 - val_loss: 0.5927 - val_accuracy: 0.8387\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0798 - accuracy: 0.9771 - val_loss: 0.2605 - val_accuracy: 0.9200\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0756 - accuracy: 0.9783 - val_loss: 0.2502 - val_accuracy: 0.9187\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0746 - accuracy: 0.9766 - val_loss: 0.6812 - val_accuracy: 0.7907\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0854 - accuracy: 0.9749 - val_loss: 0.3728 - val_accuracy: 0.8613\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0798 - accuracy: 0.9794 - val_loss: 0.3508 - val_accuracy: 0.8813\n",
      "Epoch 144/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1100 - accuracy: 0.9749 - val_loss: 0.4415 - val_accuracy: 0.8573\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0930 - accuracy: 0.9754 - val_loss: 0.5342 - val_accuracy: 0.8280\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1094 - accuracy: 0.9760 - val_loss: 0.6841 - val_accuracy: 0.7973\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0752 - accuracy: 0.9794 - val_loss: 0.3852 - val_accuracy: 0.8827\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0718 - accuracy: 0.9806 - val_loss: 0.6006 - val_accuracy: 0.8320\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0688 - accuracy: 0.9817 - val_loss: 0.4683 - val_accuracy: 0.8893\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0741 - accuracy: 0.9800 - val_loss: 0.3829 - val_accuracy: 0.8747\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0828 - accuracy: 0.9783 - val_loss: 0.4971 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0673 - accuracy: 0.9823 - val_loss: 0.4382 - val_accuracy: 0.8480\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0735 - accuracy: 0.9766 - val_loss: 0.2512 - val_accuracy: 0.9267\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0638 - accuracy: 0.9811 - val_loss: 0.4162 - val_accuracy: 0.8640\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0783 - accuracy: 0.9777 - val_loss: 0.6055 - val_accuracy: 0.8280\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0764 - accuracy: 0.9789 - val_loss: 0.4770 - val_accuracy: 0.8213\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0671 - accuracy: 0.9829 - val_loss: 0.3934 - val_accuracy: 0.8347\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0713 - accuracy: 0.9789 - val_loss: 0.5431 - val_accuracy: 0.8173\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0583 - accuracy: 0.9840 - val_loss: 0.4557 - val_accuracy: 0.8293\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0732 - accuracy: 0.9783 - val_loss: 0.4965 - val_accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0583 - accuracy: 0.9817 - val_loss: 0.4025 - val_accuracy: 0.8533\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0756 - accuracy: 0.9794 - val_loss: 0.4932 - val_accuracy: 0.8373\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0691 - accuracy: 0.9806 - val_loss: 0.3286 - val_accuracy: 0.8693\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0608 - accuracy: 0.9846 - val_loss: 0.6333 - val_accuracy: 0.8067\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0671 - accuracy: 0.9817 - val_loss: 0.4974 - val_accuracy: 0.8467\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0674 - accuracy: 0.9811 - val_loss: 0.6139 - val_accuracy: 0.8147\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0794 - accuracy: 0.9754 - val_loss: 0.2528 - val_accuracy: 0.9133\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0825 - accuracy: 0.9771 - val_loss: 0.4151 - val_accuracy: 0.8387\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0833 - accuracy: 0.9749 - val_loss: 0.5154 - val_accuracy: 0.8213\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0588 - accuracy: 0.9846 - val_loss: 0.5872 - val_accuracy: 0.8187\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.0663 - accuracy: 0.9823 - val_loss: 0.4015 - val_accuracy: 0.8747\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0883 - accuracy: 0.9766 - val_loss: 0.2193 - val_accuracy: 0.9280\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0729 - accuracy: 0.9794 - val_loss: 0.3325 - val_accuracy: 0.8787\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0589 - accuracy: 0.9817 - val_loss: 0.4498 - val_accuracy: 0.8600\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0657 - accuracy: 0.9834 - val_loss: 0.7340 - val_accuracy: 0.8107\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0665 - accuracy: 0.9811 - val_loss: 0.6830 - val_accuracy: 0.7947\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0604 - accuracy: 0.9840 - val_loss: 0.5683 - val_accuracy: 0.8080\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0682 - accuracy: 0.9811 - val_loss: 0.6580 - val_accuracy: 0.7920\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0614 - accuracy: 0.9840 - val_loss: 0.6300 - val_accuracy: 0.7907\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0665 - accuracy: 0.9817 - val_loss: 0.2829 - val_accuracy: 0.9067\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.0603 - accuracy: 0.9851 - val_loss: 0.6123 - val_accuracy: 0.8213\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0570 - accuracy: 0.9851 - val_loss: 0.5611 - val_accuracy: 0.8280\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0747 - accuracy: 0.9766 - val_loss: 0.7408 - val_accuracy: 0.7787\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0686 - accuracy: 0.9811 - val_loss: 0.5424 - val_accuracy: 0.8320\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0739 - accuracy: 0.9794 - val_loss: 0.4356 - val_accuracy: 0.8547\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0597 - accuracy: 0.9829 - val_loss: 0.3887 - val_accuracy: 0.8680\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0638 - accuracy: 0.9834 - val_loss: 0.3618 - val_accuracy: 0.8707\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0569 - accuracy: 0.9834 - val_loss: 0.4474 - val_accuracy: 0.8400\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0746 - accuracy: 0.9806 - val_loss: 0.2278 - val_accuracy: 0.9213\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0614 - accuracy: 0.9817 - val_loss: 0.2912 - val_accuracy: 0.8973\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0681 - accuracy: 0.9800 - val_loss: 0.4481 - val_accuracy: 0.8400\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0658 - accuracy: 0.9834 - val_loss: 0.5475 - val_accuracy: 0.7773\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0788 - accuracy: 0.9777 - val_loss: 0.5139 - val_accuracy: 0.8120\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0621 - accuracy: 0.9817 - val_loss: 0.3101 - val_accuracy: 0.9067\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0678 - accuracy: 0.9789 - val_loss: 0.4880 - val_accuracy: 0.8493\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0700 - accuracy: 0.9794 - val_loss: 0.5350 - val_accuracy: 0.8573\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0536 - accuracy: 0.9834 - val_loss: 0.3487 - val_accuracy: 0.8907\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0616 - accuracy: 0.9840 - val_loss: 0.3060 - val_accuracy: 0.8893\n",
      "Epoch 199/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0598 - accuracy: 0.9846 - val_loss: 0.6510 - val_accuracy: 0.8040\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0681 - accuracy: 0.9789 - val_loss: 0.4634 - val_accuracy: 0.8613\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 5)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 51s - loss: 4.5662 - accuracy: 0.5938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0703s vs `on_train_batch_end` time: 0.8279s). Check your callbacks.\n",
      "110/110 [==============================] - 20s 180ms/step - loss: 1.1506 - accuracy: 0.7331 - val_loss: 0.8893 - val_accuracy: 0.6280\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.6625 - accuracy: 0.7823 - val_loss: 0.8548 - val_accuracy: 0.4200\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.5867 - accuracy: 0.8051 - val_loss: 1.2268 - val_accuracy: 0.5360\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.5699 - accuracy: 0.7983 - val_loss: 0.8183 - val_accuracy: 0.6720\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.4912 - accuracy: 0.8251 - val_loss: 1.0228 - val_accuracy: 0.6213\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.4851 - accuracy: 0.8217 - val_loss: 0.8207 - val_accuracy: 0.7000\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.3356 - accuracy: 0.8743 - val_loss: 1.1525 - val_accuracy: 0.6653\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.3639 - accuracy: 0.8617 - val_loss: 0.8273 - val_accuracy: 0.7093\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2884 - accuracy: 0.8943 - val_loss: 1.0106 - val_accuracy: 0.6907\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2705 - accuracy: 0.9040 - val_loss: 0.4459 - val_accuracy: 0.7627\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2579 - accuracy: 0.9091 - val_loss: 0.7707 - val_accuracy: 0.6987\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.3149 - accuracy: 0.8891 - val_loss: 0.4225 - val_accuracy: 0.8120\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2583 - accuracy: 0.9160 - val_loss: 0.7270 - val_accuracy: 0.7720\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2400 - accuracy: 0.9189 - val_loss: 0.4878 - val_accuracy: 0.7827\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2381 - accuracy: 0.9211 - val_loss: 0.6567 - val_accuracy: 0.7773\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.2156 - accuracy: 0.9291 - val_loss: 0.6240 - val_accuracy: 0.7960\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2428 - accuracy: 0.9234 - val_loss: 0.4815 - val_accuracy: 0.8040\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2088 - accuracy: 0.9343 - val_loss: 0.5393 - val_accuracy: 0.7773\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1935 - accuracy: 0.9434 - val_loss: 0.6610 - val_accuracy: 0.7907\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2028 - accuracy: 0.9429 - val_loss: 0.8530 - val_accuracy: 0.7507\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1866 - accuracy: 0.9446 - val_loss: 0.5365 - val_accuracy: 0.8173\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1734 - accuracy: 0.9520 - val_loss: 0.3583 - val_accuracy: 0.8413\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1677 - accuracy: 0.9451 - val_loss: 0.5176 - val_accuracy: 0.8240\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1420 - accuracy: 0.9571 - val_loss: 0.5291 - val_accuracy: 0.8067\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1597 - accuracy: 0.9514 - val_loss: 0.7795 - val_accuracy: 0.7640\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1378 - accuracy: 0.9589 - val_loss: 0.4553 - val_accuracy: 0.8160\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1555 - accuracy: 0.9503 - val_loss: 0.3853 - val_accuracy: 0.8387\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1461 - accuracy: 0.9554 - val_loss: 0.5757 - val_accuracy: 0.7613\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1386 - accuracy: 0.9577 - val_loss: 0.7418 - val_accuracy: 0.7427\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1420 - accuracy: 0.9583 - val_loss: 0.7293 - val_accuracy: 0.7600\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1997 - accuracy: 0.9526 - val_loss: 0.4088 - val_accuracy: 0.8093\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1584 - accuracy: 0.9554 - val_loss: 0.6109 - val_accuracy: 0.7773\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1264 - accuracy: 0.9629 - val_loss: 0.6520 - val_accuracy: 0.7680\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1332 - accuracy: 0.9594 - val_loss: 0.5192 - val_accuracy: 0.8293\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1803 - accuracy: 0.9623 - val_loss: 3.8781 - val_accuracy: 0.8933\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2102 - accuracy: 0.9509 - val_loss: 0.6220 - val_accuracy: 0.8240\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1638 - accuracy: 0.9514 - val_loss: 0.4302 - val_accuracy: 0.8347\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1421 - accuracy: 0.9594 - val_loss: 0.5195 - val_accuracy: 0.8107\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1223 - accuracy: 0.9634 - val_loss: 0.4616 - val_accuracy: 0.8373\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1364 - accuracy: 0.9571 - val_loss: 0.5046 - val_accuracy: 0.8267\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1595 - accuracy: 0.9526 - val_loss: 1.4689 - val_accuracy: 0.7947\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1230 - accuracy: 0.9646 - val_loss: 0.4705 - val_accuracy: 0.8533\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1497 - accuracy: 0.9571 - val_loss: 0.6045 - val_accuracy: 0.8453\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1284 - accuracy: 0.9594 - val_loss: 0.4865 - val_accuracy: 0.8720\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1399 - accuracy: 0.9566 - val_loss: 0.4733 - val_accuracy: 0.8667\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1314 - accuracy: 0.9577 - val_loss: 0.5076 - val_accuracy: 0.8480\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0954 - accuracy: 0.9720 - val_loss: 0.6561 - val_accuracy: 0.8360\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1268 - accuracy: 0.9600 - val_loss: 0.7781 - val_accuracy: 0.7853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1222 - accuracy: 0.9600 - val_loss: 0.7056 - val_accuracy: 0.7760\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1071 - accuracy: 0.9657 - val_loss: 0.7617 - val_accuracy: 0.7907\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1051 - accuracy: 0.9674 - val_loss: 0.6931 - val_accuracy: 0.7987\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1132 - accuracy: 0.9669 - val_loss: 0.4711 - val_accuracy: 0.8533\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1088 - accuracy: 0.9714 - val_loss: 0.5107 - val_accuracy: 0.8467\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1151 - accuracy: 0.9657 - val_loss: 0.6433 - val_accuracy: 0.7920\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1185 - accuracy: 0.9651 - val_loss: 1.1852 - val_accuracy: 0.7347\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1162 - accuracy: 0.9646 - val_loss: 1.0213 - val_accuracy: 0.7360\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1033 - accuracy: 0.9686 - val_loss: 0.6088 - val_accuracy: 0.8280\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1387 - accuracy: 0.9686 - val_loss: 0.8316 - val_accuracy: 0.7547\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1196 - accuracy: 0.9629 - val_loss: 0.7195 - val_accuracy: 0.8120\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1102 - accuracy: 0.9646 - val_loss: 1.0567 - val_accuracy: 0.7627\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1116 - accuracy: 0.9680 - val_loss: 0.6432 - val_accuracy: 0.8093\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0957 - accuracy: 0.9743 - val_loss: 0.7582 - val_accuracy: 0.7787\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1038 - accuracy: 0.9680 - val_loss: 0.5854 - val_accuracy: 0.8093\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0980 - accuracy: 0.9737 - val_loss: 0.7356 - val_accuracy: 0.7920\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1129 - accuracy: 0.9697 - val_loss: 0.6297 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1454 - accuracy: 0.9657 - val_loss: 0.6075 - val_accuracy: 0.7987\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0961 - accuracy: 0.9709 - val_loss: 0.6721 - val_accuracy: 0.7947\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1063 - accuracy: 0.9709 - val_loss: 0.8233 - val_accuracy: 0.8013\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0931 - accuracy: 0.9737 - val_loss: 0.4748 - val_accuracy: 0.8720\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0939 - accuracy: 0.9714 - val_loss: 0.7656 - val_accuracy: 0.8080\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0927 - accuracy: 0.9686 - val_loss: 0.5452 - val_accuracy: 0.8413\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1254 - accuracy: 0.9731 - val_loss: 0.7245 - val_accuracy: 0.8307\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1220 - accuracy: 0.9623 - val_loss: 0.5624 - val_accuracy: 0.7933\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1146 - accuracy: 0.9691 - val_loss: 0.6850 - val_accuracy: 0.7680\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0977 - accuracy: 0.9663 - val_loss: 0.5504 - val_accuracy: 0.8227\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1047 - accuracy: 0.9680 - val_loss: 0.8452 - val_accuracy: 0.7840\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0925 - accuracy: 0.9726 - val_loss: 0.9835 - val_accuracy: 0.7120\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0922 - accuracy: 0.9731 - val_loss: 0.4851 - val_accuracy: 0.8240\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0857 - accuracy: 0.9737 - val_loss: 0.8524 - val_accuracy: 0.7667\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0980 - accuracy: 0.9709 - val_loss: 0.4642 - val_accuracy: 0.8440\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0956 - accuracy: 0.9697 - val_loss: 0.6951 - val_accuracy: 0.8107\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0954 - accuracy: 0.9703 - val_loss: 0.6394 - val_accuracy: 0.7973\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1002 - accuracy: 0.9709 - val_loss: 0.6897 - val_accuracy: 0.7853\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0841 - accuracy: 0.9726 - val_loss: 0.7516 - val_accuracy: 0.7987\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0909 - accuracy: 0.9726 - val_loss: 0.6894 - val_accuracy: 0.8053\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1018 - accuracy: 0.9686 - val_loss: 0.6910 - val_accuracy: 0.7787\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0946 - accuracy: 0.9691 - val_loss: 0.8336 - val_accuracy: 0.7560\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0917 - accuracy: 0.9709 - val_loss: 0.7993 - val_accuracy: 0.7720\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0790 - accuracy: 0.9720 - val_loss: 0.5228 - val_accuracy: 0.8493\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0844 - accuracy: 0.9754 - val_loss: 0.8045 - val_accuracy: 0.7827\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0958 - accuracy: 0.9686 - val_loss: 0.8439 - val_accuracy: 0.7427\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0964 - accuracy: 0.9714 - val_loss: 0.7484 - val_accuracy: 0.7973\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1342 - accuracy: 0.9646 - val_loss: 1.8508 - val_accuracy: 0.7187\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1265 - accuracy: 0.9594 - val_loss: 0.5040 - val_accuracy: 0.8360\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1140 - accuracy: 0.9663 - val_loss: 0.5662 - val_accuracy: 0.7973\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0959 - accuracy: 0.9737 - val_loss: 0.7782 - val_accuracy: 0.7680\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1071 - accuracy: 0.9680 - val_loss: 0.8626 - val_accuracy: 0.7507\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0821 - accuracy: 0.9789 - val_loss: 0.5705 - val_accuracy: 0.8173\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0907 - accuracy: 0.9714 - val_loss: 0.3869 - val_accuracy: 0.8720\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0889 - accuracy: 0.9749 - val_loss: 0.6054 - val_accuracy: 0.8013\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0837 - accuracy: 0.9749 - val_loss: 0.7340 - val_accuracy: 0.8107\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1034 - accuracy: 0.9737 - val_loss: 0.8599 - val_accuracy: 0.7227\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1036 - accuracy: 0.9709 - val_loss: 1.0346 - val_accuracy: 0.6680\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0699 - accuracy: 0.9806 - val_loss: 0.6976 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0782 - accuracy: 0.9783 - val_loss: 0.9426 - val_accuracy: 0.7453\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0761 - accuracy: 0.9794 - val_loss: 0.9270 - val_accuracy: 0.7547\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0955 - accuracy: 0.9754 - val_loss: 0.6238 - val_accuracy: 0.8400\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0821 - accuracy: 0.9766 - val_loss: 1.0248 - val_accuracy: 0.7320\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0972 - accuracy: 0.9703 - val_loss: 0.6597 - val_accuracy: 0.8040\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0861 - accuracy: 0.9754 - val_loss: 0.6010 - val_accuracy: 0.8547\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0778 - accuracy: 0.9777 - val_loss: 0.4485 - val_accuracy: 0.8600\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1034 - accuracy: 0.9743 - val_loss: 1.0255 - val_accuracy: 0.7107\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1371 - accuracy: 0.9577 - val_loss: 0.8653 - val_accuracy: 0.7413\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0988 - accuracy: 0.9714 - val_loss: 0.6335 - val_accuracy: 0.8120\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0905 - accuracy: 0.9731 - val_loss: 0.6324 - val_accuracy: 0.7933\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0930 - accuracy: 0.9731 - val_loss: 0.4854 - val_accuracy: 0.8387\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0837 - accuracy: 0.9731 - val_loss: 0.4822 - val_accuracy: 0.8400\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0887 - accuracy: 0.9794 - val_loss: 0.8152 - val_accuracy: 0.7853\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0947 - accuracy: 0.9714 - val_loss: 0.7945 - val_accuracy: 0.7600\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0792 - accuracy: 0.9754 - val_loss: 0.8770 - val_accuracy: 0.7427\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0765 - accuracy: 0.9794 - val_loss: 0.9295 - val_accuracy: 0.7613\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0666 - accuracy: 0.9806 - val_loss: 0.8157 - val_accuracy: 0.7693\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0899 - accuracy: 0.9731 - val_loss: 0.7962 - val_accuracy: 0.7720\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0748 - accuracy: 0.9766 - val_loss: 0.9808 - val_accuracy: 0.7507\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0606 - accuracy: 0.9840 - val_loss: 0.8047 - val_accuracy: 0.7880\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0717 - accuracy: 0.9794 - val_loss: 0.6651 - val_accuracy: 0.8093\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0809 - accuracy: 0.9771 - val_loss: 0.8523 - val_accuracy: 0.7627\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0645 - accuracy: 0.9811 - val_loss: 0.9454 - val_accuracy: 0.7760\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0655 - accuracy: 0.9817 - val_loss: 0.9571 - val_accuracy: 0.7613\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0755 - accuracy: 0.9777 - val_loss: 0.8659 - val_accuracy: 0.7960\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0757 - accuracy: 0.9760 - val_loss: 0.6300 - val_accuracy: 0.8067\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0689 - accuracy: 0.9811 - val_loss: 0.6492 - val_accuracy: 0.8053\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0871 - accuracy: 0.9806 - val_loss: 0.8718 - val_accuracy: 0.7680\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0829 - accuracy: 0.9783 - val_loss: 0.6485 - val_accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0660 - accuracy: 0.9834 - val_loss: 0.4833 - val_accuracy: 0.8533\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0674 - accuracy: 0.9783 - val_loss: 1.0006 - val_accuracy: 0.7760\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0699 - accuracy: 0.9800 - val_loss: 0.5996 - val_accuracy: 0.8360\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0703 - accuracy: 0.9783 - val_loss: 0.3614 - val_accuracy: 0.8867\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0725 - accuracy: 0.9771 - val_loss: 0.5387 - val_accuracy: 0.8400\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0734 - accuracy: 0.9771 - val_loss: 0.5717 - val_accuracy: 0.8173\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0664 - accuracy: 0.9811 - val_loss: 0.7004 - val_accuracy: 0.8240\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0861 - accuracy: 0.9777 - val_loss: 0.8923 - val_accuracy: 0.7547\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0753 - accuracy: 0.9777 - val_loss: 0.6938 - val_accuracy: 0.7973\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0793 - accuracy: 0.9789 - val_loss: 0.6998 - val_accuracy: 0.8173\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0608 - accuracy: 0.9823 - val_loss: 0.9031 - val_accuracy: 0.7547\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0654 - accuracy: 0.9811 - val_loss: 0.5559 - val_accuracy: 0.8400\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0629 - accuracy: 0.9851 - val_loss: 1.0806 - val_accuracy: 0.7667\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0775 - accuracy: 0.9737 - val_loss: 0.9313 - val_accuracy: 0.7760\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0797 - accuracy: 0.9794 - val_loss: 0.6193 - val_accuracy: 0.8053\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0746 - accuracy: 0.9794 - val_loss: 0.5742 - val_accuracy: 0.8173\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0782 - accuracy: 0.9811 - val_loss: 0.6415 - val_accuracy: 0.8013\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0754 - accuracy: 0.9766 - val_loss: 0.3176 - val_accuracy: 0.8840\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0763 - accuracy: 0.9777 - val_loss: 0.4457 - val_accuracy: 0.8520\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0610 - accuracy: 0.9800 - val_loss: 0.5391 - val_accuracy: 0.8507\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0615 - accuracy: 0.9817 - val_loss: 0.4316 - val_accuracy: 0.8467\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0751 - accuracy: 0.9783 - val_loss: 0.6042 - val_accuracy: 0.7773\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0811 - accuracy: 0.9829 - val_loss: 0.6470 - val_accuracy: 0.7893\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1167 - accuracy: 0.9606 - val_loss: 0.3756 - val_accuracy: 0.8733\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1039 - accuracy: 0.9669 - val_loss: 0.4981 - val_accuracy: 0.8413\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0750 - accuracy: 0.9800 - val_loss: 0.6346 - val_accuracy: 0.8120\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0782 - accuracy: 0.9806 - val_loss: 0.8415 - val_accuracy: 0.7493\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0769 - accuracy: 0.9794 - val_loss: 0.5098 - val_accuracy: 0.8267\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0675 - accuracy: 0.9783 - val_loss: 0.5773 - val_accuracy: 0.8120\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0636 - accuracy: 0.9829 - val_loss: 0.4795 - val_accuracy: 0.8293\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0577 - accuracy: 0.9840 - val_loss: 0.8295 - val_accuracy: 0.7733\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0619 - accuracy: 0.9823 - val_loss: 0.7695 - val_accuracy: 0.7893\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0568 - accuracy: 0.9840 - val_loss: 0.8201 - val_accuracy: 0.7800\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0613 - accuracy: 0.9829 - val_loss: 0.9049 - val_accuracy: 0.7653\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0624 - accuracy: 0.9823 - val_loss: 0.6423 - val_accuracy: 0.8040\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0526 - accuracy: 0.9874 - val_loss: 0.6514 - val_accuracy: 0.7880\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0800 - accuracy: 0.9766 - val_loss: 0.6918 - val_accuracy: 0.8053\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0643 - accuracy: 0.9829 - val_loss: 0.6052 - val_accuracy: 0.8187\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0680 - accuracy: 0.9817 - val_loss: 0.5675 - val_accuracy: 0.8280\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0738 - accuracy: 0.9789 - val_loss: 0.8107 - val_accuracy: 0.7520\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0629 - accuracy: 0.9817 - val_loss: 0.4450 - val_accuracy: 0.8227\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0526 - accuracy: 0.9857 - val_loss: 0.5844 - val_accuracy: 0.8013\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0790 - accuracy: 0.9863 - val_loss: 0.7897 - val_accuracy: 0.7747\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0678 - accuracy: 0.9829 - val_loss: 0.9344 - val_accuracy: 0.7493\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0554 - accuracy: 0.9851 - val_loss: 0.8240 - val_accuracy: 0.7920\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0630 - accuracy: 0.9840 - val_loss: 0.6264 - val_accuracy: 0.8040\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0535 - accuracy: 0.9851 - val_loss: 0.9522 - val_accuracy: 0.7600\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0645 - accuracy: 0.9794 - val_loss: 0.9935 - val_accuracy: 0.7507\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0532 - accuracy: 0.9834 - val_loss: 0.6775 - val_accuracy: 0.8080\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0623 - accuracy: 0.9834 - val_loss: 0.4570 - val_accuracy: 0.8373\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0636 - accuracy: 0.9834 - val_loss: 0.5132 - val_accuracy: 0.8253\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0519 - accuracy: 0.9874 - val_loss: 0.7156 - val_accuracy: 0.8040\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0656 - accuracy: 0.9811 - val_loss: 0.7196 - val_accuracy: 0.7867\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0528 - accuracy: 0.9846 - val_loss: 0.7980 - val_accuracy: 0.7600\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0661 - accuracy: 0.9789 - val_loss: 0.7407 - val_accuracy: 0.7813\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0704 - accuracy: 0.9800 - val_loss: 0.4748 - val_accuracy: 0.8293\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0563 - accuracy: 0.9806 - val_loss: 0.7058 - val_accuracy: 0.7680\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0679 - accuracy: 0.9823 - val_loss: 0.4180 - val_accuracy: 0.8267\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0609 - accuracy: 0.9834 - val_loss: 0.5882 - val_accuracy: 0.8160\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0534 - accuracy: 0.9834 - val_loss: 0.6195 - val_accuracy: 0.8333\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0656 - accuracy: 0.9811 - val_loss: 0.9192 - val_accuracy: 0.7227\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0683 - accuracy: 0.9834 - val_loss: 0.6987 - val_accuracy: 0.7573\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0786 - accuracy: 0.9766 - val_loss: 0.5073 - val_accuracy: 0.8280\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0634 - accuracy: 0.9823 - val_loss: 0.3607 - val_accuracy: 0.8720\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0888 - accuracy: 0.9789 - val_loss: 0.7742 - val_accuracy: 0.7733\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1153 - accuracy: 0.9754 - val_loss: 1.1549 - val_accuracy: 0.7120\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 5)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 49s - loss: 1.8547 - accuracy: 0.5000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0871s vs `on_train_batch_end` time: 0.7655s). Check your callbacks.\n",
      "110/110 [==============================] - 20s 180ms/step - loss: 0.8448 - accuracy: 0.7240 - val_loss: 0.8087 - val_accuracy: 0.3720\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.5688 - accuracy: 0.7971 - val_loss: 0.8822 - val_accuracy: 0.4200\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.4939 - accuracy: 0.8166 - val_loss: 0.6435 - val_accuracy: 0.6107\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.4762 - accuracy: 0.8223 - val_loss: 0.7530 - val_accuracy: 0.7027\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.4502 - accuracy: 0.8320 - val_loss: 0.9582 - val_accuracy: 0.7707\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.4114 - accuracy: 0.8611 - val_loss: 2.3547 - val_accuracy: 0.7747\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.4726 - accuracy: 0.8320 - val_loss: 3.0098 - val_accuracy: 0.7933\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.4148 - accuracy: 0.8423 - val_loss: 4.3995 - val_accuracy: 0.7373\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 163ms/step - loss: 0.4373 - accuracy: 0.8446 - val_loss: 1.9536 - val_accuracy: 0.7373\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.4720 - accuracy: 0.8240 - val_loss: 1.7882 - val_accuracy: 0.7640\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.3864 - accuracy: 0.8560 - val_loss: 1.2486 - val_accuracy: 0.7600\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.4155 - accuracy: 0.8514 - val_loss: 0.7939 - val_accuracy: 0.7627\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.4270 - accuracy: 0.8423 - val_loss: 1.1277 - val_accuracy: 0.7960\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.3778 - accuracy: 0.8549 - val_loss: 0.7511 - val_accuracy: 0.8293\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.3660 - accuracy: 0.8526 - val_loss: 1.6315 - val_accuracy: 0.7173\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.4174 - accuracy: 0.8554 - val_loss: 1.0770 - val_accuracy: 0.7560\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.3707 - accuracy: 0.8680 - val_loss: 1.3193 - val_accuracy: 0.7667\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.3435 - accuracy: 0.8726 - val_loss: 0.9534 - val_accuracy: 0.7653\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.3603 - accuracy: 0.8766 - val_loss: 0.5624 - val_accuracy: 0.7747\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.3578 - accuracy: 0.8611 - val_loss: 1.2846 - val_accuracy: 0.8200\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.3921 - accuracy: 0.8634 - val_loss: 0.9814 - val_accuracy: 0.7800\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.3850 - accuracy: 0.8714 - val_loss: 0.9265 - val_accuracy: 0.7733\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.3445 - accuracy: 0.8851 - val_loss: 0.6506 - val_accuracy: 0.7933\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.3120 - accuracy: 0.8829 - val_loss: 1.0087 - val_accuracy: 0.8120\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.3597 - accuracy: 0.8606 - val_loss: 0.7056 - val_accuracy: 0.7813\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.3271 - accuracy: 0.8863 - val_loss: 0.6939 - val_accuracy: 0.8240\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2987 - accuracy: 0.8880 - val_loss: 0.5641 - val_accuracy: 0.8133\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2981 - accuracy: 0.8840 - val_loss: 0.7798 - val_accuracy: 0.8040\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.3662 - accuracy: 0.8737 - val_loss: 0.8993 - val_accuracy: 0.7867\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.3386 - accuracy: 0.8789 - val_loss: 0.7508 - val_accuracy: 0.8360\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.3695 - accuracy: 0.8726 - val_loss: 0.4168 - val_accuracy: 0.8267\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.3412 - accuracy: 0.8851 - val_loss: 0.7237 - val_accuracy: 0.7387\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.3098 - accuracy: 0.8920 - val_loss: 1.0281 - val_accuracy: 0.8120\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.3301 - accuracy: 0.8714 - val_loss: 0.7027 - val_accuracy: 0.8013\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.3267 - accuracy: 0.8891 - val_loss: 1.1269 - val_accuracy: 0.7827\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.3040 - accuracy: 0.8886 - val_loss: 0.7667 - val_accuracy: 0.7733\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2820 - accuracy: 0.8857 - val_loss: 0.8614 - val_accuracy: 0.7827\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.3053 - accuracy: 0.8926 - val_loss: 1.5574 - val_accuracy: 0.8040\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2614 - accuracy: 0.9057 - val_loss: 0.8336 - val_accuracy: 0.8160\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2739 - accuracy: 0.8931 - val_loss: 0.7256 - val_accuracy: 0.8000\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.2847 - accuracy: 0.8971 - val_loss: 0.6972 - val_accuracy: 0.7867\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2641 - accuracy: 0.9023 - val_loss: 0.7603 - val_accuracy: 0.7653\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2765 - accuracy: 0.8909 - val_loss: 0.7142 - val_accuracy: 0.8027\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2688 - accuracy: 0.9006 - val_loss: 0.6782 - val_accuracy: 0.8027\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2677 - accuracy: 0.9091 - val_loss: 0.6424 - val_accuracy: 0.7893\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2825 - accuracy: 0.9034 - val_loss: 0.7146 - val_accuracy: 0.7987\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2544 - accuracy: 0.9069 - val_loss: 1.2921 - val_accuracy: 0.8080\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2515 - accuracy: 0.9023 - val_loss: 1.2830 - val_accuracy: 0.8267\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2836 - accuracy: 0.9126 - val_loss: 3.4058 - val_accuracy: 0.8453\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2587 - accuracy: 0.9080 - val_loss: 5.9640 - val_accuracy: 0.8240\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2612 - accuracy: 0.9137 - val_loss: 2.2064 - val_accuracy: 0.8400\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2299 - accuracy: 0.9160 - val_loss: 1.3807 - val_accuracy: 0.8600\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2484 - accuracy: 0.9183 - val_loss: 1.7129 - val_accuracy: 0.8427\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2594 - accuracy: 0.9189 - val_loss: 0.9586 - val_accuracy: 0.8547\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2383 - accuracy: 0.9229 - val_loss: 0.5919 - val_accuracy: 0.8573\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2337 - accuracy: 0.9211 - val_loss: 0.5653 - val_accuracy: 0.8373\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2245 - accuracy: 0.9251 - val_loss: 1.0807 - val_accuracy: 0.8440\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2396 - accuracy: 0.9149 - val_loss: 0.6934 - val_accuracy: 0.8627\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2226 - accuracy: 0.9211 - val_loss: 0.8225 - val_accuracy: 0.7973\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2006 - accuracy: 0.9297 - val_loss: 0.6294 - val_accuracy: 0.8720\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2190 - accuracy: 0.9234 - val_loss: 0.9318 - val_accuracy: 0.8440\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2004 - accuracy: 0.9269 - val_loss: 1.0208 - val_accuracy: 0.8507\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2277 - accuracy: 0.9371 - val_loss: 0.6295 - val_accuracy: 0.8280\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2020 - accuracy: 0.9343 - val_loss: 0.9058 - val_accuracy: 0.8227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1991 - accuracy: 0.9326 - val_loss: 0.6097 - val_accuracy: 0.8373\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1963 - accuracy: 0.9349 - val_loss: 1.0989 - val_accuracy: 0.8427\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2385 - accuracy: 0.9297 - val_loss: 0.8725 - val_accuracy: 0.8293\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1874 - accuracy: 0.9423 - val_loss: 1.2799 - val_accuracy: 0.7893\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1887 - accuracy: 0.9400 - val_loss: 1.2701 - val_accuracy: 0.8280\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2086 - accuracy: 0.9280 - val_loss: 1.6398 - val_accuracy: 0.8067\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1952 - accuracy: 0.9360 - val_loss: 0.9260 - val_accuracy: 0.8733\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1810 - accuracy: 0.9451 - val_loss: 1.0337 - val_accuracy: 0.8400\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1609 - accuracy: 0.9486 - val_loss: 1.5018 - val_accuracy: 0.8480\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2169 - accuracy: 0.9343 - val_loss: 1.5569 - val_accuracy: 0.8133\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1710 - accuracy: 0.9434 - val_loss: 1.4640 - val_accuracy: 0.8187\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1858 - accuracy: 0.9411 - val_loss: 2.1767 - val_accuracy: 0.8147\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1872 - accuracy: 0.9423 - val_loss: 0.9033 - val_accuracy: 0.7867\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1786 - accuracy: 0.9371 - val_loss: 0.5890 - val_accuracy: 0.8373\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1525 - accuracy: 0.9520 - val_loss: 0.8119 - val_accuracy: 0.8173\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1599 - accuracy: 0.9514 - val_loss: 0.5433 - val_accuracy: 0.8413\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1659 - accuracy: 0.9509 - val_loss: 0.6905 - val_accuracy: 0.8360\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2030 - accuracy: 0.9366 - val_loss: 0.9226 - val_accuracy: 0.8067\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1675 - accuracy: 0.9469 - val_loss: 0.4905 - val_accuracy: 0.8480\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1503 - accuracy: 0.9543 - val_loss: 0.8592 - val_accuracy: 0.8053\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1670 - accuracy: 0.9463 - val_loss: 1.1308 - val_accuracy: 0.7853\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1657 - accuracy: 0.9446 - val_loss: 0.9947 - val_accuracy: 0.8147\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1643 - accuracy: 0.9486 - val_loss: 0.8186 - val_accuracy: 0.8213\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1509 - accuracy: 0.9520 - val_loss: 0.8607 - val_accuracy: 0.8120\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1678 - accuracy: 0.9560 - val_loss: 0.6485 - val_accuracy: 0.8267\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1568 - accuracy: 0.9480 - val_loss: 0.7489 - val_accuracy: 0.8760\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1728 - accuracy: 0.9491 - val_loss: 0.9821 - val_accuracy: 0.8293\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1428 - accuracy: 0.9543 - val_loss: 0.9858 - val_accuracy: 0.8400\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1476 - accuracy: 0.9526 - val_loss: 0.7070 - val_accuracy: 0.8467\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1369 - accuracy: 0.9571 - val_loss: 0.9791 - val_accuracy: 0.8360\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1387 - accuracy: 0.9623 - val_loss: 0.8628 - val_accuracy: 0.8400\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1610 - accuracy: 0.9531 - val_loss: 0.9878 - val_accuracy: 0.8427\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1566 - accuracy: 0.9560 - val_loss: 1.2824 - val_accuracy: 0.8253\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1639 - accuracy: 0.9514 - val_loss: 0.8998 - val_accuracy: 0.8227\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1759 - accuracy: 0.9509 - val_loss: 1.1638 - val_accuracy: 0.8320\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1496 - accuracy: 0.9543 - val_loss: 1.3093 - val_accuracy: 0.8080\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1375 - accuracy: 0.9583 - val_loss: 1.1639 - val_accuracy: 0.7840\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1525 - accuracy: 0.9526 - val_loss: 1.4068 - val_accuracy: 0.8040\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1458 - accuracy: 0.9566 - val_loss: 1.4640 - val_accuracy: 0.7973\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1511 - accuracy: 0.9600 - val_loss: 1.2272 - val_accuracy: 0.8400\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1335 - accuracy: 0.9606 - val_loss: 1.3837 - val_accuracy: 0.8240\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1334 - accuracy: 0.9646 - val_loss: 1.2864 - val_accuracy: 0.8360\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1390 - accuracy: 0.9549 - val_loss: 1.1525 - val_accuracy: 0.8453\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1373 - accuracy: 0.9583 - val_loss: 1.2430 - val_accuracy: 0.8133\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1298 - accuracy: 0.9606 - val_loss: 0.9490 - val_accuracy: 0.8467\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1525 - accuracy: 0.9600 - val_loss: 1.6721 - val_accuracy: 0.8227\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1310 - accuracy: 0.9617 - val_loss: 1.8216 - val_accuracy: 0.8240\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1302 - accuracy: 0.9634 - val_loss: 0.9360 - val_accuracy: 0.8320\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1416 - accuracy: 0.9531 - val_loss: 1.1975 - val_accuracy: 0.7760\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1211 - accuracy: 0.9606 - val_loss: 0.7668 - val_accuracy: 0.8307\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1283 - accuracy: 0.9600 - val_loss: 1.1786 - val_accuracy: 0.8133\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1257 - accuracy: 0.9629 - val_loss: 1.4301 - val_accuracy: 0.7867\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1348 - accuracy: 0.9594 - val_loss: 1.8636 - val_accuracy: 0.8293\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1173 - accuracy: 0.9606 - val_loss: 1.7610 - val_accuracy: 0.8307\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1292 - accuracy: 0.9577 - val_loss: 1.3396 - val_accuracy: 0.8413\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1443 - accuracy: 0.9594 - val_loss: 0.8485 - val_accuracy: 0.8000\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1506 - accuracy: 0.9514 - val_loss: 1.0576 - val_accuracy: 0.7667\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1137 - accuracy: 0.9646 - val_loss: 1.3596 - val_accuracy: 0.7867\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1178 - accuracy: 0.9651 - val_loss: 0.9613 - val_accuracy: 0.8227\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1158 - accuracy: 0.9646 - val_loss: 0.9194 - val_accuracy: 0.8347\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1203 - accuracy: 0.9629 - val_loss: 1.1628 - val_accuracy: 0.7920\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1147 - accuracy: 0.9651 - val_loss: 1.2383 - val_accuracy: 0.8173\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1207 - accuracy: 0.9634 - val_loss: 1.0003 - val_accuracy: 0.8173\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1273 - accuracy: 0.9611 - val_loss: 1.4619 - val_accuracy: 0.8187\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1078 - accuracy: 0.9651 - val_loss: 0.6840 - val_accuracy: 0.8213\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1101 - accuracy: 0.9674 - val_loss: 0.6809 - val_accuracy: 0.8400\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1270 - accuracy: 0.9634 - val_loss: 1.1103 - val_accuracy: 0.7827\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1175 - accuracy: 0.9640 - val_loss: 1.1258 - val_accuracy: 0.7907\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1303 - accuracy: 0.9617 - val_loss: 1.0205 - val_accuracy: 0.8293\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1165 - accuracy: 0.9691 - val_loss: 0.8896 - val_accuracy: 0.8027\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1007 - accuracy: 0.9703 - val_loss: 1.0514 - val_accuracy: 0.8267\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1464 - accuracy: 0.9589 - val_loss: 1.2991 - val_accuracy: 0.8320\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1013 - accuracy: 0.9674 - val_loss: 0.8580 - val_accuracy: 0.8427\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1113 - accuracy: 0.9669 - val_loss: 0.7486 - val_accuracy: 0.8360\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1059 - accuracy: 0.9691 - val_loss: 0.7057 - val_accuracy: 0.8400\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1112 - accuracy: 0.9680 - val_loss: 1.0648 - val_accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1134 - accuracy: 0.9657 - val_loss: 0.7829 - val_accuracy: 0.8413\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0969 - accuracy: 0.9709 - val_loss: 0.8773 - val_accuracy: 0.8267\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0956 - accuracy: 0.9691 - val_loss: 1.2044 - val_accuracy: 0.8280\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1105 - accuracy: 0.9686 - val_loss: 1.2163 - val_accuracy: 0.8213\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1032 - accuracy: 0.9657 - val_loss: 1.0089 - val_accuracy: 0.8240\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1058 - accuracy: 0.9674 - val_loss: 0.9248 - val_accuracy: 0.8347\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1613 - accuracy: 0.9611 - val_loss: 1.2555 - val_accuracy: 0.8013\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0976 - accuracy: 0.9686 - val_loss: 0.7880 - val_accuracy: 0.8360\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1159 - accuracy: 0.9606 - val_loss: 0.9629 - val_accuracy: 0.8173\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1065 - accuracy: 0.9657 - val_loss: 0.8011 - val_accuracy: 0.7947\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1447 - accuracy: 0.9669 - val_loss: 0.8593 - val_accuracy: 0.8000\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1063 - accuracy: 0.9674 - val_loss: 0.6711 - val_accuracy: 0.8107\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0999 - accuracy: 0.9691 - val_loss: 0.9027 - val_accuracy: 0.7907\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0958 - accuracy: 0.9720 - val_loss: 0.7787 - val_accuracy: 0.8120\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0984 - accuracy: 0.9709 - val_loss: 0.6710 - val_accuracy: 0.8173\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1080 - accuracy: 0.9669 - val_loss: 0.5986 - val_accuracy: 0.8293\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1103 - accuracy: 0.9691 - val_loss: 0.7540 - val_accuracy: 0.8053\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0940 - accuracy: 0.9726 - val_loss: 0.6985 - val_accuracy: 0.8213\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1046 - accuracy: 0.9697 - val_loss: 0.9850 - val_accuracy: 0.7880\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0981 - accuracy: 0.9703 - val_loss: 0.6903 - val_accuracy: 0.8133\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1004 - accuracy: 0.9663 - val_loss: 0.9382 - val_accuracy: 0.8067\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1120 - accuracy: 0.9680 - val_loss: 0.7565 - val_accuracy: 0.8013\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0874 - accuracy: 0.9731 - val_loss: 0.9386 - val_accuracy: 0.7973\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1144 - accuracy: 0.9634 - val_loss: 0.7534 - val_accuracy: 0.8160\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1037 - accuracy: 0.9709 - val_loss: 0.8333 - val_accuracy: 0.8187\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0985 - accuracy: 0.9731 - val_loss: 0.8044 - val_accuracy: 0.8213\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1077 - accuracy: 0.9663 - val_loss: 0.9991 - val_accuracy: 0.8120\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0954 - accuracy: 0.9697 - val_loss: 0.8381 - val_accuracy: 0.8213\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0917 - accuracy: 0.9731 - val_loss: 0.6940 - val_accuracy: 0.8400\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0790 - accuracy: 0.9737 - val_loss: 0.8132 - val_accuracy: 0.8107\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0943 - accuracy: 0.9726 - val_loss: 0.8341 - val_accuracy: 0.7920\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0910 - accuracy: 0.9743 - val_loss: 0.9577 - val_accuracy: 0.8093\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0958 - accuracy: 0.9714 - val_loss: 1.0286 - val_accuracy: 0.8040\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0978 - accuracy: 0.9720 - val_loss: 0.7876 - val_accuracy: 0.8507\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1328 - accuracy: 0.9749 - val_loss: 0.9074 - val_accuracy: 0.7907\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1087 - accuracy: 0.9691 - val_loss: 0.9776 - val_accuracy: 0.7947\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0919 - accuracy: 0.9737 - val_loss: 0.8417 - val_accuracy: 0.8120\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0896 - accuracy: 0.9726 - val_loss: 0.9030 - val_accuracy: 0.8067\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0889 - accuracy: 0.9720 - val_loss: 0.7309 - val_accuracy: 0.8080\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0830 - accuracy: 0.9720 - val_loss: 0.7924 - val_accuracy: 0.8040\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0729 - accuracy: 0.9771 - val_loss: 0.9216 - val_accuracy: 0.8040\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1001 - accuracy: 0.9674 - val_loss: 0.7584 - val_accuracy: 0.7973\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0922 - accuracy: 0.9726 - val_loss: 0.8759 - val_accuracy: 0.7880\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0761 - accuracy: 0.9777 - val_loss: 0.8750 - val_accuracy: 0.8107\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0986 - accuracy: 0.9714 - val_loss: 0.8436 - val_accuracy: 0.8160\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1137 - accuracy: 0.9669 - val_loss: 0.5867 - val_accuracy: 0.8280\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0777 - accuracy: 0.9766 - val_loss: 0.6467 - val_accuracy: 0.8307\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0831 - accuracy: 0.9760 - val_loss: 0.7510 - val_accuracy: 0.8280\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0962 - accuracy: 0.9709 - val_loss: 0.6858 - val_accuracy: 0.8227\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0821 - accuracy: 0.9743 - val_loss: 0.5562 - val_accuracy: 0.8413\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0865 - accuracy: 0.9743 - val_loss: 0.7885 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0732 - accuracy: 0.9749 - val_loss: 0.6007 - val_accuracy: 0.8600\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0876 - accuracy: 0.9714 - val_loss: 0.9536 - val_accuracy: 0.8280\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1017 - accuracy: 0.9726 - val_loss: 0.7871 - val_accuracy: 0.8280\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0815 - accuracy: 0.9754 - val_loss: 0.7426 - val_accuracy: 0.8293\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1363 - accuracy: 0.9674 - val_loss: 0.5703 - val_accuracy: 0.8640\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1033 - accuracy: 0.9629 - val_loss: 0.8617 - val_accuracy: 0.8173\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0959 - accuracy: 0.9737 - val_loss: 0.6023 - val_accuracy: 0.8213\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0837 - accuracy: 0.9743 - val_loss: 0.6057 - val_accuracy: 0.8293\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0900 - accuracy: 0.9731 - val_loss: 0.5551 - val_accuracy: 0.8360\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 1)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 49s - loss: 5.3480 - accuracy: 0.5625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0760s vs `on_train_batch_end` time: 0.7810s). Check your callbacks.\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 1.3034 - accuracy: 0.6983 - val_loss: 0.6615 - val_accuracy: 0.6280\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.6608 - accuracy: 0.7646 - val_loss: 1.8218 - val_accuracy: 0.3720\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.6153 - accuracy: 0.7566 - val_loss: 4.9842 - val_accuracy: 0.3733\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.4492 - accuracy: 0.8143 - val_loss: 1.4101 - val_accuracy: 0.5867\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.3607 - accuracy: 0.8474 - val_loss: 0.7217 - val_accuracy: 0.7707\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.3350 - accuracy: 0.8714 - val_loss: 43.2310 - val_accuracy: 0.8973\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3567 - accuracy: 0.8920 - val_loss: 0.4265 - val_accuracy: 0.9213\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2649 - accuracy: 0.9023 - val_loss: 0.2461 - val_accuracy: 0.9040\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2894 - accuracy: 0.9023 - val_loss: 0.4377 - val_accuracy: 0.8307\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2361 - accuracy: 0.9171 - val_loss: 0.4082 - val_accuracy: 0.8613\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.2424 - accuracy: 0.9166 - val_loss: 0.2164 - val_accuracy: 0.9120\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2259 - accuracy: 0.9149 - val_loss: 0.3782 - val_accuracy: 0.8720\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2176 - accuracy: 0.9269 - val_loss: 0.3266 - val_accuracy: 0.8600\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1954 - accuracy: 0.9411 - val_loss: 0.1888 - val_accuracy: 0.9280\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2042 - accuracy: 0.9286 - val_loss: 3.4981 - val_accuracy: 0.8560\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.2081 - accuracy: 0.9309 - val_loss: 0.3500 - val_accuracy: 0.8773\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2045 - accuracy: 0.9291 - val_loss: 0.4268 - val_accuracy: 0.8733\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.2429 - accuracy: 0.9263 - val_loss: 0.2602 - val_accuracy: 0.9027\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1968 - accuracy: 0.9337 - val_loss: 0.2888 - val_accuracy: 0.9040\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2267 - accuracy: 0.9303 - val_loss: 0.5732 - val_accuracy: 0.7987\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.2165 - accuracy: 0.9263 - val_loss: 0.2869 - val_accuracy: 0.8907\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2058 - accuracy: 0.9274 - val_loss: 0.2817 - val_accuracy: 0.9013\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2014 - accuracy: 0.9423 - val_loss: 0.3719 - val_accuracy: 0.8733\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2122 - accuracy: 0.9280 - val_loss: 0.3020 - val_accuracy: 0.9227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1851 - accuracy: 0.9400 - val_loss: 0.2095 - val_accuracy: 0.9240\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1755 - accuracy: 0.9491 - val_loss: 0.3242 - val_accuracy: 0.8787\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.2286 - accuracy: 0.9423 - val_loss: 114.1220 - val_accuracy: 0.6773\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2562 - accuracy: 0.9046 - val_loss: 0.5194 - val_accuracy: 0.8827\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2252 - accuracy: 0.9240 - val_loss: 0.2826 - val_accuracy: 0.8920\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2368 - accuracy: 0.9240 - val_loss: 0.2432 - val_accuracy: 0.9147\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.2081 - accuracy: 0.9360 - val_loss: 0.2417 - val_accuracy: 0.9093\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.2008 - accuracy: 0.9429 - val_loss: 0.2647 - val_accuracy: 0.8973\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1881 - accuracy: 0.9366 - val_loss: 0.2858 - val_accuracy: 0.9040\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1819 - accuracy: 0.9417 - val_loss: 0.1829 - val_accuracy: 0.9360\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1691 - accuracy: 0.9457 - val_loss: 0.1937 - val_accuracy: 0.9333\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1584 - accuracy: 0.9520 - val_loss: 0.1789 - val_accuracy: 0.9373\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1546 - accuracy: 0.9480 - val_loss: 0.2767 - val_accuracy: 0.9133\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1793 - accuracy: 0.9394 - val_loss: 0.2696 - val_accuracy: 0.9133\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.1469 - accuracy: 0.9526 - val_loss: 0.1870 - val_accuracy: 0.9320\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1732 - accuracy: 0.9566 - val_loss: 0.2454 - val_accuracy: 0.9187\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1520 - accuracy: 0.9589 - val_loss: 0.2317 - val_accuracy: 0.9173\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1546 - accuracy: 0.9486 - val_loss: 0.3313 - val_accuracy: 0.8920\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1468 - accuracy: 0.9514 - val_loss: 0.1857 - val_accuracy: 0.9320\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1599 - accuracy: 0.9491 - val_loss: 0.2542 - val_accuracy: 0.9173\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1467 - accuracy: 0.9531 - val_loss: 0.1939 - val_accuracy: 0.9280\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1615 - accuracy: 0.9509 - val_loss: 0.1917 - val_accuracy: 0.9320\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1486 - accuracy: 0.9571 - val_loss: 0.1651 - val_accuracy: 0.9440\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1365 - accuracy: 0.9589 - val_loss: 0.1638 - val_accuracy: 0.9453\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1838 - accuracy: 0.9377 - val_loss: 0.2340 - val_accuracy: 0.9093\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1533 - accuracy: 0.9554 - val_loss: 0.1930 - val_accuracy: 0.9373\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1594 - accuracy: 0.9526 - val_loss: 0.2439 - val_accuracy: 0.9120\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1500 - accuracy: 0.9520 - val_loss: 0.2203 - val_accuracy: 0.9240\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1471 - accuracy: 0.9526 - val_loss: 0.2005 - val_accuracy: 0.9333\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1419 - accuracy: 0.9549 - val_loss: 0.1950 - val_accuracy: 0.9373\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1398 - accuracy: 0.9589 - val_loss: 0.2319 - val_accuracy: 0.9267\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1418 - accuracy: 0.9537 - val_loss: 0.1583 - val_accuracy: 0.9507\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1561 - accuracy: 0.9491 - val_loss: 0.2896 - val_accuracy: 0.8880\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1968 - accuracy: 0.9417 - val_loss: 0.1942 - val_accuracy: 0.9360\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1604 - accuracy: 0.9491 - val_loss: 0.2179 - val_accuracy: 0.9213\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2256 - accuracy: 0.9320 - val_loss: 0.1866 - val_accuracy: 0.9440\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.2494 - accuracy: 0.9114 - val_loss: 0.4252 - val_accuracy: 0.8747\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2418 - accuracy: 0.9251 - val_loss: 0.2529 - val_accuracy: 0.9160\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1644 - accuracy: 0.9509 - val_loss: 0.2946 - val_accuracy: 0.9187\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1496 - accuracy: 0.9531 - val_loss: 0.7326 - val_accuracy: 0.9187\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1646 - accuracy: 0.9446 - val_loss: 0.2457 - val_accuracy: 0.9187\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1653 - accuracy: 0.9543 - val_loss: 0.2347 - val_accuracy: 0.9120\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1365 - accuracy: 0.9514 - val_loss: 0.1915 - val_accuracy: 0.9373\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1383 - accuracy: 0.9577 - val_loss: 0.2182 - val_accuracy: 0.9147\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1414 - accuracy: 0.9571 - val_loss: 0.2020 - val_accuracy: 0.9267\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1446 - accuracy: 0.9549 - val_loss: 0.1789 - val_accuracy: 0.9400\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1592 - accuracy: 0.9514 - val_loss: 0.1865 - val_accuracy: 0.9307\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1432 - accuracy: 0.9583 - val_loss: 0.2735 - val_accuracy: 0.8907\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1441 - accuracy: 0.9594 - val_loss: 0.1832 - val_accuracy: 0.9333\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1370 - accuracy: 0.9577 - val_loss: 0.1881 - val_accuracy: 0.9333\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1392 - accuracy: 0.9554 - val_loss: 0.1862 - val_accuracy: 0.9387\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1269 - accuracy: 0.9606 - val_loss: 0.1963 - val_accuracy: 0.9360\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1271 - accuracy: 0.9680 - val_loss: 0.2509 - val_accuracy: 0.9187\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1612 - accuracy: 0.9623 - val_loss: 0.1903 - val_accuracy: 0.9373\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1333 - accuracy: 0.9611 - val_loss: 0.1566 - val_accuracy: 0.9547\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1613 - accuracy: 0.9531 - val_loss: 0.2213 - val_accuracy: 0.9200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1356 - accuracy: 0.9571 - val_loss: 0.2429 - val_accuracy: 0.9360\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2159 - accuracy: 0.9354 - val_loss: 0.3895 - val_accuracy: 0.8747\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1779 - accuracy: 0.9480 - val_loss: 0.2115 - val_accuracy: 0.9280\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1303 - accuracy: 0.9617 - val_loss: 0.2123 - val_accuracy: 0.9307\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1302 - accuracy: 0.9543 - val_loss: 0.2096 - val_accuracy: 0.9347\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1349 - accuracy: 0.9634 - val_loss: 0.1924 - val_accuracy: 0.9307\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1217 - accuracy: 0.9646 - val_loss: 0.1733 - val_accuracy: 0.9507\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1240 - accuracy: 0.9617 - val_loss: 0.2033 - val_accuracy: 0.9360\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1176 - accuracy: 0.9611 - val_loss: 0.1680 - val_accuracy: 0.9400\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1086 - accuracy: 0.9674 - val_loss: 0.1706 - val_accuracy: 0.9467\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1256 - accuracy: 0.9606 - val_loss: 0.2348 - val_accuracy: 0.9293\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1299 - accuracy: 0.9606 - val_loss: 0.1490 - val_accuracy: 0.9520\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1193 - accuracy: 0.9617 - val_loss: 0.1441 - val_accuracy: 0.9533\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1120 - accuracy: 0.9611 - val_loss: 0.1528 - val_accuracy: 0.9480\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1697 - accuracy: 0.9589 - val_loss: 0.2482 - val_accuracy: 0.9227\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1638 - accuracy: 0.9549 - val_loss: 0.1867 - val_accuracy: 0.9413\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1412 - accuracy: 0.9600 - val_loss: 0.2041 - val_accuracy: 0.9173\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1153 - accuracy: 0.9657 - val_loss: 0.1464 - val_accuracy: 0.9453\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1508 - accuracy: 0.9543 - val_loss: 0.1337 - val_accuracy: 0.9480\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1453 - accuracy: 0.9560 - val_loss: 0.1581 - val_accuracy: 0.9480\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1391 - accuracy: 0.9571 - val_loss: 0.1718 - val_accuracy: 0.9493\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1209 - accuracy: 0.9651 - val_loss: 0.1751 - val_accuracy: 0.9440\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1160 - accuracy: 0.9646 - val_loss: 0.2250 - val_accuracy: 0.9333\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.1286 - accuracy: 0.9617 - val_loss: 0.2593 - val_accuracy: 0.9293\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1224 - accuracy: 0.9634 - val_loss: 0.2093 - val_accuracy: 0.9507\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1306 - accuracy: 0.9686 - val_loss: 0.1850 - val_accuracy: 0.9400\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1184 - accuracy: 0.9634 - val_loss: 0.1651 - val_accuracy: 0.9453\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1197 - accuracy: 0.9640 - val_loss: 0.1747 - val_accuracy: 0.9373\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0982 - accuracy: 0.9720 - val_loss: 0.1926 - val_accuracy: 0.9427\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1166 - accuracy: 0.9657 - val_loss: 0.1694 - val_accuracy: 0.9427\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1009 - accuracy: 0.9686 - val_loss: 0.1838 - val_accuracy: 0.9320\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.0989 - accuracy: 0.9663 - val_loss: 0.1460 - val_accuracy: 0.9467\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1040 - accuracy: 0.9691 - val_loss: 0.1438 - val_accuracy: 0.9507\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1064 - accuracy: 0.9663 - val_loss: 0.1792 - val_accuracy: 0.9453\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1010 - accuracy: 0.9726 - val_loss: 0.2061 - val_accuracy: 0.9387\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1111 - accuracy: 0.9686 - val_loss: 0.1622 - val_accuracy: 0.9467\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1003 - accuracy: 0.9726 - val_loss: 0.1533 - val_accuracy: 0.9533\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0971 - accuracy: 0.9726 - val_loss: 0.1636 - val_accuracy: 0.9440\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1065 - accuracy: 0.9629 - val_loss: 0.1279 - val_accuracy: 0.9560\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1104 - accuracy: 0.9680 - val_loss: 0.1984 - val_accuracy: 0.9333\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1007 - accuracy: 0.9720 - val_loss: 0.1432 - val_accuracy: 0.9507\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0821 - accuracy: 0.9794 - val_loss: 0.2051 - val_accuracy: 0.9360\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1116 - accuracy: 0.9674 - val_loss: 0.1371 - val_accuracy: 0.9573\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1262 - accuracy: 0.9611 - val_loss: 0.1388 - val_accuracy: 0.9493\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1264 - accuracy: 0.9600 - val_loss: 0.1484 - val_accuracy: 0.9507\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1023 - accuracy: 0.9669 - val_loss: 0.1896 - val_accuracy: 0.9320\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1049 - accuracy: 0.9703 - val_loss: 0.1791 - val_accuracy: 0.9547\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0984 - accuracy: 0.9726 - val_loss: 0.1853 - val_accuracy: 0.9507\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1059 - accuracy: 0.9657 - val_loss: 0.1770 - val_accuracy: 0.9347\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0915 - accuracy: 0.9771 - val_loss: 0.1353 - val_accuracy: 0.9547\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0977 - accuracy: 0.9634 - val_loss: 0.1583 - val_accuracy: 0.9453\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0953 - accuracy: 0.9731 - val_loss: 0.1691 - val_accuracy: 0.9400\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1058 - accuracy: 0.9680 - val_loss: 0.1910 - val_accuracy: 0.9387\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0988 - accuracy: 0.9669 - val_loss: 0.1453 - val_accuracy: 0.9480\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1062 - accuracy: 0.9686 - val_loss: 0.1612 - val_accuracy: 0.9547\n",
      "Epoch 136/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0975 - accuracy: 0.9726 - val_loss: 0.2275 - val_accuracy: 0.9280\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1233 - accuracy: 0.9686 - val_loss: 0.2340 - val_accuracy: 0.9293\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1430 - accuracy: 0.9531 - val_loss: 0.2101 - val_accuracy: 0.9373\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1231 - accuracy: 0.9589 - val_loss: 0.1628 - val_accuracy: 0.9427\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0998 - accuracy: 0.9686 - val_loss: 0.1742 - val_accuracy: 0.9453\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1132 - accuracy: 0.9663 - val_loss: 0.1611 - val_accuracy: 0.9467\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1004 - accuracy: 0.9726 - val_loss: 0.1941 - val_accuracy: 0.9360\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1008 - accuracy: 0.9691 - val_loss: 0.1584 - val_accuracy: 0.9493\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1167 - accuracy: 0.9697 - val_loss: 0.1322 - val_accuracy: 0.9613\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0855 - accuracy: 0.9737 - val_loss: 0.1530 - val_accuracy: 0.9480\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0981 - accuracy: 0.9697 - val_loss: 0.1749 - val_accuracy: 0.9440\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0850 - accuracy: 0.9749 - val_loss: 0.1520 - val_accuracy: 0.9453\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0927 - accuracy: 0.9714 - val_loss: 0.1256 - val_accuracy: 0.9587\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0906 - accuracy: 0.9731 - val_loss: 0.1233 - val_accuracy: 0.9587\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0957 - accuracy: 0.9697 - val_loss: 1.0125 - val_accuracy: 0.6720\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0817 - accuracy: 0.9766 - val_loss: 0.1656 - val_accuracy: 0.9440\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1042 - accuracy: 0.9731 - val_loss: 0.1497 - val_accuracy: 0.9520\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.0890 - accuracy: 0.9720 - val_loss: 0.1438 - val_accuracy: 0.9587\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0894 - accuracy: 0.9720 - val_loss: 0.1309 - val_accuracy: 0.9533\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1018 - accuracy: 0.9737 - val_loss: 0.1580 - val_accuracy: 0.9493\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0839 - accuracy: 0.9749 - val_loss: 0.1777 - val_accuracy: 0.9373\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0890 - accuracy: 0.9714 - val_loss: 0.1501 - val_accuracy: 0.9413\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1058 - accuracy: 0.9629 - val_loss: 0.1532 - val_accuracy: 0.9560\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0924 - accuracy: 0.9749 - val_loss: 0.1547 - val_accuracy: 0.9560\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1033 - accuracy: 0.9720 - val_loss: 0.1805 - val_accuracy: 0.9347\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1012 - accuracy: 0.9674 - val_loss: 0.1814 - val_accuracy: 0.9467\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0923 - accuracy: 0.9726 - val_loss: 0.1307 - val_accuracy: 0.9547\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0812 - accuracy: 0.9754 - val_loss: 0.1518 - val_accuracy: 0.9493\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0799 - accuracy: 0.9771 - val_loss: 0.1635 - val_accuracy: 0.9493\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0861 - accuracy: 0.9731 - val_loss: 0.1418 - val_accuracy: 0.9480\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0949 - accuracy: 0.9731 - val_loss: 0.2231 - val_accuracy: 0.9293\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0829 - accuracy: 0.9743 - val_loss: 0.2068 - val_accuracy: 0.9427\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0995 - accuracy: 0.9714 - val_loss: 0.1515 - val_accuracy: 0.9547\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0877 - accuracy: 0.9737 - val_loss: 0.1184 - val_accuracy: 0.9547\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0892 - accuracy: 0.9731 - val_loss: 0.1110 - val_accuracy: 0.9587\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.0955 - accuracy: 0.9720 - val_loss: 0.1329 - val_accuracy: 0.9600\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0872 - accuracy: 0.9760 - val_loss: 0.1380 - val_accuracy: 0.9627\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0965 - accuracy: 0.9686 - val_loss: 0.1670 - val_accuracy: 0.9467\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0759 - accuracy: 0.9777 - val_loss: 0.1885 - val_accuracy: 0.9453\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1018 - accuracy: 0.9714 - val_loss: 0.2427 - val_accuracy: 0.9400\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0959 - accuracy: 0.9686 - val_loss: 0.1944 - val_accuracy: 0.9307\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0977 - accuracy: 0.9709 - val_loss: 0.1628 - val_accuracy: 0.9453\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0890 - accuracy: 0.9760 - val_loss: 0.1575 - val_accuracy: 0.9587\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0836 - accuracy: 0.9760 - val_loss: 0.1343 - val_accuracy: 0.9627\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1224 - accuracy: 0.9754 - val_loss: 0.1626 - val_accuracy: 0.9533\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0931 - accuracy: 0.9743 - val_loss: 0.1310 - val_accuracy: 0.9547\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0899 - accuracy: 0.9697 - val_loss: 0.1245 - val_accuracy: 0.9613\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0884 - accuracy: 0.9743 - val_loss: 0.1633 - val_accuracy: 0.9507\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0927 - accuracy: 0.9737 - val_loss: 0.1331 - val_accuracy: 0.9613\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0874 - accuracy: 0.9737 - val_loss: 0.1436 - val_accuracy: 0.9600\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1086 - accuracy: 0.9709 - val_loss: 0.1266 - val_accuracy: 0.9573\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0955 - accuracy: 0.9680 - val_loss: 0.1220 - val_accuracy: 0.9560\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0818 - accuracy: 0.9754 - val_loss: 0.1425 - val_accuracy: 0.9560\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0817 - accuracy: 0.9743 - val_loss: 0.1311 - val_accuracy: 0.9520\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0653 - accuracy: 0.9840 - val_loss: 0.1457 - val_accuracy: 0.9573\n",
      "Epoch 191/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1063 - accuracy: 0.9691 - val_loss: 0.1652 - val_accuracy: 0.9467\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1475 - accuracy: 0.9497 - val_loss: 0.1664 - val_accuracy: 0.9360\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1170 - accuracy: 0.9640 - val_loss: 0.1672 - val_accuracy: 0.9360\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1162 - accuracy: 0.9623 - val_loss: 0.1487 - val_accuracy: 0.9493\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1045 - accuracy: 0.9686 - val_loss: 0.1565 - val_accuracy: 0.9427\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1059 - accuracy: 0.9686 - val_loss: 0.1393 - val_accuracy: 0.9480\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1070 - accuracy: 0.9714 - val_loss: 0.1444 - val_accuracy: 0.9573\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0915 - accuracy: 0.9726 - val_loss: 0.1527 - val_accuracy: 0.9520\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0756 - accuracy: 0.9777 - val_loss: 0.1484 - val_accuracy: 0.9493\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0816 - accuracy: 0.9737 - val_loss: 0.1465 - val_accuracy: 0.9600\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 1)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 49s - loss: 5.6830 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0637s vs `on_train_batch_end` time: 0.7811s). Check your callbacks.\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 1.3988 - accuracy: 0.6703 - val_loss: 0.7746 - val_accuracy: 0.6280\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.6694 - accuracy: 0.7411 - val_loss: 1.8240 - val_accuracy: 0.3720\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.7184 - accuracy: 0.7646 - val_loss: 1.2144 - val_accuracy: 0.5067\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.5612 - accuracy: 0.7943 - val_loss: 1.1594 - val_accuracy: 0.6533\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.6637 - accuracy: 0.7880 - val_loss: 5.2236 - val_accuracy: 0.7800\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.4319 - accuracy: 0.8223 - val_loss: 0.9147 - val_accuracy: 0.7853\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.4279 - accuracy: 0.8326 - val_loss: 0.4233 - val_accuracy: 0.8187\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3964 - accuracy: 0.8291 - val_loss: 0.6568 - val_accuracy: 0.8213\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.3676 - accuracy: 0.8491 - val_loss: 0.6103 - val_accuracy: 0.7853\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3463 - accuracy: 0.8697 - val_loss: 0.4704 - val_accuracy: 0.8307\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.3191 - accuracy: 0.8806 - val_loss: 0.4895 - val_accuracy: 0.8547\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.3233 - accuracy: 0.8869 - val_loss: 0.3959 - val_accuracy: 0.8720\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2987 - accuracy: 0.8949 - val_loss: 0.5210 - val_accuracy: 0.8840\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2446 - accuracy: 0.9086 - val_loss: 0.3515 - val_accuracy: 0.8760\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.2677 - accuracy: 0.9126 - val_loss: 0.2772 - val_accuracy: 0.8787\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.2413 - accuracy: 0.9171 - val_loss: 0.2960 - val_accuracy: 0.8960\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.2215 - accuracy: 0.9234 - val_loss: 0.2855 - val_accuracy: 0.8947\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2198 - accuracy: 0.9274 - val_loss: 0.3505 - val_accuracy: 0.8920\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.2660 - accuracy: 0.9303 - val_loss: 0.3864 - val_accuracy: 0.8973\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.2264 - accuracy: 0.9223 - val_loss: 0.3293 - val_accuracy: 0.8907\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1934 - accuracy: 0.9343 - val_loss: 0.2592 - val_accuracy: 0.9093\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1955 - accuracy: 0.9331 - val_loss: 0.3589 - val_accuracy: 0.8947\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2115 - accuracy: 0.9297 - val_loss: 0.3910 - val_accuracy: 0.8853\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.2164 - accuracy: 0.9234 - val_loss: 0.2680 - val_accuracy: 0.9013\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.1673 - accuracy: 0.9457 - val_loss: 0.1870 - val_accuracy: 0.9347\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1835 - accuracy: 0.9423 - val_loss: 0.2704 - val_accuracy: 0.9133\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.4240 - accuracy: 0.9211 - val_loss: 3.2860 - val_accuracy: 0.9067\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.3218 - accuracy: 0.9046 - val_loss: 0.3444 - val_accuracy: 0.8480\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.2242 - accuracy: 0.9229 - val_loss: 0.2489 - val_accuracy: 0.8867\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.2183 - accuracy: 0.9269 - val_loss: 0.4091 - val_accuracy: 0.8573\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2306 - accuracy: 0.9280 - val_loss: 0.2817 - val_accuracy: 0.9013\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1748 - accuracy: 0.9434 - val_loss: 0.2591 - val_accuracy: 0.9080\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1748 - accuracy: 0.9423 - val_loss: 0.2202 - val_accuracy: 0.9213\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1798 - accuracy: 0.9446 - val_loss: 0.2260 - val_accuracy: 0.9160\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.1899 - accuracy: 0.9451 - val_loss: 0.2596 - val_accuracy: 0.8947\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2092 - accuracy: 0.9411 - val_loss: 0.2134 - val_accuracy: 0.9267\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2250 - accuracy: 0.9434 - val_loss: 0.1900 - val_accuracy: 0.9267\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1751 - accuracy: 0.9411 - val_loss: 0.3950 - val_accuracy: 0.8893\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1621 - accuracy: 0.9503 - val_loss: 0.2573 - val_accuracy: 0.9120\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1604 - accuracy: 0.9446 - val_loss: 0.2837 - val_accuracy: 0.9160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2051 - accuracy: 0.9400 - val_loss: 0.2416 - val_accuracy: 0.9200\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.1781 - accuracy: 0.9457 - val_loss: 0.2385 - val_accuracy: 0.9213\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1613 - accuracy: 0.9549 - val_loss: 0.2000 - val_accuracy: 0.9320\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.1606 - accuracy: 0.9526 - val_loss: 0.2172 - val_accuracy: 0.9253\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1875 - accuracy: 0.9429 - val_loss: 0.2353 - val_accuracy: 0.9160\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.1471 - accuracy: 0.9509 - val_loss: 0.2129 - val_accuracy: 0.9280\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1690 - accuracy: 0.9434 - val_loss: 0.2125 - val_accuracy: 0.9240\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1495 - accuracy: 0.9571 - val_loss: 0.1771 - val_accuracy: 0.9453\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1427 - accuracy: 0.9583 - val_loss: 0.2357 - val_accuracy: 0.9307\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1889 - accuracy: 0.9503 - val_loss: 0.2238 - val_accuracy: 0.9307\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1527 - accuracy: 0.9497 - val_loss: 0.2879 - val_accuracy: 0.9307\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1877 - accuracy: 0.9469 - val_loss: 0.2219 - val_accuracy: 0.9293\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1522 - accuracy: 0.9549 - val_loss: 0.2128 - val_accuracy: 0.9293\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1643 - accuracy: 0.9560 - val_loss: 0.2060 - val_accuracy: 0.9320\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1663 - accuracy: 0.9503 - val_loss: 0.2407 - val_accuracy: 0.9213\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1709 - accuracy: 0.9474 - val_loss: 0.2346 - val_accuracy: 0.9267\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1519 - accuracy: 0.9514 - val_loss: 0.2216 - val_accuracy: 0.9333\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1590 - accuracy: 0.9520 - val_loss: 0.1796 - val_accuracy: 0.9373\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1579 - accuracy: 0.9554 - val_loss: 0.1847 - val_accuracy: 0.9320\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1550 - accuracy: 0.9537 - val_loss: 0.2102 - val_accuracy: 0.9347\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1603 - accuracy: 0.9537 - val_loss: 0.2095 - val_accuracy: 0.9347\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1395 - accuracy: 0.9600 - val_loss: 0.2163 - val_accuracy: 0.9373\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1655 - accuracy: 0.9491 - val_loss: 0.2084 - val_accuracy: 0.9227\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1558 - accuracy: 0.9566 - val_loss: 0.1483 - val_accuracy: 0.9440\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1487 - accuracy: 0.9486 - val_loss: 0.1493 - val_accuracy: 0.9480\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1430 - accuracy: 0.9537 - val_loss: 0.1508 - val_accuracy: 0.9507\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1446 - accuracy: 0.9583 - val_loss: 0.2751 - val_accuracy: 0.9013\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.1638 - accuracy: 0.9589 - val_loss: 0.2237 - val_accuracy: 0.9307\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1482 - accuracy: 0.9583 - val_loss: 0.1668 - val_accuracy: 0.9400\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1510 - accuracy: 0.9589 - val_loss: 0.1864 - val_accuracy: 0.9320\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1726 - accuracy: 0.9509 - val_loss: 0.3181 - val_accuracy: 0.9200\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.1588 - accuracy: 0.9526 - val_loss: 0.2847 - val_accuracy: 0.9280\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1439 - accuracy: 0.9537 - val_loss: 0.2156 - val_accuracy: 0.9293\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1239 - accuracy: 0.9623 - val_loss: 0.2022 - val_accuracy: 0.9347\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1362 - accuracy: 0.9577 - val_loss: 0.1740 - val_accuracy: 0.9413\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1300 - accuracy: 0.9606 - val_loss: 0.1977 - val_accuracy: 0.9333\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1452 - accuracy: 0.9583 - val_loss: 0.2021 - val_accuracy: 0.9360\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1368 - accuracy: 0.9634 - val_loss: 0.2009 - val_accuracy: 0.9347\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1333 - accuracy: 0.9606 - val_loss: 0.2279 - val_accuracy: 0.9360\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1181 - accuracy: 0.9657 - val_loss: 0.1597 - val_accuracy: 0.9453\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1324 - accuracy: 0.9617 - val_loss: 0.1936 - val_accuracy: 0.9373\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1261 - accuracy: 0.9623 - val_loss: 0.1542 - val_accuracy: 0.9453\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1710 - accuracy: 0.9566 - val_loss: 0.2526 - val_accuracy: 0.9213\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1401 - accuracy: 0.9600 - val_loss: 0.1854 - val_accuracy: 0.9373\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.1275 - accuracy: 0.9583 - val_loss: 0.1866 - val_accuracy: 0.9360\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1320 - accuracy: 0.9691 - val_loss: 0.1643 - val_accuracy: 0.9440\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.1290 - accuracy: 0.9589 - val_loss: 0.1606 - val_accuracy: 0.9413\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1280 - accuracy: 0.9611 - val_loss: 0.1617 - val_accuracy: 0.9400\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1233 - accuracy: 0.9629 - val_loss: 0.1682 - val_accuracy: 0.9413\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1136 - accuracy: 0.9629 - val_loss: 0.1793 - val_accuracy: 0.9427\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1135 - accuracy: 0.9594 - val_loss: 0.1861 - val_accuracy: 0.9333\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1376 - accuracy: 0.9589 - val_loss: 0.1862 - val_accuracy: 0.9413\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1135 - accuracy: 0.9646 - val_loss: 0.1879 - val_accuracy: 0.9413\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1441 - accuracy: 0.9543 - val_loss: 0.4357 - val_accuracy: 0.8440\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1412 - accuracy: 0.9503 - val_loss: 0.1870 - val_accuracy: 0.9373\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1460 - accuracy: 0.9583 - val_loss: 0.2423 - val_accuracy: 0.9200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1360 - accuracy: 0.9617 - val_loss: 0.2247 - val_accuracy: 0.9307\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1274 - accuracy: 0.9651 - val_loss: 0.1652 - val_accuracy: 0.9480\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1198 - accuracy: 0.9663 - val_loss: 0.1811 - val_accuracy: 0.9440\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1260 - accuracy: 0.9640 - val_loss: 0.1652 - val_accuracy: 0.9533\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1161 - accuracy: 0.9674 - val_loss: 0.1640 - val_accuracy: 0.9467\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1164 - accuracy: 0.9651 - val_loss: 0.2055 - val_accuracy: 0.9387\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1096 - accuracy: 0.9680 - val_loss: 0.1626 - val_accuracy: 0.9507\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1133 - accuracy: 0.9657 - val_loss: 0.1905 - val_accuracy: 0.9373\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1022 - accuracy: 0.9691 - val_loss: 0.1929 - val_accuracy: 0.9413\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1155 - accuracy: 0.9669 - val_loss: 0.1924 - val_accuracy: 0.9320\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1010 - accuracy: 0.9697 - val_loss: 0.1417 - val_accuracy: 0.9533\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1021 - accuracy: 0.9686 - val_loss: 0.2338 - val_accuracy: 0.9240\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1194 - accuracy: 0.9634 - val_loss: 0.1953 - val_accuracy: 0.9400\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.1144 - accuracy: 0.9651 - val_loss: 0.1976 - val_accuracy: 0.9387\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1076 - accuracy: 0.9680 - val_loss: 0.2147 - val_accuracy: 0.9347\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1023 - accuracy: 0.9640 - val_loss: 0.1829 - val_accuracy: 0.9373\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1177 - accuracy: 0.9663 - val_loss: 0.2786 - val_accuracy: 0.9173\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1301 - accuracy: 0.9674 - val_loss: 0.1788 - val_accuracy: 0.9427\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1023 - accuracy: 0.9663 - val_loss: 0.2039 - val_accuracy: 0.9400\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0991 - accuracy: 0.9686 - val_loss: 0.1803 - val_accuracy: 0.9387\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1019 - accuracy: 0.9680 - val_loss: 0.1784 - val_accuracy: 0.9427\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1104 - accuracy: 0.9674 - val_loss: 0.1559 - val_accuracy: 0.9507\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0984 - accuracy: 0.9709 - val_loss: 0.1576 - val_accuracy: 0.9507\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1024 - accuracy: 0.9703 - val_loss: 0.1836 - val_accuracy: 0.9373\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1088 - accuracy: 0.9697 - val_loss: 0.1918 - val_accuracy: 0.9373\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1011 - accuracy: 0.9691 - val_loss: 0.2047 - val_accuracy: 0.9373\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0959 - accuracy: 0.9720 - val_loss: 0.1559 - val_accuracy: 0.9560\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0975 - accuracy: 0.9697 - val_loss: 0.1579 - val_accuracy: 0.9493\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1038 - accuracy: 0.9714 - val_loss: 0.1566 - val_accuracy: 0.9533\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1395 - accuracy: 0.9606 - val_loss: 0.1645 - val_accuracy: 0.9507\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1184 - accuracy: 0.9623 - val_loss: 0.1793 - val_accuracy: 0.9413\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0973 - accuracy: 0.9669 - val_loss: 0.1694 - val_accuracy: 0.9400\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1044 - accuracy: 0.9680 - val_loss: 0.2457 - val_accuracy: 0.9280\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0916 - accuracy: 0.9726 - val_loss: 0.2210 - val_accuracy: 0.9480\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0994 - accuracy: 0.9691 - val_loss: 0.2479 - val_accuracy: 0.9133\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1441 - accuracy: 0.9611 - val_loss: 0.1690 - val_accuracy: 0.9413\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1037 - accuracy: 0.9657 - val_loss: 0.1429 - val_accuracy: 0.9520\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0952 - accuracy: 0.9691 - val_loss: 0.1816 - val_accuracy: 0.9400\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0925 - accuracy: 0.9703 - val_loss: 0.1928 - val_accuracy: 0.9453\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0986 - accuracy: 0.9726 - val_loss: 0.1529 - val_accuracy: 0.9560\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0926 - accuracy: 0.9720 - val_loss: 0.1760 - val_accuracy: 0.9400\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0747 - accuracy: 0.9766 - val_loss: 0.1663 - val_accuracy: 0.9453\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0999 - accuracy: 0.9674 - val_loss: 0.1662 - val_accuracy: 0.9547\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0836 - accuracy: 0.9737 - val_loss: 0.1647 - val_accuracy: 0.9400\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0852 - accuracy: 0.9783 - val_loss: 0.1542 - val_accuracy: 0.9493\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0824 - accuracy: 0.9737 - val_loss: 0.1901 - val_accuracy: 0.9440\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1056 - accuracy: 0.9731 - val_loss: 0.1672 - val_accuracy: 0.9480\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0886 - accuracy: 0.9726 - val_loss: 0.1521 - val_accuracy: 0.9507\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.0923 - accuracy: 0.9691 - val_loss: 0.1869 - val_accuracy: 0.9387\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1002 - accuracy: 0.9714 - val_loss: 0.1497 - val_accuracy: 0.9480\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0849 - accuracy: 0.9737 - val_loss: 0.1507 - val_accuracy: 0.9493\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0867 - accuracy: 0.9714 - val_loss: 0.1759 - val_accuracy: 0.9480\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1100 - accuracy: 0.9714 - val_loss: 0.1435 - val_accuracy: 0.9520\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0752 - accuracy: 0.9789 - val_loss: 0.2032 - val_accuracy: 0.9387\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1191 - accuracy: 0.9651 - val_loss: 0.1746 - val_accuracy: 0.9453\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0909 - accuracy: 0.9697 - val_loss: 0.1815 - val_accuracy: 0.9400\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0991 - accuracy: 0.9697 - val_loss: 0.1677 - val_accuracy: 0.9440\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0787 - accuracy: 0.9737 - val_loss: 0.1901 - val_accuracy: 0.9400\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0942 - accuracy: 0.9714 - val_loss: 0.1678 - val_accuracy: 0.9387\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0850 - accuracy: 0.9709 - val_loss: 0.1749 - val_accuracy: 0.9413\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0835 - accuracy: 0.9720 - val_loss: 0.1594 - val_accuracy: 0.9413\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.0776 - accuracy: 0.9766 - val_loss: 0.1811 - val_accuracy: 0.9427\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0970 - accuracy: 0.9703 - val_loss: 0.1613 - val_accuracy: 0.9520\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0705 - accuracy: 0.9806 - val_loss: 0.1489 - val_accuracy: 0.9480\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.0825 - accuracy: 0.9743 - val_loss: 0.1507 - val_accuracy: 0.9507\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0781 - accuracy: 0.9777 - val_loss: 0.1680 - val_accuracy: 0.9453\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0808 - accuracy: 0.9743 - val_loss: 0.1405 - val_accuracy: 0.9573\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0848 - accuracy: 0.9731 - val_loss: 0.1794 - val_accuracy: 0.9440\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0869 - accuracy: 0.9686 - val_loss: 0.2096 - val_accuracy: 0.9387\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0978 - accuracy: 0.9691 - val_loss: 0.1556 - val_accuracy: 0.9507\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0978 - accuracy: 0.9720 - val_loss: 0.1561 - val_accuracy: 0.9520\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0753 - accuracy: 0.9731 - val_loss: 0.1612 - val_accuracy: 0.9493\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0818 - accuracy: 0.9743 - val_loss: 0.1491 - val_accuracy: 0.9587\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0868 - accuracy: 0.9714 - val_loss: 0.1503 - val_accuracy: 0.9573\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.0830 - accuracy: 0.9686 - val_loss: 0.1433 - val_accuracy: 0.9573\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0679 - accuracy: 0.9794 - val_loss: 0.1617 - val_accuracy: 0.9520\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0746 - accuracy: 0.9800 - val_loss: 0.1784 - val_accuracy: 0.9520\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.0921 - accuracy: 0.9743 - val_loss: 0.1693 - val_accuracy: 0.9427\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0751 - accuracy: 0.9749 - val_loss: 0.1561 - val_accuracy: 0.9507\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1000 - accuracy: 0.9749 - val_loss: 0.1534 - val_accuracy: 0.9520\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0876 - accuracy: 0.9749 - val_loss: 0.1720 - val_accuracy: 0.9480\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0807 - accuracy: 0.9760 - val_loss: 0.1806 - val_accuracy: 0.9467\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0816 - accuracy: 0.9754 - val_loss: 0.1821 - val_accuracy: 0.9547\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0822 - accuracy: 0.9737 - val_loss: 0.1265 - val_accuracy: 0.9640\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0800 - accuracy: 0.9754 - val_loss: 0.1623 - val_accuracy: 0.9453\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0689 - accuracy: 0.9817 - val_loss: 0.2110 - val_accuracy: 0.9400\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0869 - accuracy: 0.9743 - val_loss: 0.1493 - val_accuracy: 0.9507\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0713 - accuracy: 0.9760 - val_loss: 0.1814 - val_accuracy: 0.9520\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0949 - accuracy: 0.9691 - val_loss: 0.1486 - val_accuracy: 0.9560\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0788 - accuracy: 0.9783 - val_loss: 0.1331 - val_accuracy: 0.9627\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0735 - accuracy: 0.9789 - val_loss: 0.1348 - val_accuracy: 0.9600\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0630 - accuracy: 0.9783 - val_loss: 0.1486 - val_accuracy: 0.9493\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1381 - accuracy: 0.9663 - val_loss: 0.2610 - val_accuracy: 0.9053\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0967 - accuracy: 0.9731 - val_loss: 0.2454 - val_accuracy: 0.9280\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0820 - accuracy: 0.9789 - val_loss: 0.1378 - val_accuracy: 0.9520\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0775 - accuracy: 0.9760 - val_loss: 0.1907 - val_accuracy: 0.9373\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0773 - accuracy: 0.9783 - val_loss: 0.1343 - val_accuracy: 0.9560\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0729 - accuracy: 0.9789 - val_loss: 0.1498 - val_accuracy: 0.9533\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0666 - accuracy: 0.9823 - val_loss: 0.1515 - val_accuracy: 0.9493\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0736 - accuracy: 0.9783 - val_loss: 0.1325 - val_accuracy: 0.9613\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0665 - accuracy: 0.9811 - val_loss: 0.1762 - val_accuracy: 0.9480\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0811 - accuracy: 0.9811 - val_loss: 0.1460 - val_accuracy: 0.9573\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0722 - accuracy: 0.9794 - val_loss: 0.1400 - val_accuracy: 0.9587\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.0928 - accuracy: 0.9726 - val_loss: 0.1505 - val_accuracy: 0.9533\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 1)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 47s - loss: 0.4489 - accuracy: 0.7812WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0920s vs `on_train_batch_end` time: 0.7654s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 164ms/step - loss: 0.6444 - accuracy: 0.7166 - val_loss: 0.7744 - val_accuracy: 0.3720\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.6709 - accuracy: 0.7389 - val_loss: 0.8411 - val_accuracy: 0.3720\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.6298 - accuracy: 0.7531 - val_loss: 0.5498 - val_accuracy: 0.6280\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.5623 - accuracy: 0.7634 - val_loss: 0.5506 - val_accuracy: 0.6693\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.5633 - accuracy: 0.7657 - val_loss: 0.4932 - val_accuracy: 0.7493\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.6322 - accuracy: 0.7663 - val_loss: 0.6339 - val_accuracy: 0.6947\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.5195 - accuracy: 0.7766 - val_loss: 0.7095 - val_accuracy: 0.7533\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.4895 - accuracy: 0.7989 - val_loss: 0.4712 - val_accuracy: 0.7680\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.4734 - accuracy: 0.7914 - val_loss: 1.4891 - val_accuracy: 0.7947\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.4932 - accuracy: 0.8029 - val_loss: 0.3808 - val_accuracy: 0.8413\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.4245 - accuracy: 0.8211 - val_loss: 0.4144 - val_accuracy: 0.8200\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.4595 - accuracy: 0.8154 - val_loss: 0.3596 - val_accuracy: 0.8360\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.4458 - accuracy: 0.8189 - val_loss: 0.4460 - val_accuracy: 0.8040\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.4266 - accuracy: 0.8377 - val_loss: 0.4751 - val_accuracy: 0.8067\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.4134 - accuracy: 0.8314 - val_loss: 0.3991 - val_accuracy: 0.8293\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.4645 - accuracy: 0.8263 - val_loss: 0.4548 - val_accuracy: 0.8080\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3839 - accuracy: 0.8406 - val_loss: 0.6712 - val_accuracy: 0.7693\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.4383 - accuracy: 0.8343 - val_loss: 0.3270 - val_accuracy: 0.8493\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.4032 - accuracy: 0.8337 - val_loss: 0.4217 - val_accuracy: 0.8253\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.4019 - accuracy: 0.8234 - val_loss: 1.3202 - val_accuracy: 0.8187\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.4416 - accuracy: 0.8463 - val_loss: 0.3705 - val_accuracy: 0.8293\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3935 - accuracy: 0.8549 - val_loss: 1.0978 - val_accuracy: 0.8187\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.4301 - accuracy: 0.8343 - val_loss: 0.3304 - val_accuracy: 0.8453\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.3398 - accuracy: 0.8589 - val_loss: 0.3711 - val_accuracy: 0.8347\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3652 - accuracy: 0.8623 - val_loss: 0.4301 - val_accuracy: 0.8213\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2987 - accuracy: 0.8697 - val_loss: 0.4324 - val_accuracy: 0.8427\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.3105 - accuracy: 0.8697 - val_loss: 0.3645 - val_accuracy: 0.8547\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3616 - accuracy: 0.8640 - val_loss: 0.2954 - val_accuracy: 0.8547\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3305 - accuracy: 0.8691 - val_loss: 0.3209 - val_accuracy: 0.8493\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3119 - accuracy: 0.8754 - val_loss: 0.3622 - val_accuracy: 0.8547\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.3381 - accuracy: 0.8851 - val_loss: 0.3558 - val_accuracy: 0.8640\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.3802 - accuracy: 0.8811 - val_loss: 0.3841 - val_accuracy: 0.8307\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.3533 - accuracy: 0.8634 - val_loss: 0.6654 - val_accuracy: 0.8027\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3086 - accuracy: 0.8817 - val_loss: 0.3529 - val_accuracy: 0.8507\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3403 - accuracy: 0.8623 - val_loss: 0.4025 - val_accuracy: 0.8427\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2954 - accuracy: 0.8829 - val_loss: 0.4375 - val_accuracy: 0.8480\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2831 - accuracy: 0.8937 - val_loss: 0.3694 - val_accuracy: 0.8453\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3052 - accuracy: 0.8909 - val_loss: 0.5755 - val_accuracy: 0.8387\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.3204 - accuracy: 0.8817 - val_loss: 0.4094 - val_accuracy: 0.8440\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2934 - accuracy: 0.8834 - val_loss: 0.4626 - val_accuracy: 0.8427\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.3029 - accuracy: 0.8880 - val_loss: 0.3067 - val_accuracy: 0.8600\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.2534 - accuracy: 0.8954 - val_loss: 0.9457 - val_accuracy: 0.8307\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.3035 - accuracy: 0.9011 - val_loss: 0.4153 - val_accuracy: 0.8533\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.3025 - accuracy: 0.8920 - val_loss: 0.3378 - val_accuracy: 0.8587\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2845 - accuracy: 0.8920 - val_loss: 0.4068 - val_accuracy: 0.8667\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2550 - accuracy: 0.9029 - val_loss: 0.3462 - val_accuracy: 0.8653\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2354 - accuracy: 0.9069 - val_loss: 0.4469 - val_accuracy: 0.8507\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2692 - accuracy: 0.9051 - val_loss: 0.4965 - val_accuracy: 0.8333\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.2690 - accuracy: 0.9097 - val_loss: 0.3433 - val_accuracy: 0.8693\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2697 - accuracy: 0.9029 - val_loss: 0.3269 - val_accuracy: 0.8720\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.2588 - accuracy: 0.9063 - val_loss: 0.4163 - val_accuracy: 0.8613\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2601 - accuracy: 0.9120 - val_loss: 0.4322 - val_accuracy: 0.8573\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2656 - accuracy: 0.9040 - val_loss: 0.3471 - val_accuracy: 0.8573\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2885 - accuracy: 0.8971 - val_loss: 0.3336 - val_accuracy: 0.8680\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.2790 - accuracy: 0.9109 - val_loss: 0.3405 - val_accuracy: 0.8827\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2298 - accuracy: 0.9126 - val_loss: 0.3726 - val_accuracy: 0.8613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2319 - accuracy: 0.9137 - val_loss: 0.2669 - val_accuracy: 0.8787\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.2194 - accuracy: 0.9297 - val_loss: 0.3750 - val_accuracy: 0.8573\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.2150 - accuracy: 0.9200 - val_loss: 0.4237 - val_accuracy: 0.8560\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2298 - accuracy: 0.9234 - val_loss: 0.2477 - val_accuracy: 0.9000\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2168 - accuracy: 0.9257 - val_loss: 0.3027 - val_accuracy: 0.8853\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2123 - accuracy: 0.9200 - val_loss: 0.4138 - val_accuracy: 0.8640\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2069 - accuracy: 0.9291 - val_loss: 0.3160 - val_accuracy: 0.8840\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.2045 - accuracy: 0.9291 - val_loss: 0.2381 - val_accuracy: 0.9013\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.2139 - accuracy: 0.9269 - val_loss: 0.2932 - val_accuracy: 0.8880\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2097 - accuracy: 0.9314 - val_loss: 0.3564 - val_accuracy: 0.8827\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2047 - accuracy: 0.9303 - val_loss: 0.2654 - val_accuracy: 0.9000\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2215 - accuracy: 0.9303 - val_loss: 0.3840 - val_accuracy: 0.8760\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2091 - accuracy: 0.9297 - val_loss: 0.3640 - val_accuracy: 0.8600\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2036 - accuracy: 0.9360 - val_loss: 0.3257 - val_accuracy: 0.8920\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.2226 - accuracy: 0.9234 - val_loss: 0.3427 - val_accuracy: 0.8880\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2145 - accuracy: 0.9189 - val_loss: 0.3171 - val_accuracy: 0.8933\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1862 - accuracy: 0.9349 - val_loss: 0.3864 - val_accuracy: 0.8947\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.2130 - accuracy: 0.9331 - val_loss: 0.3335 - val_accuracy: 0.8760\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1918 - accuracy: 0.9331 - val_loss: 0.2047 - val_accuracy: 0.9133\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2039 - accuracy: 0.9360 - val_loss: 0.2073 - val_accuracy: 0.9187\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1947 - accuracy: 0.9337 - val_loss: 0.2764 - val_accuracy: 0.9040\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.2001 - accuracy: 0.9263 - val_loss: 0.2421 - val_accuracy: 0.8933\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1810 - accuracy: 0.9343 - val_loss: 0.2743 - val_accuracy: 0.9013\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2169 - accuracy: 0.9423 - val_loss: 0.2475 - val_accuracy: 0.9000\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1764 - accuracy: 0.9434 - val_loss: 0.2924 - val_accuracy: 0.9013\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1718 - accuracy: 0.9417 - val_loss: 0.2926 - val_accuracy: 0.9000\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1853 - accuracy: 0.9383 - val_loss: 0.2343 - val_accuracy: 0.9187\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1779 - accuracy: 0.9406 - val_loss: 0.3672 - val_accuracy: 0.8920\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1779 - accuracy: 0.9423 - val_loss: 0.2704 - val_accuracy: 0.8987\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1861 - accuracy: 0.9389 - val_loss: 0.2390 - val_accuracy: 0.9093\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1885 - accuracy: 0.9383 - val_loss: 0.2574 - val_accuracy: 0.9147\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1798 - accuracy: 0.9377 - val_loss: 0.1845 - val_accuracy: 0.9373\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.1928 - accuracy: 0.9360 - val_loss: 0.2210 - val_accuracy: 0.9213\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1815 - accuracy: 0.9406 - val_loss: 0.2539 - val_accuracy: 0.9067\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1638 - accuracy: 0.9469 - val_loss: 0.2150 - val_accuracy: 0.9280\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1609 - accuracy: 0.9417 - val_loss: 0.2180 - val_accuracy: 0.9147\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1641 - accuracy: 0.9423 - val_loss: 0.2130 - val_accuracy: 0.9213\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1558 - accuracy: 0.9497 - val_loss: 0.2690 - val_accuracy: 0.9187\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1780 - accuracy: 0.9389 - val_loss: 0.3003 - val_accuracy: 0.9053\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1831 - accuracy: 0.9377 - val_loss: 0.2297 - val_accuracy: 0.9213\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1828 - accuracy: 0.9309 - val_loss: 0.1823 - val_accuracy: 0.9267\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1788 - accuracy: 0.9429 - val_loss: 0.2868 - val_accuracy: 0.8973\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1526 - accuracy: 0.9497 - val_loss: 0.1777 - val_accuracy: 0.9293\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1743 - accuracy: 0.9423 - val_loss: 0.5717 - val_accuracy: 0.8387\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1679 - accuracy: 0.9457 - val_loss: 0.2041 - val_accuracy: 0.9347\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1698 - accuracy: 0.9509 - val_loss: 0.3241 - val_accuracy: 0.9040\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1637 - accuracy: 0.9503 - val_loss: 0.2530 - val_accuracy: 0.9053\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1744 - accuracy: 0.9480 - val_loss: 0.2373 - val_accuracy: 0.9187\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1808 - accuracy: 0.9400 - val_loss: 0.2301 - val_accuracy: 0.9293\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1588 - accuracy: 0.9526 - val_loss: 0.2542 - val_accuracy: 0.9000\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1595 - accuracy: 0.9486 - val_loss: 0.2779 - val_accuracy: 0.9160\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1533 - accuracy: 0.9543 - val_loss: 0.2609 - val_accuracy: 0.9120\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1444 - accuracy: 0.9531 - val_loss: 0.2395 - val_accuracy: 0.9160\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1440 - accuracy: 0.9526 - val_loss: 0.2159 - val_accuracy: 0.9240\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1800 - accuracy: 0.9503 - val_loss: 0.1761 - val_accuracy: 0.9400\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1664 - accuracy: 0.9463 - val_loss: 0.2419 - val_accuracy: 0.9133\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1587 - accuracy: 0.9486 - val_loss: 0.2042 - val_accuracy: 0.9240\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1357 - accuracy: 0.9571 - val_loss: 0.2101 - val_accuracy: 0.9200\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1566 - accuracy: 0.9497 - val_loss: 0.2199 - val_accuracy: 0.9227\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1481 - accuracy: 0.9549 - val_loss: 0.2468 - val_accuracy: 0.9053\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1503 - accuracy: 0.9526 - val_loss: 0.2768 - val_accuracy: 0.8987\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1367 - accuracy: 0.9543 - val_loss: 0.2115 - val_accuracy: 0.9267\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1520 - accuracy: 0.9503 - val_loss: 0.3659 - val_accuracy: 0.8787\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1412 - accuracy: 0.9629 - val_loss: 0.3632 - val_accuracy: 0.8867\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1444 - accuracy: 0.9537 - val_loss: 0.2332 - val_accuracy: 0.9240\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1920 - accuracy: 0.9549 - val_loss: 0.2024 - val_accuracy: 0.9293\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1671 - accuracy: 0.9474 - val_loss: 0.4220 - val_accuracy: 0.8573\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1548 - accuracy: 0.9514 - val_loss: 0.1560 - val_accuracy: 0.9440\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1516 - accuracy: 0.9520 - val_loss: 0.2201 - val_accuracy: 0.9200\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1383 - accuracy: 0.9543 - val_loss: 0.1767 - val_accuracy: 0.9400\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1264 - accuracy: 0.9634 - val_loss: 0.1861 - val_accuracy: 0.9373\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1372 - accuracy: 0.9526 - val_loss: 0.3410 - val_accuracy: 0.8813\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1289 - accuracy: 0.9571 - val_loss: 0.1758 - val_accuracy: 0.9400\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1171 - accuracy: 0.9600 - val_loss: 0.1884 - val_accuracy: 0.9320\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1430 - accuracy: 0.9531 - val_loss: 0.1835 - val_accuracy: 0.9400\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1253 - accuracy: 0.9589 - val_loss: 0.2179 - val_accuracy: 0.9280\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1283 - accuracy: 0.9611 - val_loss: 0.2377 - val_accuracy: 0.9067\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1403 - accuracy: 0.9537 - val_loss: 0.3576 - val_accuracy: 0.8760\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1326 - accuracy: 0.9577 - val_loss: 0.1677 - val_accuracy: 0.9467\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1347 - accuracy: 0.9531 - val_loss: 0.2760 - val_accuracy: 0.9013\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1418 - accuracy: 0.9514 - val_loss: 0.1900 - val_accuracy: 0.9373\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1189 - accuracy: 0.9594 - val_loss: 0.1687 - val_accuracy: 0.9427\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1297 - accuracy: 0.9606 - val_loss: 0.2470 - val_accuracy: 0.9107\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1197 - accuracy: 0.9600 - val_loss: 0.2125 - val_accuracy: 0.9267\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1248 - accuracy: 0.9594 - val_loss: 0.1805 - val_accuracy: 0.9400\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.1278 - accuracy: 0.9657 - val_loss: 0.2085 - val_accuracy: 0.9333\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1148 - accuracy: 0.9646 - val_loss: 0.1856 - val_accuracy: 0.9373\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 16s 144ms/step - loss: 0.1340 - accuracy: 0.9611 - val_loss: 0.1927 - val_accuracy: 0.9320\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1184 - accuracy: 0.9640 - val_loss: 0.1888 - val_accuracy: 0.9307\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1224 - accuracy: 0.9589 - val_loss: 0.2165 - val_accuracy: 0.9240\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1143 - accuracy: 0.9623 - val_loss: 0.2040 - val_accuracy: 0.9307\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1137 - accuracy: 0.9640 - val_loss: 0.1960 - val_accuracy: 0.9280\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1198 - accuracy: 0.9629 - val_loss: 0.1919 - val_accuracy: 0.9373\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1303 - accuracy: 0.9566 - val_loss: 0.3187 - val_accuracy: 0.8907\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1201 - accuracy: 0.9623 - val_loss: 0.1373 - val_accuracy: 0.9507\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1208 - accuracy: 0.9617 - val_loss: 0.6284 - val_accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1334 - accuracy: 0.9566 - val_loss: 0.1480 - val_accuracy: 0.9520\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1126 - accuracy: 0.9657 - val_loss: 0.1427 - val_accuracy: 0.9533\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1157 - accuracy: 0.9669 - val_loss: 0.2519 - val_accuracy: 0.9093\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1165 - accuracy: 0.9651 - val_loss: 0.1499 - val_accuracy: 0.9520\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1287 - accuracy: 0.9640 - val_loss: 0.1858 - val_accuracy: 0.9427\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1337 - accuracy: 0.9566 - val_loss: 0.1963 - val_accuracy: 0.9267\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1234 - accuracy: 0.9617 - val_loss: 0.2619 - val_accuracy: 0.9027\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1183 - accuracy: 0.9617 - val_loss: 0.1558 - val_accuracy: 0.9493\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1150 - accuracy: 0.9623 - val_loss: 0.2019 - val_accuracy: 0.9347\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1157 - accuracy: 0.9663 - val_loss: 0.1698 - val_accuracy: 0.9387\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1072 - accuracy: 0.9640 - val_loss: 0.1899 - val_accuracy: 0.9293\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1151 - accuracy: 0.9663 - val_loss: 0.1423 - val_accuracy: 0.9573\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1034 - accuracy: 0.9663 - val_loss: 0.1949 - val_accuracy: 0.9320\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1370 - accuracy: 0.9674 - val_loss: 0.2577 - val_accuracy: 0.8973\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1316 - accuracy: 0.9583 - val_loss: 0.1407 - val_accuracy: 0.9507\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1011 - accuracy: 0.9663 - val_loss: 0.1942 - val_accuracy: 0.9347\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1189 - accuracy: 0.9611 - val_loss: 0.1893 - val_accuracy: 0.9373\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1054 - accuracy: 0.9663 - val_loss: 0.1402 - val_accuracy: 0.9520\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1125 - accuracy: 0.9651 - val_loss: 0.2387 - val_accuracy: 0.9160\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1017 - accuracy: 0.9680 - val_loss: 0.1604 - val_accuracy: 0.9467\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1113 - accuracy: 0.9640 - val_loss: 0.1452 - val_accuracy: 0.9520\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1141 - accuracy: 0.9674 - val_loss: 0.1960 - val_accuracy: 0.9360\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1131 - accuracy: 0.9669 - val_loss: 0.1278 - val_accuracy: 0.9547\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0994 - accuracy: 0.9680 - val_loss: 0.1795 - val_accuracy: 0.9400\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1000 - accuracy: 0.9697 - val_loss: 0.1648 - val_accuracy: 0.9400\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1142 - accuracy: 0.9680 - val_loss: 0.2304 - val_accuracy: 0.9067\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1044 - accuracy: 0.9680 - val_loss: 0.1573 - val_accuracy: 0.9453\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1040 - accuracy: 0.9691 - val_loss: 0.1672 - val_accuracy: 0.9480\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1218 - accuracy: 0.9589 - val_loss: 0.1586 - val_accuracy: 0.9493\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.0998 - accuracy: 0.9669 - val_loss: 0.1407 - val_accuracy: 0.9520\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1026 - accuracy: 0.9663 - val_loss: 0.2934 - val_accuracy: 0.9120\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1151 - accuracy: 0.9640 - val_loss: 0.1410 - val_accuracy: 0.9480\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1257 - accuracy: 0.9686 - val_loss: 0.5479 - val_accuracy: 0.7933\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1194 - accuracy: 0.9600 - val_loss: 0.1544 - val_accuracy: 0.9427\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1029 - accuracy: 0.9709 - val_loss: 0.1538 - val_accuracy: 0.9440\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1157 - accuracy: 0.9669 - val_loss: 0.2118 - val_accuracy: 0.9373\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1056 - accuracy: 0.9674 - val_loss: 0.1524 - val_accuracy: 0.9547\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 16s 145ms/step - loss: 0.1012 - accuracy: 0.9680 - val_loss: 0.1829 - val_accuracy: 0.9413\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0979 - accuracy: 0.9703 - val_loss: 0.1740 - val_accuracy: 0.9480\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1184 - accuracy: 0.9674 - val_loss: 0.4940 - val_accuracy: 0.8733\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1180 - accuracy: 0.9623 - val_loss: 0.1390 - val_accuracy: 0.9533\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0993 - accuracy: 0.9714 - val_loss: 0.1531 - val_accuracy: 0.9453\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0921 - accuracy: 0.9691 - val_loss: 0.1970 - val_accuracy: 0.9293\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1035 - accuracy: 0.9663 - val_loss: 0.2223 - val_accuracy: 0.9200\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0888 - accuracy: 0.9726 - val_loss: 0.1613 - val_accuracy: 0.9520\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.1094 - accuracy: 0.9657 - val_loss: 0.1613 - val_accuracy: 0.9467\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1099 - accuracy: 0.9697 - val_loss: 0.1340 - val_accuracy: 0.9520\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1165 - accuracy: 0.9651 - val_loss: 0.1683 - val_accuracy: 0.9453\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 4)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 51s - loss: 19.9034 - accuracy: 0.2812WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0863s vs `on_train_batch_end` time: 0.7811s). Check your callbacks.\n",
      "110/110 [==============================] - 19s 176ms/step - loss: 1.6700 - accuracy: 0.7389 - val_loss: 0.8175 - val_accuracy: 0.6280\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.5170 - accuracy: 0.8223 - val_loss: 0.5902 - val_accuracy: 0.6267\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3773 - accuracy: 0.8406 - val_loss: 0.6631 - val_accuracy: 0.6733\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3760 - accuracy: 0.8691 - val_loss: 1.3923 - val_accuracy: 0.4840\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.3026 - accuracy: 0.8886 - val_loss: 0.3460 - val_accuracy: 0.8653\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2828 - accuracy: 0.9017 - val_loss: 0.4231 - val_accuracy: 0.8333\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2763 - accuracy: 0.9149 - val_loss: 1.2737 - val_accuracy: 0.7653\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2387 - accuracy: 0.9223 - val_loss: 0.7649 - val_accuracy: 0.7533\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2164 - accuracy: 0.9337 - val_loss: 0.6622 - val_accuracy: 0.7693\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3418 - accuracy: 0.9177 - val_loss: 31.8413 - val_accuracy: 0.7320\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.3524 - accuracy: 0.9131 - val_loss: 0.4724 - val_accuracy: 0.7947\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.5976 - accuracy: 0.8709 - val_loss: 0.9738 - val_accuracy: 0.7333\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.4135 - accuracy: 0.8657 - val_loss: 1.4269 - val_accuracy: 0.7467\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3217 - accuracy: 0.8966 - val_loss: 0.5278 - val_accuracy: 0.8227\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2202 - accuracy: 0.9280 - val_loss: 0.3928 - val_accuracy: 0.8493\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2461 - accuracy: 0.9131 - val_loss: 0.3990 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2500 - accuracy: 0.9246 - val_loss: 0.8868 - val_accuracy: 0.7133\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1958 - accuracy: 0.9331 - val_loss: 0.6639 - val_accuracy: 0.7600\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2001 - accuracy: 0.9366 - val_loss: 0.3668 - val_accuracy: 0.8467\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1863 - accuracy: 0.9429 - val_loss: 0.6178 - val_accuracy: 0.7667\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1863 - accuracy: 0.9417 - val_loss: 0.4044 - val_accuracy: 0.8360\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1820 - accuracy: 0.9417 - val_loss: 0.3889 - val_accuracy: 0.8373\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1710 - accuracy: 0.9474 - val_loss: 0.4505 - val_accuracy: 0.8107\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1918 - accuracy: 0.9377 - val_loss: 0.6515 - val_accuracy: 0.7493\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1677 - accuracy: 0.9434 - val_loss: 0.6171 - val_accuracy: 0.7573\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1646 - accuracy: 0.9514 - val_loss: 0.4950 - val_accuracy: 0.7787\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1964 - accuracy: 0.9434 - val_loss: 0.6585 - val_accuracy: 0.6960\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.2105 - accuracy: 0.9434 - val_loss: 0.6038 - val_accuracy: 0.8147\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2007 - accuracy: 0.9469 - val_loss: 0.5468 - val_accuracy: 0.8173\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1996 - accuracy: 0.9457 - val_loss: 0.5221 - val_accuracy: 0.7867\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1765 - accuracy: 0.9469 - val_loss: 0.5978 - val_accuracy: 0.8253\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1735 - accuracy: 0.9451 - val_loss: 0.6015 - val_accuracy: 0.8320\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1723 - accuracy: 0.9469 - val_loss: 0.4394 - val_accuracy: 0.8293\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1553 - accuracy: 0.9549 - val_loss: 0.7234 - val_accuracy: 0.7387\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1496 - accuracy: 0.9491 - val_loss: 0.8790 - val_accuracy: 0.6747\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1456 - accuracy: 0.9560 - val_loss: 0.5515 - val_accuracy: 0.8160\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1473 - accuracy: 0.9543 - val_loss: 0.4362 - val_accuracy: 0.8227\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1785 - accuracy: 0.9503 - val_loss: 0.4799 - val_accuracy: 0.8373\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1712 - accuracy: 0.9509 - val_loss: 0.4867 - val_accuracy: 0.8507\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1634 - accuracy: 0.9549 - val_loss: 0.3826 - val_accuracy: 0.8467\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1562 - accuracy: 0.9543 - val_loss: 0.4107 - val_accuracy: 0.8493\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1586 - accuracy: 0.9537 - val_loss: 0.4721 - val_accuracy: 0.8373\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1384 - accuracy: 0.9560 - val_loss: 0.5284 - val_accuracy: 0.7987\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1578 - accuracy: 0.9514 - val_loss: 0.4134 - val_accuracy: 0.8613\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1285 - accuracy: 0.9566 - val_loss: 0.3599 - val_accuracy: 0.8787\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2007 - accuracy: 0.9366 - val_loss: 2.1768 - val_accuracy: 0.7413\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1928 - accuracy: 0.9417 - val_loss: 0.6340 - val_accuracy: 0.7627\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1878 - accuracy: 0.9446 - val_loss: 0.4881 - val_accuracy: 0.8213\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1518 - accuracy: 0.9594 - val_loss: 0.6593 - val_accuracy: 0.7627\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1464 - accuracy: 0.9571 - val_loss: 0.4345 - val_accuracy: 0.8480\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1308 - accuracy: 0.9617 - val_loss: 0.6690 - val_accuracy: 0.7893\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1493 - accuracy: 0.9537 - val_loss: 0.7018 - val_accuracy: 0.7507\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1587 - accuracy: 0.9440 - val_loss: 0.7160 - val_accuracy: 0.8080\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1460 - accuracy: 0.9611 - val_loss: 0.5136 - val_accuracy: 0.8267\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1388 - accuracy: 0.9589 - val_loss: 0.4223 - val_accuracy: 0.8307\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1530 - accuracy: 0.9537 - val_loss: 0.7432 - val_accuracy: 0.7773\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1412 - accuracy: 0.9566 - val_loss: 0.6085 - val_accuracy: 0.7200\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1398 - accuracy: 0.9520 - val_loss: 0.7489 - val_accuracy: 0.6987\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1254 - accuracy: 0.9583 - val_loss: 0.6482 - val_accuracy: 0.7267\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1228 - accuracy: 0.9606 - val_loss: 0.6186 - val_accuracy: 0.7520\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1260 - accuracy: 0.9629 - val_loss: 0.5595 - val_accuracy: 0.7933\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1064 - accuracy: 0.9663 - val_loss: 0.7952 - val_accuracy: 0.7640\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1143 - accuracy: 0.9651 - val_loss: 0.5477 - val_accuracy: 0.7933\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1197 - accuracy: 0.9589 - val_loss: 0.6118 - val_accuracy: 0.7827\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1449 - accuracy: 0.9560 - val_loss: 0.3027 - val_accuracy: 0.8880\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1181 - accuracy: 0.9617 - val_loss: 0.7055 - val_accuracy: 0.8027\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1727 - accuracy: 0.9537 - val_loss: 0.5170 - val_accuracy: 0.8200\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1162 - accuracy: 0.9646 - val_loss: 0.6327 - val_accuracy: 0.7227\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1322 - accuracy: 0.9543 - val_loss: 0.8253 - val_accuracy: 0.7320\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1358 - accuracy: 0.9600 - val_loss: 0.3735 - val_accuracy: 0.8573\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1328 - accuracy: 0.9611 - val_loss: 0.4918 - val_accuracy: 0.8320\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1245 - accuracy: 0.9623 - val_loss: 0.5916 - val_accuracy: 0.7453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200\n",
      "110/110 [==============================] - 17s 156ms/step - loss: 0.1300 - accuracy: 0.9623 - val_loss: 0.6815 - val_accuracy: 0.7293\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1096 - accuracy: 0.9640 - val_loss: 0.5964 - val_accuracy: 0.7573\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1170 - accuracy: 0.9674 - val_loss: 0.5524 - val_accuracy: 0.8107\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1107 - accuracy: 0.9697 - val_loss: 0.3283 - val_accuracy: 0.8747\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1239 - accuracy: 0.9600 - val_loss: 1.3980 - val_accuracy: 0.6000\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0956 - accuracy: 0.9703 - val_loss: 0.7962 - val_accuracy: 0.7360\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1041 - accuracy: 0.9680 - val_loss: 0.7572 - val_accuracy: 0.7173\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0921 - accuracy: 0.9703 - val_loss: 0.6810 - val_accuracy: 0.8027\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1062 - accuracy: 0.9703 - val_loss: 0.5511 - val_accuracy: 0.8027\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1091 - accuracy: 0.9663 - val_loss: 0.4445 - val_accuracy: 0.8493\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1060 - accuracy: 0.9697 - val_loss: 0.4961 - val_accuracy: 0.8093\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0913 - accuracy: 0.9714 - val_loss: 0.8081 - val_accuracy: 0.7547\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1157 - accuracy: 0.9657 - val_loss: 0.8623 - val_accuracy: 0.7147\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1172 - accuracy: 0.9651 - val_loss: 0.6086 - val_accuracy: 0.8080\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1022 - accuracy: 0.9663 - val_loss: 0.7682 - val_accuracy: 0.7240\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0907 - accuracy: 0.9703 - val_loss: 1.0460 - val_accuracy: 0.7067\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0999 - accuracy: 0.9663 - val_loss: 0.4997 - val_accuracy: 0.8520\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1146 - accuracy: 0.9686 - val_loss: 0.8554 - val_accuracy: 0.7520\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1168 - accuracy: 0.9640 - val_loss: 0.8387 - val_accuracy: 0.7347\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1070 - accuracy: 0.9686 - val_loss: 0.6225 - val_accuracy: 0.7333\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1039 - accuracy: 0.9709 - val_loss: 0.7717 - val_accuracy: 0.7747\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1016 - accuracy: 0.9669 - val_loss: 1.0275 - val_accuracy: 0.6667\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1026 - accuracy: 0.9709 - val_loss: 0.6289 - val_accuracy: 0.7853\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0999 - accuracy: 0.9703 - val_loss: 0.6033 - val_accuracy: 0.7867\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0865 - accuracy: 0.9760 - val_loss: 0.8052 - val_accuracy: 0.7587\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0967 - accuracy: 0.9697 - val_loss: 0.8513 - val_accuracy: 0.7453\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1030 - accuracy: 0.9674 - val_loss: 0.8103 - val_accuracy: 0.7200\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0940 - accuracy: 0.9749 - val_loss: 0.7899 - val_accuracy: 0.7667\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0974 - accuracy: 0.9720 - val_loss: 1.1197 - val_accuracy: 0.6133\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0954 - accuracy: 0.9720 - val_loss: 0.7998 - val_accuracy: 0.7187\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0953 - accuracy: 0.9743 - val_loss: 0.9714 - val_accuracy: 0.6760\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0972 - accuracy: 0.9760 - val_loss: 0.6540 - val_accuracy: 0.7533\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0957 - accuracy: 0.9720 - val_loss: 0.7604 - val_accuracy: 0.7613\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0827 - accuracy: 0.9749 - val_loss: 0.6119 - val_accuracy: 0.7933\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1024 - accuracy: 0.9709 - val_loss: 0.7606 - val_accuracy: 0.7800\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1015 - accuracy: 0.9703 - val_loss: 0.4106 - val_accuracy: 0.8387\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0930 - accuracy: 0.9743 - val_loss: 0.4002 - val_accuracy: 0.8627\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0909 - accuracy: 0.9737 - val_loss: 0.7477 - val_accuracy: 0.7707\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1257 - accuracy: 0.9674 - val_loss: 0.8189 - val_accuracy: 0.7760\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0800 - accuracy: 0.9777 - val_loss: 0.5960 - val_accuracy: 0.8080\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0865 - accuracy: 0.9760 - val_loss: 0.4736 - val_accuracy: 0.8600\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0851 - accuracy: 0.9771 - val_loss: 0.5962 - val_accuracy: 0.8253\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1091 - accuracy: 0.9686 - val_loss: 0.7133 - val_accuracy: 0.7667\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0931 - accuracy: 0.9697 - val_loss: 0.3686 - val_accuracy: 0.8600\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0835 - accuracy: 0.9731 - val_loss: 0.5671 - val_accuracy: 0.7867\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0939 - accuracy: 0.9709 - val_loss: 0.6605 - val_accuracy: 0.7960\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0845 - accuracy: 0.9737 - val_loss: 0.7498 - val_accuracy: 0.7880\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1041 - accuracy: 0.9691 - val_loss: 0.4507 - val_accuracy: 0.8573\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0918 - accuracy: 0.9703 - val_loss: 0.7517 - val_accuracy: 0.7307\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0907 - accuracy: 0.9714 - val_loss: 0.8683 - val_accuracy: 0.7240\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1022 - accuracy: 0.9726 - val_loss: 1.1952 - val_accuracy: 0.6893\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0937 - accuracy: 0.9714 - val_loss: 0.6927 - val_accuracy: 0.7680\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1410 - accuracy: 0.9617 - val_loss: 0.8584 - val_accuracy: 0.7400\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1178 - accuracy: 0.9680 - val_loss: 0.6340 - val_accuracy: 0.8093\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1013 - accuracy: 0.9703 - val_loss: 0.8352 - val_accuracy: 0.7707\n",
      "Epoch 128/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0948 - accuracy: 0.9749 - val_loss: 0.9012 - val_accuracy: 0.7227\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0936 - accuracy: 0.9743 - val_loss: 0.8454 - val_accuracy: 0.7427\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0997 - accuracy: 0.9731 - val_loss: 0.5683 - val_accuracy: 0.8120\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0861 - accuracy: 0.9789 - val_loss: 0.8926 - val_accuracy: 0.7333\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0988 - accuracy: 0.9726 - val_loss: 0.8049 - val_accuracy: 0.7920\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0876 - accuracy: 0.9737 - val_loss: 0.7338 - val_accuracy: 0.7787\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0662 - accuracy: 0.9800 - val_loss: 0.7936 - val_accuracy: 0.7573\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0721 - accuracy: 0.9789 - val_loss: 0.5467 - val_accuracy: 0.8293\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0745 - accuracy: 0.9743 - val_loss: 0.5690 - val_accuracy: 0.8147\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0765 - accuracy: 0.9749 - val_loss: 0.7343 - val_accuracy: 0.7747\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0753 - accuracy: 0.9777 - val_loss: 0.6286 - val_accuracy: 0.7973\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0630 - accuracy: 0.9851 - val_loss: 0.7218 - val_accuracy: 0.7987\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0780 - accuracy: 0.9766 - val_loss: 0.7606 - val_accuracy: 0.8053\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0674 - accuracy: 0.9800 - val_loss: 0.6331 - val_accuracy: 0.7933\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0679 - accuracy: 0.9789 - val_loss: 0.5984 - val_accuracy: 0.8280\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0893 - accuracy: 0.9766 - val_loss: 0.6031 - val_accuracy: 0.7933\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0861 - accuracy: 0.9749 - val_loss: 0.4616 - val_accuracy: 0.8267\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0883 - accuracy: 0.9760 - val_loss: 0.5398 - val_accuracy: 0.8293\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0789 - accuracy: 0.9760 - val_loss: 0.9571 - val_accuracy: 0.7173\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0966 - accuracy: 0.9697 - val_loss: 0.4922 - val_accuracy: 0.8013\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0765 - accuracy: 0.9737 - val_loss: 0.7307 - val_accuracy: 0.7720\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0848 - accuracy: 0.9737 - val_loss: 0.7706 - val_accuracy: 0.7747\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0788 - accuracy: 0.9800 - val_loss: 0.4650 - val_accuracy: 0.8307\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0605 - accuracy: 0.9817 - val_loss: 0.5247 - val_accuracy: 0.8253\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1064 - accuracy: 0.9760 - val_loss: 0.6297 - val_accuracy: 0.7800\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0723 - accuracy: 0.9766 - val_loss: 0.8251 - val_accuracy: 0.7480\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0861 - accuracy: 0.9766 - val_loss: 0.7649 - val_accuracy: 0.7707\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0695 - accuracy: 0.9817 - val_loss: 0.6421 - val_accuracy: 0.8147\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0680 - accuracy: 0.9789 - val_loss: 0.4923 - val_accuracy: 0.8453\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0806 - accuracy: 0.9777 - val_loss: 0.4369 - val_accuracy: 0.8560\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0715 - accuracy: 0.9766 - val_loss: 0.4251 - val_accuracy: 0.8627\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0554 - accuracy: 0.9823 - val_loss: 0.5171 - val_accuracy: 0.8467\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0710 - accuracy: 0.9760 - val_loss: 0.4754 - val_accuracy: 0.8427\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0922 - accuracy: 0.9743 - val_loss: 0.7217 - val_accuracy: 0.8053\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0664 - accuracy: 0.9800 - val_loss: 0.5168 - val_accuracy: 0.8427\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0581 - accuracy: 0.9857 - val_loss: 0.7361 - val_accuracy: 0.8133\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0638 - accuracy: 0.9840 - val_loss: 0.4895 - val_accuracy: 0.8667\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0717 - accuracy: 0.9783 - val_loss: 0.6242 - val_accuracy: 0.8267\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0684 - accuracy: 0.9800 - val_loss: 0.5088 - val_accuracy: 0.8400\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0709 - accuracy: 0.9811 - val_loss: 0.7090 - val_accuracy: 0.8080\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0577 - accuracy: 0.9817 - val_loss: 0.5493 - val_accuracy: 0.8560\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0518 - accuracy: 0.9874 - val_loss: 0.7044 - val_accuracy: 0.8080\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0639 - accuracy: 0.9829 - val_loss: 0.7154 - val_accuracy: 0.8293\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0786 - accuracy: 0.9794 - val_loss: 0.8364 - val_accuracy: 0.7640\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0711 - accuracy: 0.9783 - val_loss: 0.5638 - val_accuracy: 0.8373\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0772 - accuracy: 0.9783 - val_loss: 0.5026 - val_accuracy: 0.8267\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0737 - accuracy: 0.9783 - val_loss: 0.7904 - val_accuracy: 0.7893\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0899 - accuracy: 0.9760 - val_loss: 0.4922 - val_accuracy: 0.8400\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0675 - accuracy: 0.9794 - val_loss: 0.7932 - val_accuracy: 0.8080\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0589 - accuracy: 0.9840 - val_loss: 0.7770 - val_accuracy: 0.8120\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0682 - accuracy: 0.9817 - val_loss: 0.7447 - val_accuracy: 0.8307\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0855 - accuracy: 0.9783 - val_loss: 0.4229 - val_accuracy: 0.8613\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0950 - accuracy: 0.9714 - val_loss: 0.4021 - val_accuracy: 0.8693\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0779 - accuracy: 0.9777 - val_loss: 1.0588 - val_accuracy: 0.6973\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0801 - accuracy: 0.9766 - val_loss: 0.6820 - val_accuracy: 0.7907\n",
      "Epoch 183/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0662 - accuracy: 0.9823 - val_loss: 0.8622 - val_accuracy: 0.7720\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0685 - accuracy: 0.9800 - val_loss: 0.5975 - val_accuracy: 0.8427\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0772 - accuracy: 0.9743 - val_loss: 0.7677 - val_accuracy: 0.8040\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0660 - accuracy: 0.9783 - val_loss: 0.6654 - val_accuracy: 0.8227\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0689 - accuracy: 0.9817 - val_loss: 0.6811 - val_accuracy: 0.8307\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0709 - accuracy: 0.9811 - val_loss: 0.6456 - val_accuracy: 0.8027\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0718 - accuracy: 0.9800 - val_loss: 0.6892 - val_accuracy: 0.7867\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0650 - accuracy: 0.9811 - val_loss: 0.9687 - val_accuracy: 0.7613\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0653 - accuracy: 0.9794 - val_loss: 0.5178 - val_accuracy: 0.8293\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0963 - accuracy: 0.9731 - val_loss: 0.6863 - val_accuracy: 0.7680\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0638 - accuracy: 0.9794 - val_loss: 0.6944 - val_accuracy: 0.8067\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0730 - accuracy: 0.9800 - val_loss: 0.9733 - val_accuracy: 0.7453\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0690 - accuracy: 0.9811 - val_loss: 0.3557 - val_accuracy: 0.8707\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0641 - accuracy: 0.9840 - val_loss: 0.5514 - val_accuracy: 0.8480\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0665 - accuracy: 0.9800 - val_loss: 0.6145 - val_accuracy: 0.8160\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0765 - accuracy: 0.9800 - val_loss: 0.6349 - val_accuracy: 0.8347\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0572 - accuracy: 0.9806 - val_loss: 0.7262 - val_accuracy: 0.8067\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0501 - accuracy: 0.9874 - val_loss: 0.7267 - val_accuracy: 0.8267\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 4)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 49s - loss: 1.0301 - accuracy: 0.7812WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0952s vs `on_train_batch_end` time: 0.7811s). Check your callbacks.\n",
      "110/110 [==============================] - 19s 176ms/step - loss: 0.8074 - accuracy: 0.7829 - val_loss: 0.6491 - val_accuracy: 0.6280\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.6463 - accuracy: 0.8011 - val_loss: 0.7922 - val_accuracy: 0.6280\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.6404 - accuracy: 0.8069 - val_loss: 1.3627 - val_accuracy: 0.5547\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.4338 - accuracy: 0.8554 - val_loss: 4.3278 - val_accuracy: 0.6240\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.5321 - accuracy: 0.8389 - val_loss: 1.4214 - val_accuracy: 0.6333\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3475 - accuracy: 0.8680 - val_loss: 6.7816 - val_accuracy: 0.6640\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.4196 - accuracy: 0.8549 - val_loss: 3.6326 - val_accuracy: 0.7293\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3018 - accuracy: 0.8874 - val_loss: 10.0474 - val_accuracy: 0.6893\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2954 - accuracy: 0.8954 - val_loss: 4.5779 - val_accuracy: 0.7480\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2819 - accuracy: 0.8966 - val_loss: 2.5544 - val_accuracy: 0.8453\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2634 - accuracy: 0.9034 - val_loss: 1.9176 - val_accuracy: 0.7653\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2386 - accuracy: 0.9183 - val_loss: 1.6726 - val_accuracy: 0.7987\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2320 - accuracy: 0.9240 - val_loss: 1.2040 - val_accuracy: 0.7867\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.2094 - accuracy: 0.9297 - val_loss: 1.3185 - val_accuracy: 0.6933\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2157 - accuracy: 0.9280 - val_loss: 1.0543 - val_accuracy: 0.7560\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2251 - accuracy: 0.9274 - val_loss: 0.5949 - val_accuracy: 0.7307\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2082 - accuracy: 0.9354 - val_loss: 0.4477 - val_accuracy: 0.8360\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1909 - accuracy: 0.9377 - val_loss: 0.5733 - val_accuracy: 0.8293\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2048 - accuracy: 0.9389 - val_loss: 0.4773 - val_accuracy: 0.8107\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1734 - accuracy: 0.9520 - val_loss: 0.8818 - val_accuracy: 0.7453\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1923 - accuracy: 0.9423 - val_loss: 0.4780 - val_accuracy: 0.8027\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1752 - accuracy: 0.9457 - val_loss: 0.4628 - val_accuracy: 0.8200\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1604 - accuracy: 0.9451 - val_loss: 0.6650 - val_accuracy: 0.7107\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2000 - accuracy: 0.9457 - val_loss: 1.0419 - val_accuracy: 0.8267\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2117 - accuracy: 0.9349 - val_loss: 0.6519 - val_accuracy: 0.8227\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1912 - accuracy: 0.9371 - val_loss: 0.6217 - val_accuracy: 0.7947\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2520 - accuracy: 0.9389 - val_loss: 0.4631 - val_accuracy: 0.8107\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1701 - accuracy: 0.9497 - val_loss: 0.5926 - val_accuracy: 0.7880\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2189 - accuracy: 0.9411 - val_loss: 0.4888 - val_accuracy: 0.8333\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.3173 - accuracy: 0.9280 - val_loss: 0.3641 - val_accuracy: 0.8560\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1930 - accuracy: 0.9434 - val_loss: 0.4364 - val_accuracy: 0.8467\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.2016 - accuracy: 0.9491 - val_loss: 0.4043 - val_accuracy: 0.8280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1650 - accuracy: 0.9526 - val_loss: 0.6259 - val_accuracy: 0.7600\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1712 - accuracy: 0.9514 - val_loss: 0.3666 - val_accuracy: 0.8280\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1584 - accuracy: 0.9526 - val_loss: 0.4039 - val_accuracy: 0.8173\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1650 - accuracy: 0.9537 - val_loss: 0.7352 - val_accuracy: 0.7520\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1757 - accuracy: 0.9583 - val_loss: 0.5401 - val_accuracy: 0.7720\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1523 - accuracy: 0.9629 - val_loss: 0.5111 - val_accuracy: 0.8000\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1504 - accuracy: 0.9571 - val_loss: 0.5674 - val_accuracy: 0.7867\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1406 - accuracy: 0.9629 - val_loss: 0.5782 - val_accuracy: 0.7947\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1541 - accuracy: 0.9537 - val_loss: 0.5436 - val_accuracy: 0.7907\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1353 - accuracy: 0.9589 - val_loss: 0.6616 - val_accuracy: 0.7707\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1420 - accuracy: 0.9543 - val_loss: 0.5648 - val_accuracy: 0.8027\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1517 - accuracy: 0.9531 - val_loss: 0.6550 - val_accuracy: 0.7320\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1372 - accuracy: 0.9606 - val_loss: 0.3654 - val_accuracy: 0.8427\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1378 - accuracy: 0.9560 - val_loss: 0.5486 - val_accuracy: 0.7573\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1550 - accuracy: 0.9474 - val_loss: 0.4461 - val_accuracy: 0.7987\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1294 - accuracy: 0.9623 - val_loss: 0.6957 - val_accuracy: 0.7507\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1410 - accuracy: 0.9600 - val_loss: 0.6097 - val_accuracy: 0.7400\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1323 - accuracy: 0.9589 - val_loss: 0.7729 - val_accuracy: 0.7227\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1180 - accuracy: 0.9611 - val_loss: 0.9599 - val_accuracy: 0.6960\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1529 - accuracy: 0.9629 - val_loss: 0.6429 - val_accuracy: 0.7973\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1361 - accuracy: 0.9566 - val_loss: 0.5877 - val_accuracy: 0.7827\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1644 - accuracy: 0.9594 - val_loss: 0.7539 - val_accuracy: 0.7107\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1578 - accuracy: 0.9611 - val_loss: 0.8476 - val_accuracy: 0.6840\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1621 - accuracy: 0.9606 - val_loss: 0.9108 - val_accuracy: 0.7293\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1516 - accuracy: 0.9566 - val_loss: 0.8732 - val_accuracy: 0.7493\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1347 - accuracy: 0.9571 - val_loss: 0.6587 - val_accuracy: 0.7400\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1187 - accuracy: 0.9646 - val_loss: 0.4573 - val_accuracy: 0.8160\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1284 - accuracy: 0.9634 - val_loss: 0.5564 - val_accuracy: 0.7960\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1067 - accuracy: 0.9674 - val_loss: 0.6517 - val_accuracy: 0.8027\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1260 - accuracy: 0.9629 - val_loss: 0.7164 - val_accuracy: 0.7733\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1204 - accuracy: 0.9617 - val_loss: 0.7370 - val_accuracy: 0.7413\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1080 - accuracy: 0.9646 - val_loss: 0.4887 - val_accuracy: 0.8147\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1123 - accuracy: 0.9634 - val_loss: 0.5255 - val_accuracy: 0.8147\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0936 - accuracy: 0.9669 - val_loss: 0.5292 - val_accuracy: 0.8173\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1077 - accuracy: 0.9651 - val_loss: 0.9225 - val_accuracy: 0.6627\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1075 - accuracy: 0.9657 - val_loss: 0.4053 - val_accuracy: 0.8493\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1139 - accuracy: 0.9651 - val_loss: 0.8572 - val_accuracy: 0.6973\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 17s 156ms/step - loss: 0.1020 - accuracy: 0.9680 - val_loss: 0.3614 - val_accuracy: 0.8560\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1196 - accuracy: 0.9623 - val_loss: 0.6594 - val_accuracy: 0.7573\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1205 - accuracy: 0.9657 - val_loss: 0.3367 - val_accuracy: 0.8680\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1000 - accuracy: 0.9697 - val_loss: 0.7607 - val_accuracy: 0.7187\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1000 - accuracy: 0.9697 - val_loss: 0.5320 - val_accuracy: 0.7733\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1243 - accuracy: 0.9651 - val_loss: 0.3577 - val_accuracy: 0.8627\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1421 - accuracy: 0.9646 - val_loss: 0.4494 - val_accuracy: 0.8360\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1213 - accuracy: 0.9629 - val_loss: 0.6713 - val_accuracy: 0.7720\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1171 - accuracy: 0.9663 - val_loss: 0.4547 - val_accuracy: 0.8160\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1434 - accuracy: 0.9611 - val_loss: 0.4841 - val_accuracy: 0.8160\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1962 - accuracy: 0.9531 - val_loss: 0.4885 - val_accuracy: 0.8387\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1400 - accuracy: 0.9554 - val_loss: 0.3406 - val_accuracy: 0.8533\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1527 - accuracy: 0.9520 - val_loss: 0.4473 - val_accuracy: 0.8093\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1262 - accuracy: 0.9629 - val_loss: 0.4956 - val_accuracy: 0.8213\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1161 - accuracy: 0.9634 - val_loss: 0.4347 - val_accuracy: 0.8360\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1719 - accuracy: 0.9623 - val_loss: 0.8719 - val_accuracy: 0.7173\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1554 - accuracy: 0.9611 - val_loss: 0.7544 - val_accuracy: 0.7467\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1188 - accuracy: 0.9611 - val_loss: 0.8668 - val_accuracy: 0.7120\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1159 - accuracy: 0.9629 - val_loss: 0.6737 - val_accuracy: 0.7787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1108 - accuracy: 0.9669 - val_loss: 0.6875 - val_accuracy: 0.7627\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1257 - accuracy: 0.9617 - val_loss: 0.7264 - val_accuracy: 0.7493\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1243 - accuracy: 0.9663 - val_loss: 0.5016 - val_accuracy: 0.8013\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1144 - accuracy: 0.9629 - val_loss: 0.4596 - val_accuracy: 0.8227\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0976 - accuracy: 0.9714 - val_loss: 0.8398 - val_accuracy: 0.7347\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1098 - accuracy: 0.9651 - val_loss: 0.6972 - val_accuracy: 0.7307\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0996 - accuracy: 0.9686 - val_loss: 0.6600 - val_accuracy: 0.7413\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0890 - accuracy: 0.9691 - val_loss: 0.5215 - val_accuracy: 0.8013\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0996 - accuracy: 0.9754 - val_loss: 0.3322 - val_accuracy: 0.8733\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1006 - accuracy: 0.9743 - val_loss: 0.7499 - val_accuracy: 0.7307\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0974 - accuracy: 0.9703 - val_loss: 1.0428 - val_accuracy: 0.6707\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0970 - accuracy: 0.9731 - val_loss: 0.7412 - val_accuracy: 0.7613\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0886 - accuracy: 0.9743 - val_loss: 0.9638 - val_accuracy: 0.7067\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0778 - accuracy: 0.9766 - val_loss: 1.0807 - val_accuracy: 0.6827\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0932 - accuracy: 0.9737 - val_loss: 0.6152 - val_accuracy: 0.8000\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1024 - accuracy: 0.9623 - val_loss: 0.5656 - val_accuracy: 0.7947\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0898 - accuracy: 0.9754 - val_loss: 0.5726 - val_accuracy: 0.7960\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0862 - accuracy: 0.9754 - val_loss: 0.5695 - val_accuracy: 0.8160\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0922 - accuracy: 0.9726 - val_loss: 1.0391 - val_accuracy: 0.6987\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0874 - accuracy: 0.9731 - val_loss: 0.9186 - val_accuracy: 0.7600\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0909 - accuracy: 0.9731 - val_loss: 0.7932 - val_accuracy: 0.7480\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0835 - accuracy: 0.9766 - val_loss: 0.6261 - val_accuracy: 0.8067\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0920 - accuracy: 0.9749 - val_loss: 0.6571 - val_accuracy: 0.7760\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0888 - accuracy: 0.9714 - val_loss: 0.5146 - val_accuracy: 0.8280\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1000 - accuracy: 0.9674 - val_loss: 0.5946 - val_accuracy: 0.7880\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0966 - accuracy: 0.9686 - val_loss: 1.1748 - val_accuracy: 0.6800\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0864 - accuracy: 0.9731 - val_loss: 0.8091 - val_accuracy: 0.7280\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0816 - accuracy: 0.9737 - val_loss: 0.4788 - val_accuracy: 0.8240\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0910 - accuracy: 0.9737 - val_loss: 0.7269 - val_accuracy: 0.7573\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0829 - accuracy: 0.9737 - val_loss: 0.6637 - val_accuracy: 0.7320\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0777 - accuracy: 0.9766 - val_loss: 0.7626 - val_accuracy: 0.7440\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0902 - accuracy: 0.9754 - val_loss: 0.7647 - val_accuracy: 0.7547\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0909 - accuracy: 0.9731 - val_loss: 0.5115 - val_accuracy: 0.8267\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0804 - accuracy: 0.9743 - val_loss: 0.4387 - val_accuracy: 0.8547\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1063 - accuracy: 0.9743 - val_loss: 0.4354 - val_accuracy: 0.8387\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0890 - accuracy: 0.9720 - val_loss: 0.4909 - val_accuracy: 0.8227\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0968 - accuracy: 0.9714 - val_loss: 0.9804 - val_accuracy: 0.6800\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0828 - accuracy: 0.9760 - val_loss: 0.9632 - val_accuracy: 0.7240\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0779 - accuracy: 0.9789 - val_loss: 0.4721 - val_accuracy: 0.8413\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0852 - accuracy: 0.9714 - val_loss: 0.6709 - val_accuracy: 0.7867\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0886 - accuracy: 0.9726 - val_loss: 0.5416 - val_accuracy: 0.7987\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1520 - accuracy: 0.9674 - val_loss: 0.5906 - val_accuracy: 0.7827\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0867 - accuracy: 0.9726 - val_loss: 0.5756 - val_accuracy: 0.8173\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1024 - accuracy: 0.9749 - val_loss: 0.5391 - val_accuracy: 0.8147\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0860 - accuracy: 0.9766 - val_loss: 0.6793 - val_accuracy: 0.7640\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0795 - accuracy: 0.9794 - val_loss: 0.8025 - val_accuracy: 0.7333\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0870 - accuracy: 0.9714 - val_loss: 0.7835 - val_accuracy: 0.7507\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0827 - accuracy: 0.9800 - val_loss: 0.7034 - val_accuracy: 0.7493\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0808 - accuracy: 0.9771 - val_loss: 0.7378 - val_accuracy: 0.7507\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0788 - accuracy: 0.9743 - val_loss: 0.7083 - val_accuracy: 0.7680\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0734 - accuracy: 0.9811 - val_loss: 0.5033 - val_accuracy: 0.8067\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0645 - accuracy: 0.9794 - val_loss: 0.7766 - val_accuracy: 0.7413\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0743 - accuracy: 0.9766 - val_loss: 1.2099 - val_accuracy: 0.6573\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0893 - accuracy: 0.9714 - val_loss: 0.5115 - val_accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0768 - accuracy: 0.9800 - val_loss: 0.6558 - val_accuracy: 0.7907\n",
      "Epoch 144/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0756 - accuracy: 0.9766 - val_loss: 0.5015 - val_accuracy: 0.8320\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0808 - accuracy: 0.9749 - val_loss: 0.3748 - val_accuracy: 0.8440\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0723 - accuracy: 0.9783 - val_loss: 0.3825 - val_accuracy: 0.8733\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0708 - accuracy: 0.9777 - val_loss: 0.4934 - val_accuracy: 0.8280\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0670 - accuracy: 0.9783 - val_loss: 0.4229 - val_accuracy: 0.8480\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0806 - accuracy: 0.9771 - val_loss: 0.5120 - val_accuracy: 0.8240\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0928 - accuracy: 0.9743 - val_loss: 0.8129 - val_accuracy: 0.7147\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0642 - accuracy: 0.9840 - val_loss: 0.6411 - val_accuracy: 0.7880\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0613 - accuracy: 0.9817 - val_loss: 0.7984 - val_accuracy: 0.7560\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0756 - accuracy: 0.9794 - val_loss: 0.7520 - val_accuracy: 0.7707\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0744 - accuracy: 0.9777 - val_loss: 0.7386 - val_accuracy: 0.7747\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0770 - accuracy: 0.9806 - val_loss: 0.4315 - val_accuracy: 0.8480\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0707 - accuracy: 0.9794 - val_loss: 0.6048 - val_accuracy: 0.8000\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0615 - accuracy: 0.9834 - val_loss: 1.0611 - val_accuracy: 0.7267\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0705 - accuracy: 0.9817 - val_loss: 0.6387 - val_accuracy: 0.7987\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0751 - accuracy: 0.9789 - val_loss: 0.8043 - val_accuracy: 0.7560\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0906 - accuracy: 0.9749 - val_loss: 0.7585 - val_accuracy: 0.7373\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0790 - accuracy: 0.9783 - val_loss: 0.4635 - val_accuracy: 0.8133\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0820 - accuracy: 0.9777 - val_loss: 0.9409 - val_accuracy: 0.7333\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0727 - accuracy: 0.9783 - val_loss: 0.8977 - val_accuracy: 0.7347\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0791 - accuracy: 0.9766 - val_loss: 0.7206 - val_accuracy: 0.7907\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0635 - accuracy: 0.9817 - val_loss: 0.7514 - val_accuracy: 0.7853\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0775 - accuracy: 0.9777 - val_loss: 0.7394 - val_accuracy: 0.7653\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0652 - accuracy: 0.9794 - val_loss: 0.6540 - val_accuracy: 0.7880\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0643 - accuracy: 0.9794 - val_loss: 0.7685 - val_accuracy: 0.7787\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0709 - accuracy: 0.9794 - val_loss: 0.5122 - val_accuracy: 0.8227\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0704 - accuracy: 0.9794 - val_loss: 0.5925 - val_accuracy: 0.8200\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0810 - accuracy: 0.9783 - val_loss: 0.6312 - val_accuracy: 0.7853\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0609 - accuracy: 0.9834 - val_loss: 0.8533 - val_accuracy: 0.7653\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0731 - accuracy: 0.9794 - val_loss: 0.7211 - val_accuracy: 0.7920\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0591 - accuracy: 0.9846 - val_loss: 0.7277 - val_accuracy: 0.7947\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0886 - accuracy: 0.9760 - val_loss: 0.5026 - val_accuracy: 0.8160\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0663 - accuracy: 0.9794 - val_loss: 0.4211 - val_accuracy: 0.8640\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0717 - accuracy: 0.9794 - val_loss: 0.5908 - val_accuracy: 0.8333\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0664 - accuracy: 0.9811 - val_loss: 0.4725 - val_accuracy: 0.8453\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0729 - accuracy: 0.9789 - val_loss: 0.6056 - val_accuracy: 0.7773\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0671 - accuracy: 0.9783 - val_loss: 0.4740 - val_accuracy: 0.8480\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0743 - accuracy: 0.9800 - val_loss: 0.7055 - val_accuracy: 0.7920\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0662 - accuracy: 0.9823 - val_loss: 0.7824 - val_accuracy: 0.7773\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.0769 - accuracy: 0.9789 - val_loss: 0.8883 - val_accuracy: 0.7693\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0677 - accuracy: 0.9800 - val_loss: 0.6620 - val_accuracy: 0.7853\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0720 - accuracy: 0.9806 - val_loss: 0.7179 - val_accuracy: 0.7827\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0616 - accuracy: 0.9829 - val_loss: 0.5069 - val_accuracy: 0.8440\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0718 - accuracy: 0.9760 - val_loss: 0.4337 - val_accuracy: 0.8493\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0643 - accuracy: 0.9817 - val_loss: 0.7939 - val_accuracy: 0.7987\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0718 - accuracy: 0.9760 - val_loss: 0.6702 - val_accuracy: 0.8027\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0564 - accuracy: 0.9829 - val_loss: 0.6682 - val_accuracy: 0.8333\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0649 - accuracy: 0.9800 - val_loss: 0.3909 - val_accuracy: 0.8467\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0701 - accuracy: 0.9806 - val_loss: 0.4803 - val_accuracy: 0.8373\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0706 - accuracy: 0.9800 - val_loss: 0.6690 - val_accuracy: 0.8213\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0705 - accuracy: 0.9766 - val_loss: 0.6202 - val_accuracy: 0.8027\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0883 - accuracy: 0.9749 - val_loss: 0.3598 - val_accuracy: 0.8453\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0674 - accuracy: 0.9817 - val_loss: 0.4198 - val_accuracy: 0.8413\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0765 - accuracy: 0.9771 - val_loss: 0.3799 - val_accuracy: 0.8467\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0655 - accuracy: 0.9771 - val_loss: 0.3949 - val_accuracy: 0.8573\n",
      "Epoch 199/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0661 - accuracy: 0.9794 - val_loss: 0.4695 - val_accuracy: 0.8227\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0551 - accuracy: 0.9846 - val_loss: 0.4337 - val_accuracy: 0.8320\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 4)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 50s - loss: 1.1858 - accuracy: 0.5312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0829s vs `on_train_batch_end` time: 0.8124s). Check your callbacks.\n",
      "110/110 [==============================] - 19s 176ms/step - loss: 0.7336 - accuracy: 0.7309 - val_loss: 0.7824 - val_accuracy: 0.6293\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.5743 - accuracy: 0.7943 - val_loss: 1.1987 - val_accuracy: 0.4613\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.4866 - accuracy: 0.8234 - val_loss: 2.0443 - val_accuracy: 0.7640\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.4765 - accuracy: 0.8160 - val_loss: 2.0281 - val_accuracy: 0.6533\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.4656 - accuracy: 0.8223 - val_loss: 3.2351 - val_accuracy: 0.7840\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3893 - accuracy: 0.8491 - val_loss: 1.4679 - val_accuracy: 0.8067\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.4940 - accuracy: 0.8257 - val_loss: 2.9397 - val_accuracy: 0.7493\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.4669 - accuracy: 0.8360 - val_loss: 2.0618 - val_accuracy: 0.7840\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3930 - accuracy: 0.8566 - val_loss: 2.7410 - val_accuracy: 0.7320\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.3924 - accuracy: 0.8543 - val_loss: 2.7112 - val_accuracy: 0.6867\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.4012 - accuracy: 0.8394 - val_loss: 1.4132 - val_accuracy: 0.6840\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3695 - accuracy: 0.8520 - val_loss: 1.8213 - val_accuracy: 0.7840\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3807 - accuracy: 0.8531 - val_loss: 3.4939 - val_accuracy: 0.6613\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3309 - accuracy: 0.8646 - val_loss: 2.1579 - val_accuracy: 0.7107\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.3849 - accuracy: 0.8577 - val_loss: 1.7729 - val_accuracy: 0.6520\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.3653 - accuracy: 0.8514 - val_loss: 3.7486 - val_accuracy: 0.6400\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.3315 - accuracy: 0.8737 - val_loss: 2.8916 - val_accuracy: 0.7227\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.3303 - accuracy: 0.8714 - val_loss: 3.6577 - val_accuracy: 0.6987\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.3600 - accuracy: 0.8611 - val_loss: 5.1991 - val_accuracy: 0.7133\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.3867 - accuracy: 0.8663 - val_loss: 2.2614 - val_accuracy: 0.7493\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.3132 - accuracy: 0.8709 - val_loss: 2.2513 - val_accuracy: 0.7387\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3580 - accuracy: 0.8623 - val_loss: 2.3295 - val_accuracy: 0.6947\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3329 - accuracy: 0.8623 - val_loss: 1.6800 - val_accuracy: 0.7333\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3163 - accuracy: 0.8857 - val_loss: 2.2090 - val_accuracy: 0.7093\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.3348 - accuracy: 0.8726 - val_loss: 1.3599 - val_accuracy: 0.7053\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.3194 - accuracy: 0.8869 - val_loss: 1.3784 - val_accuracy: 0.7227\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.3143 - accuracy: 0.8709 - val_loss: 1.8221 - val_accuracy: 0.7387\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.3037 - accuracy: 0.8937 - val_loss: 1.2492 - val_accuracy: 0.7507\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.3281 - accuracy: 0.8823 - val_loss: 2.1835 - val_accuracy: 0.7107\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2998 - accuracy: 0.8846 - val_loss: 0.8158 - val_accuracy: 0.6933\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.3169 - accuracy: 0.8806 - val_loss: 1.3104 - val_accuracy: 0.7187\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.2921 - accuracy: 0.8954 - val_loss: 2.0638 - val_accuracy: 0.6987\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2778 - accuracy: 0.9006 - val_loss: 1.3271 - val_accuracy: 0.7000\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2866 - accuracy: 0.8874 - val_loss: 1.2717 - val_accuracy: 0.6680\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2636 - accuracy: 0.9000 - val_loss: 1.4240 - val_accuracy: 0.7240\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.3517 - accuracy: 0.8926 - val_loss: 2.4445 - val_accuracy: 0.7200\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.3011 - accuracy: 0.8840 - val_loss: 2.2035 - val_accuracy: 0.7133\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.2542 - accuracy: 0.9034 - val_loss: 2.1826 - val_accuracy: 0.7453\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2456 - accuracy: 0.9017 - val_loss: 3.4425 - val_accuracy: 0.7387\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2800 - accuracy: 0.8943 - val_loss: 1.7313 - val_accuracy: 0.7173\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2701 - accuracy: 0.9091 - val_loss: 2.5117 - val_accuracy: 0.7173\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2477 - accuracy: 0.9074 - val_loss: 2.8694 - val_accuracy: 0.7480\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2561 - accuracy: 0.9080 - val_loss: 3.9216 - val_accuracy: 0.7333\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2350 - accuracy: 0.9143 - val_loss: 3.1350 - val_accuracy: 0.7187\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2400 - accuracy: 0.9194 - val_loss: 1.3752 - val_accuracy: 0.7560\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2729 - accuracy: 0.9006 - val_loss: 2.5153 - val_accuracy: 0.6573\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.2232 - accuracy: 0.9171 - val_loss: 1.9103 - val_accuracy: 0.6880\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.2439 - accuracy: 0.9154 - val_loss: 2.2363 - val_accuracy: 0.6947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2359 - accuracy: 0.9166 - val_loss: 2.9248 - val_accuracy: 0.6667\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2287 - accuracy: 0.9177 - val_loss: 1.6064 - val_accuracy: 0.7360\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2375 - accuracy: 0.9160 - val_loss: 1.7181 - val_accuracy: 0.7347\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2095 - accuracy: 0.9251 - val_loss: 1.5536 - val_accuracy: 0.7213\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2246 - accuracy: 0.9194 - val_loss: 2.2485 - val_accuracy: 0.6933\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.2478 - accuracy: 0.9206 - val_loss: 1.9944 - val_accuracy: 0.7200\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2037 - accuracy: 0.9343 - val_loss: 1.5596 - val_accuracy: 0.7280\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2677 - accuracy: 0.9274 - val_loss: 1.0134 - val_accuracy: 0.7200\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.2159 - accuracy: 0.9200 - val_loss: 0.8276 - val_accuracy: 0.6533\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2095 - accuracy: 0.9331 - val_loss: 0.5299 - val_accuracy: 0.7133\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1990 - accuracy: 0.9337 - val_loss: 0.9988 - val_accuracy: 0.7040\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.2197 - accuracy: 0.9303 - val_loss: 0.8799 - val_accuracy: 0.7080\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1930 - accuracy: 0.9349 - val_loss: 1.7655 - val_accuracy: 0.7587\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.2292 - accuracy: 0.9326 - val_loss: 4.2534 - val_accuracy: 0.7067\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1896 - accuracy: 0.9366 - val_loss: 1.5557 - val_accuracy: 0.7120\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1977 - accuracy: 0.9377 - val_loss: 1.7254 - val_accuracy: 0.7413\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1960 - accuracy: 0.9337 - val_loss: 1.1902 - val_accuracy: 0.7267\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1811 - accuracy: 0.9371 - val_loss: 0.9546 - val_accuracy: 0.7453\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1839 - accuracy: 0.9411 - val_loss: 0.9074 - val_accuracy: 0.7413\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1739 - accuracy: 0.9423 - val_loss: 1.1286 - val_accuracy: 0.7213\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2048 - accuracy: 0.9349 - val_loss: 1.1918 - val_accuracy: 0.7440\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1741 - accuracy: 0.9406 - val_loss: 1.2808 - val_accuracy: 0.6840\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1874 - accuracy: 0.9406 - val_loss: 1.0298 - val_accuracy: 0.7493\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1728 - accuracy: 0.9429 - val_loss: 1.0162 - val_accuracy: 0.7000\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1768 - accuracy: 0.9406 - val_loss: 1.1214 - val_accuracy: 0.7253\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1824 - accuracy: 0.9394 - val_loss: 0.8710 - val_accuracy: 0.7547\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1651 - accuracy: 0.9429 - val_loss: 0.9844 - val_accuracy: 0.7520\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2120 - accuracy: 0.9360 - val_loss: 1.7985 - val_accuracy: 0.7853\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1582 - accuracy: 0.9474 - val_loss: 0.9239 - val_accuracy: 0.7707\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1921 - accuracy: 0.9394 - val_loss: 1.7950 - val_accuracy: 0.7187\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1637 - accuracy: 0.9474 - val_loss: 1.4161 - val_accuracy: 0.7307\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1439 - accuracy: 0.9474 - val_loss: 1.0544 - val_accuracy: 0.7480\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1760 - accuracy: 0.9417 - val_loss: 0.8012 - val_accuracy: 0.7653\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1897 - accuracy: 0.9434 - val_loss: 1.5154 - val_accuracy: 0.7053\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1572 - accuracy: 0.9520 - val_loss: 0.9255 - val_accuracy: 0.7640\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1658 - accuracy: 0.9486 - val_loss: 0.7910 - val_accuracy: 0.7707\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1785 - accuracy: 0.9343 - val_loss: 1.2506 - val_accuracy: 0.7187\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1491 - accuracy: 0.9514 - val_loss: 1.3463 - val_accuracy: 0.7160\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1482 - accuracy: 0.9583 - val_loss: 1.0539 - val_accuracy: 0.7133\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1594 - accuracy: 0.9474 - val_loss: 1.1749 - val_accuracy: 0.7507\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1541 - accuracy: 0.9526 - val_loss: 0.9899 - val_accuracy: 0.6853\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1446 - accuracy: 0.9526 - val_loss: 1.1032 - val_accuracy: 0.7067\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1514 - accuracy: 0.9503 - val_loss: 1.1974 - val_accuracy: 0.7093\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1473 - accuracy: 0.9537 - val_loss: 1.0447 - val_accuracy: 0.7760\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1499 - accuracy: 0.9497 - val_loss: 0.9473 - val_accuracy: 0.7267\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1646 - accuracy: 0.9503 - val_loss: 0.9883 - val_accuracy: 0.7240\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1706 - accuracy: 0.9457 - val_loss: 0.8154 - val_accuracy: 0.7520\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1371 - accuracy: 0.9560 - val_loss: 0.9188 - val_accuracy: 0.7453\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1387 - accuracy: 0.9566 - val_loss: 0.6271 - val_accuracy: 0.7787\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1457 - accuracy: 0.9554 - val_loss: 1.1679 - val_accuracy: 0.7067\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1366 - accuracy: 0.9537 - val_loss: 1.3682 - val_accuracy: 0.7493\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1474 - accuracy: 0.9531 - val_loss: 0.8853 - val_accuracy: 0.7533\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1315 - accuracy: 0.9566 - val_loss: 0.8028 - val_accuracy: 0.7720\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1452 - accuracy: 0.9531 - val_loss: 1.2146 - val_accuracy: 0.7507\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1604 - accuracy: 0.9503 - val_loss: 1.0963 - val_accuracy: 0.7280\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1396 - accuracy: 0.9554 - val_loss: 0.7337 - val_accuracy: 0.7480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1408 - accuracy: 0.9583 - val_loss: 0.8271 - val_accuracy: 0.7427\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1536 - accuracy: 0.9491 - val_loss: 0.8545 - val_accuracy: 0.7907\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1396 - accuracy: 0.9537 - val_loss: 0.6616 - val_accuracy: 0.7640\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1201 - accuracy: 0.9623 - val_loss: 0.7060 - val_accuracy: 0.7667\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1507 - accuracy: 0.9520 - val_loss: 0.8775 - val_accuracy: 0.7387\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1283 - accuracy: 0.9589 - val_loss: 0.8763 - val_accuracy: 0.7347\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1266 - accuracy: 0.9606 - val_loss: 0.8797 - val_accuracy: 0.7493\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1456 - accuracy: 0.9526 - val_loss: 0.7180 - val_accuracy: 0.7733\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1288 - accuracy: 0.9589 - val_loss: 0.9730 - val_accuracy: 0.7107\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1279 - accuracy: 0.9583 - val_loss: 0.7670 - val_accuracy: 0.7613\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1314 - accuracy: 0.9583 - val_loss: 0.9126 - val_accuracy: 0.7227\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1204 - accuracy: 0.9634 - val_loss: 1.0083 - val_accuracy: 0.7347\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1350 - accuracy: 0.9566 - val_loss: 0.7938 - val_accuracy: 0.7213\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1298 - accuracy: 0.9623 - val_loss: 0.8224 - val_accuracy: 0.7160\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1430 - accuracy: 0.9549 - val_loss: 1.0105 - val_accuracy: 0.6920\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1479 - accuracy: 0.9520 - val_loss: 1.1422 - val_accuracy: 0.7040\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1341 - accuracy: 0.9611 - val_loss: 0.9031 - val_accuracy: 0.7213\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1432 - accuracy: 0.9554 - val_loss: 0.7728 - val_accuracy: 0.7773\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1456 - accuracy: 0.9583 - val_loss: 0.7780 - val_accuracy: 0.7480\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1274 - accuracy: 0.9611 - val_loss: 0.6304 - val_accuracy: 0.7893\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1190 - accuracy: 0.9640 - val_loss: 0.8127 - val_accuracy: 0.7413\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1234 - accuracy: 0.9611 - val_loss: 0.8308 - val_accuracy: 0.7453\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1273 - accuracy: 0.9589 - val_loss: 0.8363 - val_accuracy: 0.6973\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1155 - accuracy: 0.9577 - val_loss: 0.9285 - val_accuracy: 0.7213\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1285 - accuracy: 0.9566 - val_loss: 0.7868 - val_accuracy: 0.7453\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1263 - accuracy: 0.9577 - val_loss: 1.0094 - val_accuracy: 0.7493\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1173 - accuracy: 0.9651 - val_loss: 0.8701 - val_accuracy: 0.7240\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1185 - accuracy: 0.9634 - val_loss: 0.9755 - val_accuracy: 0.7267\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1167 - accuracy: 0.9617 - val_loss: 0.8322 - val_accuracy: 0.7013\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1639 - accuracy: 0.9549 - val_loss: 1.0681 - val_accuracy: 0.7547\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1296 - accuracy: 0.9634 - val_loss: 0.9668 - val_accuracy: 0.7293\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1262 - accuracy: 0.9651 - val_loss: 0.6999 - val_accuracy: 0.7813\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1052 - accuracy: 0.9691 - val_loss: 0.8448 - val_accuracy: 0.7213\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1655 - accuracy: 0.9583 - val_loss: 0.8748 - val_accuracy: 0.7360\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1223 - accuracy: 0.9606 - val_loss: 0.9190 - val_accuracy: 0.6720\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1275 - accuracy: 0.9589 - val_loss: 0.8771 - val_accuracy: 0.6960\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1201 - accuracy: 0.9640 - val_loss: 1.0648 - val_accuracy: 0.6880\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1209 - accuracy: 0.9634 - val_loss: 0.8025 - val_accuracy: 0.7560\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1074 - accuracy: 0.9657 - val_loss: 0.8505 - val_accuracy: 0.7453\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1083 - accuracy: 0.9646 - val_loss: 0.7900 - val_accuracy: 0.7760\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1165 - accuracy: 0.9594 - val_loss: 0.6089 - val_accuracy: 0.7880\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.1022 - accuracy: 0.9663 - val_loss: 0.7102 - val_accuracy: 0.7693\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1210 - accuracy: 0.9606 - val_loss: 0.7389 - val_accuracy: 0.7427\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1043 - accuracy: 0.9646 - val_loss: 0.8179 - val_accuracy: 0.7387\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1033 - accuracy: 0.9657 - val_loss: 1.1110 - val_accuracy: 0.6840\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1210 - accuracy: 0.9629 - val_loss: 1.0320 - val_accuracy: 0.7333\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1126 - accuracy: 0.9640 - val_loss: 0.7404 - val_accuracy: 0.7453\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1128 - accuracy: 0.9611 - val_loss: 0.8210 - val_accuracy: 0.7213\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1110 - accuracy: 0.9663 - val_loss: 0.7273 - val_accuracy: 0.7280\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1009 - accuracy: 0.9663 - val_loss: 0.6920 - val_accuracy: 0.7627\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1165 - accuracy: 0.9606 - val_loss: 0.7406 - val_accuracy: 0.7533\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1134 - accuracy: 0.9594 - val_loss: 0.8892 - val_accuracy: 0.7360\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1188 - accuracy: 0.9617 - val_loss: 0.7415 - val_accuracy: 0.7413\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1215 - accuracy: 0.9646 - val_loss: 1.1054 - val_accuracy: 0.6640\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1172 - accuracy: 0.9629 - val_loss: 0.6394 - val_accuracy: 0.7600\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1232 - accuracy: 0.9634 - val_loss: 0.6328 - val_accuracy: 0.7787\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1242 - accuracy: 0.9543 - val_loss: 0.8567 - val_accuracy: 0.7147\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1102 - accuracy: 0.9629 - val_loss: 0.6027 - val_accuracy: 0.7960\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1039 - accuracy: 0.9657 - val_loss: 0.8183 - val_accuracy: 0.7427\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1079 - accuracy: 0.9640 - val_loss: 0.7177 - val_accuracy: 0.7533\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 37s 336ms/step - loss: 0.1087 - accuracy: 0.9669 - val_loss: 0.8416 - val_accuracy: 0.7507\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 26s 240ms/step - loss: 0.1182 - accuracy: 0.9657 - val_loss: 0.5409 - val_accuracy: 0.7840\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 29s 264ms/step - loss: 0.0858 - accuracy: 0.9726 - val_loss: 0.8807 - val_accuracy: 0.7440\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 22s 201ms/step - loss: 0.1189 - accuracy: 0.9657 - val_loss: 0.7182 - val_accuracy: 0.7413\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 25s 225ms/step - loss: 0.1079 - accuracy: 0.9657 - val_loss: 0.8617 - val_accuracy: 0.7107\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 24s 218ms/step - loss: 0.1139 - accuracy: 0.9646 - val_loss: 0.6752 - val_accuracy: 0.7413\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 21s 193ms/step - loss: 0.0856 - accuracy: 0.9726 - val_loss: 0.7591 - val_accuracy: 0.7387\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1080 - accuracy: 0.9640 - val_loss: 0.7346 - val_accuracy: 0.7427\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1084 - accuracy: 0.9651 - val_loss: 0.6249 - val_accuracy: 0.7613\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1069 - accuracy: 0.9640 - val_loss: 0.7677 - val_accuracy: 0.7440\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0982 - accuracy: 0.9697 - val_loss: 0.9551 - val_accuracy: 0.7307\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1042 - accuracy: 0.9674 - val_loss: 0.6891 - val_accuracy: 0.7587\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0894 - accuracy: 0.9691 - val_loss: 0.6772 - val_accuracy: 0.7773\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0997 - accuracy: 0.9669 - val_loss: 0.8216 - val_accuracy: 0.7453\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0935 - accuracy: 0.9720 - val_loss: 0.8187 - val_accuracy: 0.7080\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0997 - accuracy: 0.9674 - val_loss: 0.8180 - val_accuracy: 0.7747\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1120 - accuracy: 0.9686 - val_loss: 0.7710 - val_accuracy: 0.7533\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1071 - accuracy: 0.9651 - val_loss: 0.9057 - val_accuracy: 0.7267\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1148 - accuracy: 0.9611 - val_loss: 0.8918 - val_accuracy: 0.7133\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1034 - accuracy: 0.9680 - val_loss: 1.0746 - val_accuracy: 0.6893\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1073 - accuracy: 0.9646 - val_loss: 0.9355 - val_accuracy: 0.7053\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1124 - accuracy: 0.9680 - val_loss: 0.7811 - val_accuracy: 0.7147\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0993 - accuracy: 0.9737 - val_loss: 1.0259 - val_accuracy: 0.7040\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1030 - accuracy: 0.9703 - val_loss: 0.9204 - val_accuracy: 0.7160\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1075 - accuracy: 0.9674 - val_loss: 0.7978 - val_accuracy: 0.7493\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1107 - accuracy: 0.9640 - val_loss: 0.7674 - val_accuracy: 0.7600\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1027 - accuracy: 0.9714 - val_loss: 0.6999 - val_accuracy: 0.7720\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0899 - accuracy: 0.9714 - val_loss: 0.9374 - val_accuracy: 0.7253\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0931 - accuracy: 0.9703 - val_loss: 0.6860 - val_accuracy: 0.7987\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0875 - accuracy: 0.9720 - val_loss: 1.0203 - val_accuracy: 0.7173\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0868 - accuracy: 0.9720 - val_loss: 0.8967 - val_accuracy: 0.7307\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1073 - accuracy: 0.9663 - val_loss: 0.6256 - val_accuracy: 0.7907\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0820 - accuracy: 0.9749 - val_loss: 0.8776 - val_accuracy: 0.7760\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0881 - accuracy: 0.9749 - val_loss: 0.5847 - val_accuracy: 0.8067\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0918 - accuracy: 0.9726 - val_loss: 0.8442 - val_accuracy: 0.7653\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0925 - accuracy: 0.9726 - val_loss: 0.7810 - val_accuracy: 0.7413\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 5)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 53s - loss: 7.5873 - accuracy: 0.2500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1072s vs `on_train_batch_end` time: 0.8366s). Check your callbacks.\n",
      "110/110 [==============================] - 20s 184ms/step - loss: 1.1146 - accuracy: 0.7731 - val_loss: 2.4064 - val_accuracy: 0.3720\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.4631 - accuracy: 0.8314 - val_loss: 1.1458 - val_accuracy: 0.3787\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.4506 - accuracy: 0.8503 - val_loss: 0.6766 - val_accuracy: 0.6427\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.3795 - accuracy: 0.8589 - val_loss: 0.5206 - val_accuracy: 0.7853\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.3598 - accuracy: 0.8869 - val_loss: 0.5186 - val_accuracy: 0.7827\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2704 - accuracy: 0.9097 - val_loss: 0.4979 - val_accuracy: 0.8187\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.3199 - accuracy: 0.8966 - val_loss: 0.7470 - val_accuracy: 0.8173\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.2858 - accuracy: 0.8914 - val_loss: 0.9689 - val_accuracy: 0.8253\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2336 - accuracy: 0.9206 - val_loss: 0.5288 - val_accuracy: 0.7907\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2226 - accuracy: 0.9331 - val_loss: 0.6930 - val_accuracy: 0.7987\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 19s 170ms/step - loss: 0.2219 - accuracy: 0.9389 - val_loss: 0.5550 - val_accuracy: 0.7840\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.2259 - accuracy: 0.9297 - val_loss: 1.0976 - val_accuracy: 0.6453\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1947 - accuracy: 0.9394 - val_loss: 1.1353 - val_accuracy: 0.6320\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1997 - accuracy: 0.9457 - val_loss: 0.5982 - val_accuracy: 0.8027\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1626 - accuracy: 0.9503 - val_loss: 0.8021 - val_accuracy: 0.7987\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1382 - accuracy: 0.9571 - val_loss: 0.9992 - val_accuracy: 0.6360\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1435 - accuracy: 0.9514 - val_loss: 0.9866 - val_accuracy: 0.6787\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1898 - accuracy: 0.9514 - val_loss: 0.6331 - val_accuracy: 0.7800\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1433 - accuracy: 0.9594 - val_loss: 1.1773 - val_accuracy: 0.6213\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.1511 - accuracy: 0.9526 - val_loss: 0.5950 - val_accuracy: 0.8053\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 19s 170ms/step - loss: 0.1401 - accuracy: 0.9623 - val_loss: 0.7014 - val_accuracy: 0.7200\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1317 - accuracy: 0.9577 - val_loss: 0.5907 - val_accuracy: 0.7787\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1252 - accuracy: 0.9669 - val_loss: 0.7367 - val_accuracy: 0.7400\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2201 - accuracy: 0.9554 - val_loss: 0.6791 - val_accuracy: 0.7827\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.2360 - accuracy: 0.9526 - val_loss: 177.1533 - val_accuracy: 0.7053\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1979 - accuracy: 0.9509 - val_loss: 463.7735 - val_accuracy: 0.6747\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1625 - accuracy: 0.9503 - val_loss: 131.0524 - val_accuracy: 0.7053\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2183 - accuracy: 0.9549 - val_loss: 15.0207 - val_accuracy: 0.7293\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2260 - accuracy: 0.9286 - val_loss: 0.5483 - val_accuracy: 0.8080\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1870 - accuracy: 0.9406 - val_loss: 0.8918 - val_accuracy: 0.7280\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.1705 - accuracy: 0.9417 - val_loss: 0.6552 - val_accuracy: 0.7907\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1617 - accuracy: 0.9600 - val_loss: 0.6699 - val_accuracy: 0.7920\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1583 - accuracy: 0.9640 - val_loss: 0.8501 - val_accuracy: 0.7040\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2495 - accuracy: 0.9434 - val_loss: 0.4426 - val_accuracy: 0.8240\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.2920 - accuracy: 0.9297 - val_loss: 1.6060 - val_accuracy: 0.8013\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1702 - accuracy: 0.9469 - val_loss: 0.8827 - val_accuracy: 0.7280\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1612 - accuracy: 0.9509 - val_loss: 0.9358 - val_accuracy: 0.7480\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1635 - accuracy: 0.9549 - val_loss: 0.4458 - val_accuracy: 0.8147\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1461 - accuracy: 0.9577 - val_loss: 0.5160 - val_accuracy: 0.8080\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1135 - accuracy: 0.9680 - val_loss: 0.7619 - val_accuracy: 0.7907\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.1189 - accuracy: 0.9634 - val_loss: 0.3589 - val_accuracy: 0.8747\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1035 - accuracy: 0.9703 - val_loss: 0.5800 - val_accuracy: 0.8280\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1061 - accuracy: 0.9686 - val_loss: 0.5450 - val_accuracy: 0.8507\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1203 - accuracy: 0.9663 - val_loss: 0.6358 - val_accuracy: 0.8213\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1156 - accuracy: 0.9634 - val_loss: 0.8409 - val_accuracy: 0.7867\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1148 - accuracy: 0.9623 - val_loss: 0.3961 - val_accuracy: 0.8640\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1369 - accuracy: 0.9709 - val_loss: 0.2924 - val_accuracy: 0.8947\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1822 - accuracy: 0.9514 - val_loss: 0.9690 - val_accuracy: 0.7733\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1727 - accuracy: 0.9594 - val_loss: 0.5068 - val_accuracy: 0.8333\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1343 - accuracy: 0.9606 - val_loss: 0.2608 - val_accuracy: 0.9067\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 19s 172ms/step - loss: 0.1504 - accuracy: 0.9543 - val_loss: 0.2704 - val_accuracy: 0.8960\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.1985 - accuracy: 0.9531 - val_loss: 2.7258 - val_accuracy: 0.7200\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1181 - accuracy: 0.9611 - val_loss: 0.7980 - val_accuracy: 0.7067\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1210 - accuracy: 0.9617 - val_loss: 0.4613 - val_accuracy: 0.8400\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1134 - accuracy: 0.9663 - val_loss: 0.5242 - val_accuracy: 0.8333\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1412 - accuracy: 0.9709 - val_loss: 0.4729 - val_accuracy: 0.8413\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1218 - accuracy: 0.9669 - val_loss: 0.5625 - val_accuracy: 0.8520\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1079 - accuracy: 0.9640 - val_loss: 0.5255 - val_accuracy: 0.8640\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1055 - accuracy: 0.9691 - val_loss: 0.4441 - val_accuracy: 0.8187\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1333 - accuracy: 0.9663 - val_loss: 0.4926 - val_accuracy: 0.8440\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 19s 171ms/step - loss: 0.1297 - accuracy: 0.9531 - val_loss: 0.4444 - val_accuracy: 0.8373\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0945 - accuracy: 0.9714 - val_loss: 0.6283 - val_accuracy: 0.8107\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1128 - accuracy: 0.9657 - val_loss: 0.6169 - val_accuracy: 0.8000\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1032 - accuracy: 0.9731 - val_loss: 0.6653 - val_accuracy: 0.8187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1238 - accuracy: 0.9714 - val_loss: 0.6933 - val_accuracy: 0.8027\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1429 - accuracy: 0.9640 - val_loss: 0.6279 - val_accuracy: 0.8200\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1115 - accuracy: 0.9674 - val_loss: 0.9237 - val_accuracy: 0.7147\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1198 - accuracy: 0.9640 - val_loss: 0.7012 - val_accuracy: 0.7960\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0974 - accuracy: 0.9754 - val_loss: 1.0200 - val_accuracy: 0.7187\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1132 - accuracy: 0.9686 - val_loss: 0.5913 - val_accuracy: 0.8040\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 19s 171ms/step - loss: 0.1140 - accuracy: 0.9691 - val_loss: 0.6998 - val_accuracy: 0.7880\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1165 - accuracy: 0.9674 - val_loss: 0.4927 - val_accuracy: 0.8480\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0980 - accuracy: 0.9714 - val_loss: 0.7609 - val_accuracy: 0.8293\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1105 - accuracy: 0.9691 - val_loss: 0.8352 - val_accuracy: 0.8147\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.0924 - accuracy: 0.9720 - val_loss: 0.6184 - val_accuracy: 0.8267\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0976 - accuracy: 0.9731 - val_loss: 0.5822 - val_accuracy: 0.8387\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0911 - accuracy: 0.9720 - val_loss: 0.4600 - val_accuracy: 0.8373\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0963 - accuracy: 0.9714 - val_loss: 0.4103 - val_accuracy: 0.8680\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1110 - accuracy: 0.9651 - val_loss: 0.5106 - val_accuracy: 0.8413\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0947 - accuracy: 0.9743 - val_loss: 0.4953 - val_accuracy: 0.8107\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.1087 - accuracy: 0.9686 - val_loss: 0.5800 - val_accuracy: 0.8427\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0923 - accuracy: 0.9709 - val_loss: 0.4496 - val_accuracy: 0.8160\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0905 - accuracy: 0.9754 - val_loss: 0.7252 - val_accuracy: 0.7907\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0912 - accuracy: 0.9703 - val_loss: 0.4666 - val_accuracy: 0.8453\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.0960 - accuracy: 0.9771 - val_loss: 0.5360 - val_accuracy: 0.8053\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0950 - accuracy: 0.9783 - val_loss: 0.5613 - val_accuracy: 0.8440\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0873 - accuracy: 0.9737 - val_loss: 0.6064 - val_accuracy: 0.8307\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0834 - accuracy: 0.9760 - val_loss: 0.5716 - val_accuracy: 0.8253\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0862 - accuracy: 0.9789 - val_loss: 0.5314 - val_accuracy: 0.8627\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0831 - accuracy: 0.9754 - val_loss: 0.4588 - val_accuracy: 0.8667\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 19s 170ms/step - loss: 0.1081 - accuracy: 0.9691 - val_loss: 0.6041 - val_accuracy: 0.8253\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0922 - accuracy: 0.9743 - val_loss: 0.9161 - val_accuracy: 0.7613\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0897 - accuracy: 0.9737 - val_loss: 0.6467 - val_accuracy: 0.8133\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0712 - accuracy: 0.9811 - val_loss: 0.5707 - val_accuracy: 0.8467\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0925 - accuracy: 0.9697 - val_loss: 0.3501 - val_accuracy: 0.8733\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1187 - accuracy: 0.9720 - val_loss: 0.5545 - val_accuracy: 0.8707\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1071 - accuracy: 0.9669 - val_loss: 0.4279 - val_accuracy: 0.8573\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0961 - accuracy: 0.9703 - val_loss: 0.4641 - val_accuracy: 0.8493\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0967 - accuracy: 0.9743 - val_loss: 0.3107 - val_accuracy: 0.9120\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0732 - accuracy: 0.9794 - val_loss: 0.5241 - val_accuracy: 0.8640\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 19s 170ms/step - loss: 0.0754 - accuracy: 0.9794 - val_loss: 0.5222 - val_accuracy: 0.8520\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0937 - accuracy: 0.9743 - val_loss: 0.9511 - val_accuracy: 0.7013\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1440 - accuracy: 0.9634 - val_loss: 0.4918 - val_accuracy: 0.8920\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1044 - accuracy: 0.9657 - val_loss: 0.5030 - val_accuracy: 0.8613\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0851 - accuracy: 0.9731 - val_loss: 0.5850 - val_accuracy: 0.8107\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0913 - accuracy: 0.9731 - val_loss: 0.3955 - val_accuracy: 0.8587\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1322 - accuracy: 0.9583 - val_loss: 0.4312 - val_accuracy: 0.8760\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0888 - accuracy: 0.9743 - val_loss: 0.4718 - val_accuracy: 0.8707\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1015 - accuracy: 0.9743 - val_loss: 0.6718 - val_accuracy: 0.8240\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0871 - accuracy: 0.9731 - val_loss: 0.4976 - val_accuracy: 0.8667\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 19s 171ms/step - loss: 0.1145 - accuracy: 0.9686 - val_loss: 0.3475 - val_accuracy: 0.8747\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0862 - accuracy: 0.9743 - val_loss: 0.5134 - val_accuracy: 0.8280\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0962 - accuracy: 0.9737 - val_loss: 0.4192 - val_accuracy: 0.8760\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0905 - accuracy: 0.9743 - val_loss: 0.3611 - val_accuracy: 0.8760\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0827 - accuracy: 0.9743 - val_loss: 0.5474 - val_accuracy: 0.8227\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0575 - accuracy: 0.9823 - val_loss: 0.4658 - val_accuracy: 0.8547\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0732 - accuracy: 0.9789 - val_loss: 0.3537 - val_accuracy: 0.8680\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0930 - accuracy: 0.9749 - val_loss: 0.8223 - val_accuracy: 0.7307\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0783 - accuracy: 0.9783 - val_loss: 0.3333 - val_accuracy: 0.8920\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0707 - accuracy: 0.9794 - val_loss: 0.3843 - val_accuracy: 0.8653\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 19s 170ms/step - loss: 0.1170 - accuracy: 0.9760 - val_loss: 0.8627 - val_accuracy: 0.7747\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0652 - accuracy: 0.9829 - val_loss: 0.4561 - val_accuracy: 0.8480\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0969 - accuracy: 0.9749 - val_loss: 0.6466 - val_accuracy: 0.8027\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0840 - accuracy: 0.9771 - val_loss: 0.3797 - val_accuracy: 0.8760\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0883 - accuracy: 0.9754 - val_loss: 0.5958 - val_accuracy: 0.8120\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0683 - accuracy: 0.9817 - val_loss: 0.3451 - val_accuracy: 0.8787\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0539 - accuracy: 0.9851 - val_loss: 0.4746 - val_accuracy: 0.8800\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0835 - accuracy: 0.9777 - val_loss: 0.3799 - val_accuracy: 0.8613\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0908 - accuracy: 0.9743 - val_loss: 0.3648 - val_accuracy: 0.8640\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0844 - accuracy: 0.9737 - val_loss: 0.6574 - val_accuracy: 0.7733\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 19s 170ms/step - loss: 0.0895 - accuracy: 0.9766 - val_loss: 0.7010 - val_accuracy: 0.7480\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0804 - accuracy: 0.9789 - val_loss: 0.4961 - val_accuracy: 0.8467\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0937 - accuracy: 0.9743 - val_loss: 0.4125 - val_accuracy: 0.8533\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0736 - accuracy: 0.9777 - val_loss: 0.5848 - val_accuracy: 0.7840\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0743 - accuracy: 0.9789 - val_loss: 0.5458 - val_accuracy: 0.8013\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0715 - accuracy: 0.9806 - val_loss: 0.4925 - val_accuracy: 0.8507\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0633 - accuracy: 0.9817 - val_loss: 0.3817 - val_accuracy: 0.8653\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0818 - accuracy: 0.9771 - val_loss: 1.3770 - val_accuracy: 0.7147\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0774 - accuracy: 0.9777 - val_loss: 0.5936 - val_accuracy: 0.8267\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0769 - accuracy: 0.9794 - val_loss: 0.5834 - val_accuracy: 0.8200\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 19s 170ms/step - loss: 0.0722 - accuracy: 0.9777 - val_loss: 0.5759 - val_accuracy: 0.8240\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0739 - accuracy: 0.9811 - val_loss: 0.7282 - val_accuracy: 0.7600\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0613 - accuracy: 0.9811 - val_loss: 0.5035 - val_accuracy: 0.8707\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0823 - accuracy: 0.9754 - val_loss: 0.3806 - val_accuracy: 0.8907\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0684 - accuracy: 0.9800 - val_loss: 0.6026 - val_accuracy: 0.8107\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0677 - accuracy: 0.9789 - val_loss: 0.8255 - val_accuracy: 0.7773\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0697 - accuracy: 0.9846 - val_loss: 0.4624 - val_accuracy: 0.8320\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0619 - accuracy: 0.9817 - val_loss: 0.4982 - val_accuracy: 0.8227\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0818 - accuracy: 0.9783 - val_loss: 0.5049 - val_accuracy: 0.8240\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0713 - accuracy: 0.9806 - val_loss: 0.6809 - val_accuracy: 0.7947\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 19s 170ms/step - loss: 0.0825 - accuracy: 0.9743 - val_loss: 0.5721 - val_accuracy: 0.7893\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0709 - accuracy: 0.9760 - val_loss: 0.3800 - val_accuracy: 0.8693\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0778 - accuracy: 0.9754 - val_loss: 0.4882 - val_accuracy: 0.7947\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0686 - accuracy: 0.9811 - val_loss: 0.3618 - val_accuracy: 0.8573\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0694 - accuracy: 0.9811 - val_loss: 0.8989 - val_accuracy: 0.7427\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0681 - accuracy: 0.9800 - val_loss: 0.7639 - val_accuracy: 0.7773\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.0607 - accuracy: 0.9823 - val_loss: 0.6185 - val_accuracy: 0.8093\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0731 - accuracy: 0.9806 - val_loss: 0.6214 - val_accuracy: 0.8360\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0701 - accuracy: 0.9771 - val_loss: 0.5648 - val_accuracy: 0.8400\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0886 - accuracy: 0.9737 - val_loss: 0.4384 - val_accuracy: 0.8667\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 19s 170ms/step - loss: 0.0723 - accuracy: 0.9794 - val_loss: 0.3443 - val_accuracy: 0.8707\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0582 - accuracy: 0.9823 - val_loss: 0.4639 - val_accuracy: 0.8520\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0599 - accuracy: 0.9846 - val_loss: 0.5151 - val_accuracy: 0.8467\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0744 - accuracy: 0.9811 - val_loss: 0.4215 - val_accuracy: 0.8773\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0706 - accuracy: 0.9811 - val_loss: 0.7105 - val_accuracy: 0.8293\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0671 - accuracy: 0.9806 - val_loss: 0.4593 - val_accuracy: 0.8587\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0780 - accuracy: 0.9771 - val_loss: 0.4849 - val_accuracy: 0.8200\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0596 - accuracy: 0.9817 - val_loss: 0.8237 - val_accuracy: 0.7947\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0531 - accuracy: 0.9840 - val_loss: 0.6529 - val_accuracy: 0.8520\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0677 - accuracy: 0.9829 - val_loss: 0.4496 - val_accuracy: 0.8840\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 19s 171ms/step - loss: 0.0553 - accuracy: 0.9834 - val_loss: 0.5648 - val_accuracy: 0.8400\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0546 - accuracy: 0.9857 - val_loss: 1.0192 - val_accuracy: 0.8093\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0549 - accuracy: 0.9874 - val_loss: 0.5372 - val_accuracy: 0.8307\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0540 - accuracy: 0.9834 - val_loss: 0.6753 - val_accuracy: 0.7947\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0545 - accuracy: 0.9851 - val_loss: 0.7326 - val_accuracy: 0.8253\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0548 - accuracy: 0.9880 - val_loss: 0.5656 - val_accuracy: 0.8373\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0584 - accuracy: 0.9840 - val_loss: 0.6309 - val_accuracy: 0.8147\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0565 - accuracy: 0.9823 - val_loss: 0.5488 - val_accuracy: 0.8560\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0643 - accuracy: 0.9829 - val_loss: 0.7257 - val_accuracy: 0.8360\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0586 - accuracy: 0.9846 - val_loss: 0.5872 - val_accuracy: 0.8440\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 19s 170ms/step - loss: 0.0717 - accuracy: 0.9794 - val_loss: 0.5389 - val_accuracy: 0.8640\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0604 - accuracy: 0.9823 - val_loss: 0.3769 - val_accuracy: 0.8973\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0719 - accuracy: 0.9766 - val_loss: 0.4357 - val_accuracy: 0.8680\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0619 - accuracy: 0.9817 - val_loss: 0.4715 - val_accuracy: 0.8707\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0703 - accuracy: 0.9800 - val_loss: 0.6214 - val_accuracy: 0.8333\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0549 - accuracy: 0.9834 - val_loss: 0.5317 - val_accuracy: 0.8493\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0739 - accuracy: 0.9794 - val_loss: 0.4658 - val_accuracy: 0.8520\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0595 - accuracy: 0.9806 - val_loss: 0.3073 - val_accuracy: 0.8867\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0654 - accuracy: 0.9806 - val_loss: 0.5386 - val_accuracy: 0.8693\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0553 - accuracy: 0.9857 - val_loss: 0.3416 - val_accuracy: 0.8880\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 19s 170ms/step - loss: 0.0642 - accuracy: 0.9806 - val_loss: 0.5145 - val_accuracy: 0.8347\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0556 - accuracy: 0.9834 - val_loss: 0.4397 - val_accuracy: 0.8693\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0553 - accuracy: 0.9823 - val_loss: 0.4087 - val_accuracy: 0.8613\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0598 - accuracy: 0.9806 - val_loss: 0.4274 - val_accuracy: 0.8733\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0515 - accuracy: 0.9869 - val_loss: 0.3740 - val_accuracy: 0.9013\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0713 - accuracy: 0.9806 - val_loss: 0.3508 - val_accuracy: 0.8840\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0553 - accuracy: 0.9857 - val_loss: 0.4786 - val_accuracy: 0.8627\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0509 - accuracy: 0.9857 - val_loss: 0.3848 - val_accuracy: 0.8907\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0548 - accuracy: 0.9846 - val_loss: 0.5940 - val_accuracy: 0.8427\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0549 - accuracy: 0.9851 - val_loss: 0.4781 - val_accuracy: 0.8480\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 5)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 51s - loss: 2.4404 - accuracy: 0.6250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0888s vs `on_train_batch_end` time: 0.8019s). Check your callbacks.\n",
      "110/110 [==============================] - 20s 182ms/step - loss: 1.0462 - accuracy: 0.7674 - val_loss: 0.9159 - val_accuracy: 0.3733\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.6442 - accuracy: 0.8126 - val_loss: 0.6032 - val_accuracy: 0.6387\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.4833 - accuracy: 0.8343 - val_loss: 0.7329 - val_accuracy: 0.7160\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.4669 - accuracy: 0.8371 - val_loss: 0.6031 - val_accuracy: 0.7293\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.4615 - accuracy: 0.8474 - val_loss: 0.8009 - val_accuracy: 0.7253\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.3636 - accuracy: 0.8629 - val_loss: 0.8609 - val_accuracy: 0.7227\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.3132 - accuracy: 0.8851 - val_loss: 0.6632 - val_accuracy: 0.6947\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2783 - accuracy: 0.8977 - val_loss: 0.7673 - val_accuracy: 0.6773\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.3405 - accuracy: 0.8920 - val_loss: 0.5467 - val_accuracy: 0.7853\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.3256 - accuracy: 0.8949 - val_loss: 0.5451 - val_accuracy: 0.7893\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.2412 - accuracy: 0.9206 - val_loss: 0.4174 - val_accuracy: 0.8227\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2297 - accuracy: 0.9229 - val_loss: 0.5583 - val_accuracy: 0.7920\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 22s 203ms/step - loss: 0.2831 - accuracy: 0.9280 - val_loss: 0.3834 - val_accuracy: 0.8280\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 21s 186ms/step - loss: 0.3218 - accuracy: 0.9137 - val_loss: 0.6287 - val_accuracy: 0.7373\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2271 - accuracy: 0.9326 - val_loss: 0.6054 - val_accuracy: 0.7973\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2804 - accuracy: 0.9246 - val_loss: 0.3830 - val_accuracy: 0.8507\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1823 - accuracy: 0.9411 - val_loss: 0.7543 - val_accuracy: 0.7680\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2504 - accuracy: 0.9377 - val_loss: 0.6113 - val_accuracy: 0.7600\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1889 - accuracy: 0.9366 - val_loss: 0.5942 - val_accuracy: 0.7427\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1598 - accuracy: 0.9497 - val_loss: 0.6951 - val_accuracy: 0.7467\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.1669 - accuracy: 0.9446 - val_loss: 0.4895 - val_accuracy: 0.7680\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1848 - accuracy: 0.9429 - val_loss: 0.4607 - val_accuracy: 0.8200\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1709 - accuracy: 0.9417 - val_loss: 0.3973 - val_accuracy: 0.8227\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1493 - accuracy: 0.9497 - val_loss: 0.5634 - val_accuracy: 0.7907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1454 - accuracy: 0.9543 - val_loss: 0.6006 - val_accuracy: 0.7533\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1417 - accuracy: 0.9537 - val_loss: 0.5291 - val_accuracy: 0.7733\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1364 - accuracy: 0.9571 - val_loss: 0.7202 - val_accuracy: 0.7747\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1384 - accuracy: 0.9520 - val_loss: 0.4115 - val_accuracy: 0.8373\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1399 - accuracy: 0.9566 - val_loss: 0.3440 - val_accuracy: 0.8613\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1490 - accuracy: 0.9526 - val_loss: 0.5492 - val_accuracy: 0.8227\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.2013 - accuracy: 0.9486 - val_loss: 0.4294 - val_accuracy: 0.8373\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1498 - accuracy: 0.9554 - val_loss: 0.3783 - val_accuracy: 0.8573\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1384 - accuracy: 0.9526 - val_loss: 0.3990 - val_accuracy: 0.8720\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1407 - accuracy: 0.9577 - val_loss: 0.2211 - val_accuracy: 0.9173\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1404 - accuracy: 0.9549 - val_loss: 0.5201 - val_accuracy: 0.8440\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1700 - accuracy: 0.9554 - val_loss: 0.7536 - val_accuracy: 0.6867\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2042 - accuracy: 0.9469 - val_loss: 0.7007 - val_accuracy: 0.7813\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1644 - accuracy: 0.9537 - val_loss: 0.5983 - val_accuracy: 0.7813\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2105 - accuracy: 0.9537 - val_loss: 3.0414 - val_accuracy: 0.8373\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2395 - accuracy: 0.9531 - val_loss: 0.2935 - val_accuracy: 0.8787\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.1215 - accuracy: 0.9611 - val_loss: 0.3792 - val_accuracy: 0.8600\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1266 - accuracy: 0.9634 - val_loss: 0.4068 - val_accuracy: 0.8413\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1364 - accuracy: 0.9549 - val_loss: 0.4089 - val_accuracy: 0.8600\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1212 - accuracy: 0.9617 - val_loss: 0.3225 - val_accuracy: 0.8587\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1379 - accuracy: 0.9606 - val_loss: 0.3790 - val_accuracy: 0.8613\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1274 - accuracy: 0.9651 - val_loss: 0.4341 - val_accuracy: 0.8573\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1136 - accuracy: 0.9680 - val_loss: 0.4838 - val_accuracy: 0.8453\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0967 - accuracy: 0.9703 - val_loss: 0.4465 - val_accuracy: 0.8480\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1194 - accuracy: 0.9651 - val_loss: 0.5785 - val_accuracy: 0.8107\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1350 - accuracy: 0.9600 - val_loss: 0.6768 - val_accuracy: 0.7813\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.1279 - accuracy: 0.9560 - val_loss: 0.6374 - val_accuracy: 0.7960\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0970 - accuracy: 0.9743 - val_loss: 0.5743 - val_accuracy: 0.8147\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1193 - accuracy: 0.9686 - val_loss: 0.3669 - val_accuracy: 0.8667\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1412 - accuracy: 0.9611 - val_loss: 0.2108 - val_accuracy: 0.9147\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1481 - accuracy: 0.9571 - val_loss: 0.4508 - val_accuracy: 0.8107\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1725 - accuracy: 0.9571 - val_loss: 0.4677 - val_accuracy: 0.8547\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1203 - accuracy: 0.9646 - val_loss: 0.4394 - val_accuracy: 0.8467\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1232 - accuracy: 0.9629 - val_loss: 0.4355 - val_accuracy: 0.8293\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1397 - accuracy: 0.9629 - val_loss: 0.5061 - val_accuracy: 0.8107\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1423 - accuracy: 0.9651 - val_loss: 0.3727 - val_accuracy: 0.8587\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.1208 - accuracy: 0.9629 - val_loss: 0.4645 - val_accuracy: 0.8267\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1064 - accuracy: 0.9663 - val_loss: 0.6889 - val_accuracy: 0.7760\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0982 - accuracy: 0.9697 - val_loss: 0.6922 - val_accuracy: 0.7707\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1097 - accuracy: 0.9680 - val_loss: 0.6779 - val_accuracy: 0.7627\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1178 - accuracy: 0.9651 - val_loss: 0.3824 - val_accuracy: 0.8173\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1201 - accuracy: 0.9629 - val_loss: 0.4652 - val_accuracy: 0.8080\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1068 - accuracy: 0.9709 - val_loss: 0.3468 - val_accuracy: 0.8640\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1084 - accuracy: 0.9680 - val_loss: 0.6713 - val_accuracy: 0.7733\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1133 - accuracy: 0.9669 - val_loss: 0.5440 - val_accuracy: 0.8080\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1193 - accuracy: 0.9651 - val_loss: 0.5961 - val_accuracy: 0.7973\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1307 - accuracy: 0.9680 - val_loss: 0.4654 - val_accuracy: 0.8067\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1034 - accuracy: 0.9697 - val_loss: 0.4449 - val_accuracy: 0.8227\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0837 - accuracy: 0.9749 - val_loss: 0.6523 - val_accuracy: 0.7613\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1147 - accuracy: 0.9691 - val_loss: 0.5632 - val_accuracy: 0.8147\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0999 - accuracy: 0.9669 - val_loss: 0.6183 - val_accuracy: 0.7973\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0955 - accuracy: 0.9726 - val_loss: 0.3823 - val_accuracy: 0.8267\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1056 - accuracy: 0.9731 - val_loss: 0.9728 - val_accuracy: 0.7333\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1090 - accuracy: 0.9720 - val_loss: 0.6657 - val_accuracy: 0.7587\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0866 - accuracy: 0.9749 - val_loss: 0.5354 - val_accuracy: 0.8120\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0947 - accuracy: 0.9726 - val_loss: 0.6936 - val_accuracy: 0.7733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.0886 - accuracy: 0.9754 - val_loss: 0.8547 - val_accuracy: 0.7213\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1103 - accuracy: 0.9657 - val_loss: 0.8206 - val_accuracy: 0.7440\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1058 - accuracy: 0.9709 - val_loss: 0.7031 - val_accuracy: 0.7373\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1187 - accuracy: 0.9703 - val_loss: 0.5283 - val_accuracy: 0.7893\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0952 - accuracy: 0.9691 - val_loss: 0.7328 - val_accuracy: 0.7373\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0939 - accuracy: 0.9714 - val_loss: 0.7785 - val_accuracy: 0.7027\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1008 - accuracy: 0.9703 - val_loss: 0.5324 - val_accuracy: 0.7933\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0970 - accuracy: 0.9720 - val_loss: 0.4144 - val_accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0838 - accuracy: 0.9754 - val_loss: 0.6444 - val_accuracy: 0.7933\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0886 - accuracy: 0.9743 - val_loss: 0.4444 - val_accuracy: 0.8280\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.1240 - accuracy: 0.9709 - val_loss: 0.6741 - val_accuracy: 0.7893\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0976 - accuracy: 0.9720 - val_loss: 0.3678 - val_accuracy: 0.8587\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0841 - accuracy: 0.9766 - val_loss: 0.4441 - val_accuracy: 0.8453\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0768 - accuracy: 0.9766 - val_loss: 0.3616 - val_accuracy: 0.8587\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0859 - accuracy: 0.9749 - val_loss: 0.5312 - val_accuracy: 0.8280\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0856 - accuracy: 0.9806 - val_loss: 0.6224 - val_accuracy: 0.8000\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0999 - accuracy: 0.9686 - val_loss: 0.4506 - val_accuracy: 0.8400\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0847 - accuracy: 0.9749 - val_loss: 0.7258 - val_accuracy: 0.7733\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0857 - accuracy: 0.9737 - val_loss: 0.3415 - val_accuracy: 0.8613\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0888 - accuracy: 0.9760 - val_loss: 0.3928 - val_accuracy: 0.8480\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0887 - accuracy: 0.9731 - val_loss: 0.6095 - val_accuracy: 0.7840\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0925 - accuracy: 0.9743 - val_loss: 0.3332 - val_accuracy: 0.8787\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0861 - accuracy: 0.9754 - val_loss: 0.3195 - val_accuracy: 0.8667\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0925 - accuracy: 0.9720 - val_loss: 0.6245 - val_accuracy: 0.7747\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0883 - accuracy: 0.9726 - val_loss: 0.4794 - val_accuracy: 0.8227\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0832 - accuracy: 0.9771 - val_loss: 0.3540 - val_accuracy: 0.8560\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0796 - accuracy: 0.9777 - val_loss: 0.4407 - val_accuracy: 0.8427\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1017 - accuracy: 0.9731 - val_loss: 0.4160 - val_accuracy: 0.8373\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0769 - accuracy: 0.9766 - val_loss: 0.3675 - val_accuracy: 0.8573\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0860 - accuracy: 0.9754 - val_loss: 0.4886 - val_accuracy: 0.8053\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.1241 - accuracy: 0.9640 - val_loss: 0.2994 - val_accuracy: 0.8787\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1271 - accuracy: 0.9697 - val_loss: 0.9007 - val_accuracy: 0.6987\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1307 - accuracy: 0.9720 - val_loss: 0.5634 - val_accuracy: 0.7880\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0968 - accuracy: 0.9714 - val_loss: 0.5589 - val_accuracy: 0.7987\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0793 - accuracy: 0.9789 - val_loss: 0.5224 - val_accuracy: 0.8293\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0716 - accuracy: 0.9800 - val_loss: 0.5821 - val_accuracy: 0.8013\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0841 - accuracy: 0.9766 - val_loss: 0.3611 - val_accuracy: 0.8693\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0844 - accuracy: 0.9766 - val_loss: 0.2783 - val_accuracy: 0.8947\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0835 - accuracy: 0.9771 - val_loss: 0.3575 - val_accuracy: 0.8653\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0821 - accuracy: 0.9760 - val_loss: 0.6319 - val_accuracy: 0.7800\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.0787 - accuracy: 0.9749 - val_loss: 0.4249 - val_accuracy: 0.8387\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0814 - accuracy: 0.9749 - val_loss: 0.5276 - val_accuracy: 0.7973\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0879 - accuracy: 0.9777 - val_loss: 0.4600 - val_accuracy: 0.8093\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0741 - accuracy: 0.9743 - val_loss: 0.5353 - val_accuracy: 0.8147\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0617 - accuracy: 0.9817 - val_loss: 0.4860 - val_accuracy: 0.8373\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0683 - accuracy: 0.9800 - val_loss: 0.5502 - val_accuracy: 0.8093\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0857 - accuracy: 0.9737 - val_loss: 0.5405 - val_accuracy: 0.8093\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0703 - accuracy: 0.9811 - val_loss: 0.2967 - val_accuracy: 0.8987\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0768 - accuracy: 0.9766 - val_loss: 0.5451 - val_accuracy: 0.8293\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0839 - accuracy: 0.9754 - val_loss: 0.2786 - val_accuracy: 0.9000\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.0852 - accuracy: 0.9737 - val_loss: 0.3180 - val_accuracy: 0.8760\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0874 - accuracy: 0.9697 - val_loss: 0.2653 - val_accuracy: 0.8987\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0797 - accuracy: 0.9771 - val_loss: 0.6354 - val_accuracy: 0.7827\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0664 - accuracy: 0.9817 - val_loss: 0.3206 - val_accuracy: 0.8920\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0605 - accuracy: 0.9851 - val_loss: 0.2816 - val_accuracy: 0.9120\n",
      "Epoch 136/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0702 - accuracy: 0.9806 - val_loss: 0.2545 - val_accuracy: 0.9000\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0576 - accuracy: 0.9829 - val_loss: 0.4206 - val_accuracy: 0.8533\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0777 - accuracy: 0.9771 - val_loss: 0.3310 - val_accuracy: 0.8920\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0736 - accuracy: 0.9823 - val_loss: 0.5208 - val_accuracy: 0.8253\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0768 - accuracy: 0.9766 - val_loss: 0.3918 - val_accuracy: 0.8667\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0577 - accuracy: 0.9840 - val_loss: 0.4428 - val_accuracy: 0.8480\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0629 - accuracy: 0.9811 - val_loss: 0.4485 - val_accuracy: 0.8640\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0719 - accuracy: 0.9783 - val_loss: 0.3472 - val_accuracy: 0.8693\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0716 - accuracy: 0.9829 - val_loss: 0.4144 - val_accuracy: 0.8427\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0750 - accuracy: 0.9777 - val_loss: 0.6949 - val_accuracy: 0.7653\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0868 - accuracy: 0.9737 - val_loss: 0.4037 - val_accuracy: 0.8533\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0639 - accuracy: 0.9811 - val_loss: 0.5068 - val_accuracy: 0.8147\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0712 - accuracy: 0.9766 - val_loss: 0.5482 - val_accuracy: 0.8400\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0847 - accuracy: 0.9771 - val_loss: 0.5281 - val_accuracy: 0.8453\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0700 - accuracy: 0.9789 - val_loss: 0.4804 - val_accuracy: 0.8493\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0815 - accuracy: 0.9783 - val_loss: 0.4163 - val_accuracy: 0.8413\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0690 - accuracy: 0.9806 - val_loss: 0.7418 - val_accuracy: 0.7373\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0656 - accuracy: 0.9800 - val_loss: 0.7821 - val_accuracy: 0.7653\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0713 - accuracy: 0.9794 - val_loss: 0.5021 - val_accuracy: 0.8347\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0687 - accuracy: 0.9771 - val_loss: 0.5419 - val_accuracy: 0.8160\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0752 - accuracy: 0.9783 - val_loss: 0.5612 - val_accuracy: 0.8093\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0670 - accuracy: 0.9783 - val_loss: 0.4607 - val_accuracy: 0.8240\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0618 - accuracy: 0.9823 - val_loss: 0.3670 - val_accuracy: 0.8720\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0706 - accuracy: 0.9783 - val_loss: 0.3100 - val_accuracy: 0.8867\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0878 - accuracy: 0.9766 - val_loss: 0.2927 - val_accuracy: 0.8893\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.1165 - accuracy: 0.9657 - val_loss: 0.3316 - val_accuracy: 0.8947\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0963 - accuracy: 0.9697 - val_loss: 0.4016 - val_accuracy: 0.8413\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0747 - accuracy: 0.9806 - val_loss: 0.4679 - val_accuracy: 0.8560\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0790 - accuracy: 0.9794 - val_loss: 0.6217 - val_accuracy: 0.8093\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0826 - accuracy: 0.9754 - val_loss: 0.5864 - val_accuracy: 0.8120\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0605 - accuracy: 0.9846 - val_loss: 0.5387 - val_accuracy: 0.8000\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0725 - accuracy: 0.9789 - val_loss: 0.5500 - val_accuracy: 0.8413\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0836 - accuracy: 0.9817 - val_loss: 0.7710 - val_accuracy: 0.7427\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1059 - accuracy: 0.9731 - val_loss: 0.3694 - val_accuracy: 0.8813\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0702 - accuracy: 0.9783 - val_loss: 0.6582 - val_accuracy: 0.8853\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.0946 - accuracy: 0.9766 - val_loss: 0.5360 - val_accuracy: 0.8573\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0900 - accuracy: 0.9737 - val_loss: 0.6097 - val_accuracy: 0.8133\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0658 - accuracy: 0.9794 - val_loss: 0.6012 - val_accuracy: 0.8120\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0699 - accuracy: 0.9777 - val_loss: 0.3499 - val_accuracy: 0.8627\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0621 - accuracy: 0.9811 - val_loss: 0.4002 - val_accuracy: 0.8467\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0724 - accuracy: 0.9794 - val_loss: 0.4233 - val_accuracy: 0.8427\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0597 - accuracy: 0.9846 - val_loss: 0.3700 - val_accuracy: 0.8493\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0907 - accuracy: 0.9754 - val_loss: 0.4213 - val_accuracy: 0.8747\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0828 - accuracy: 0.9771 - val_loss: 0.4585 - val_accuracy: 0.8427\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0749 - accuracy: 0.9800 - val_loss: 0.4878 - val_accuracy: 0.8360\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0697 - accuracy: 0.9806 - val_loss: 0.4000 - val_accuracy: 0.8707\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0605 - accuracy: 0.9829 - val_loss: 0.3153 - val_accuracy: 0.8840\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0830 - accuracy: 0.9760 - val_loss: 0.4979 - val_accuracy: 0.8267\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0730 - accuracy: 0.9783 - val_loss: 0.4396 - val_accuracy: 0.8467\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0618 - accuracy: 0.9811 - val_loss: 0.7865 - val_accuracy: 0.7453\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0514 - accuracy: 0.9869 - val_loss: 0.4140 - val_accuracy: 0.8573\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0722 - accuracy: 0.9800 - val_loss: 0.5255 - val_accuracy: 0.8253\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0708 - accuracy: 0.9811 - val_loss: 0.3850 - val_accuracy: 0.8707\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0535 - accuracy: 0.9857 - val_loss: 0.4879 - val_accuracy: 0.8373\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0545 - accuracy: 0.9834 - val_loss: 0.5551 - val_accuracy: 0.8387\n",
      "Epoch 191/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0870 - accuracy: 0.9823 - val_loss: 0.5180 - val_accuracy: 0.8280\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0587 - accuracy: 0.9857 - val_loss: 0.6440 - val_accuracy: 0.7853\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0671 - accuracy: 0.9823 - val_loss: 0.4874 - val_accuracy: 0.8280\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0637 - accuracy: 0.9829 - val_loss: 0.4642 - val_accuracy: 0.8280\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0568 - accuracy: 0.9829 - val_loss: 0.5005 - val_accuracy: 0.8427\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0566 - accuracy: 0.9823 - val_loss: 0.5575 - val_accuracy: 0.8213\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0593 - accuracy: 0.9823 - val_loss: 0.5466 - val_accuracy: 0.8187\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0632 - accuracy: 0.9834 - val_loss: 0.4499 - val_accuracy: 0.8333\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0574 - accuracy: 0.9851 - val_loss: 0.5503 - val_accuracy: 0.8280\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0607 - accuracy: 0.9829 - val_loss: 0.5540 - val_accuracy: 0.8253\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 5)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 50s - loss: 2.3617 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1018s vs `on_train_batch_end` time: 0.7811s). Check your callbacks.\n",
      "110/110 [==============================] - 20s 184ms/step - loss: 0.8815 - accuracy: 0.7263 - val_loss: 0.7082 - val_accuracy: 0.6280\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.5708 - accuracy: 0.7943 - val_loss: 1.2483 - val_accuracy: 0.3720\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.4871 - accuracy: 0.8091 - val_loss: 0.6007 - val_accuracy: 0.6587\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.4439 - accuracy: 0.8394 - val_loss: 1.0024 - val_accuracy: 0.5933\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.4498 - accuracy: 0.8371 - val_loss: 0.8716 - val_accuracy: 0.6187\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.4686 - accuracy: 0.8251 - val_loss: 0.6011 - val_accuracy: 0.6907\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.4279 - accuracy: 0.8640 - val_loss: 0.8915 - val_accuracy: 0.7240\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.3650 - accuracy: 0.8543 - val_loss: 0.4669 - val_accuracy: 0.7120\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.3479 - accuracy: 0.8657 - val_loss: 0.5671 - val_accuracy: 0.7600\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.3761 - accuracy: 0.8543 - val_loss: 0.5384 - val_accuracy: 0.7813\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.3572 - accuracy: 0.8703 - val_loss: 0.6324 - val_accuracy: 0.7200\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.3924 - accuracy: 0.8651 - val_loss: 0.7745 - val_accuracy: 0.6907\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.3812 - accuracy: 0.8520 - val_loss: 0.6197 - val_accuracy: 0.7040\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.3819 - accuracy: 0.8629 - val_loss: 0.6305 - val_accuracy: 0.6947\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.4201 - accuracy: 0.8491 - val_loss: 0.5798 - val_accuracy: 0.7347\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.3685 - accuracy: 0.8669 - val_loss: 0.8092 - val_accuracy: 0.7107\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.3440 - accuracy: 0.8783 - val_loss: 0.5791 - val_accuracy: 0.7400\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.3277 - accuracy: 0.8737 - val_loss: 0.7026 - val_accuracy: 0.7307\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.3539 - accuracy: 0.8760 - val_loss: 0.5923 - val_accuracy: 0.7667\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.3126 - accuracy: 0.8977 - val_loss: 0.8574 - val_accuracy: 0.7240\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.3233 - accuracy: 0.8846 - val_loss: 0.8262 - val_accuracy: 0.7347\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2964 - accuracy: 0.8983 - val_loss: 0.8031 - val_accuracy: 0.6760\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2996 - accuracy: 0.8834 - val_loss: 0.7858 - val_accuracy: 0.7160\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.3064 - accuracy: 0.8931 - val_loss: 0.5464 - val_accuracy: 0.7373\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.3053 - accuracy: 0.8857 - val_loss: 0.6449 - val_accuracy: 0.7227\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2739 - accuracy: 0.9029 - val_loss: 0.5639 - val_accuracy: 0.7160\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2945 - accuracy: 0.8891 - val_loss: 0.6274 - val_accuracy: 0.7160\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2904 - accuracy: 0.8863 - val_loss: 0.6298 - val_accuracy: 0.7520\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2602 - accuracy: 0.9034 - val_loss: 0.5458 - val_accuracy: 0.7533\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2832 - accuracy: 0.8926 - val_loss: 0.5308 - val_accuracy: 0.7947\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.2644 - accuracy: 0.9126 - val_loss: 0.5689 - val_accuracy: 0.7720\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2944 - accuracy: 0.8949 - val_loss: 0.4942 - val_accuracy: 0.7427\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2482 - accuracy: 0.9103 - val_loss: 0.5074 - val_accuracy: 0.7440\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2833 - accuracy: 0.8989 - val_loss: 0.5410 - val_accuracy: 0.7360\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2729 - accuracy: 0.9051 - val_loss: 0.5760 - val_accuracy: 0.7507\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2456 - accuracy: 0.9137 - val_loss: 0.5634 - val_accuracy: 0.7960\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2592 - accuracy: 0.9114 - val_loss: 0.6310 - val_accuracy: 0.7813\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2598 - accuracy: 0.9069 - val_loss: 0.6289 - val_accuracy: 0.7640\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2445 - accuracy: 0.9149 - val_loss: 0.5338 - val_accuracy: 0.7573\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.2337 - accuracy: 0.9194 - val_loss: 0.6936 - val_accuracy: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200\n",
      "110/110 [==============================] - 19s 168ms/step - loss: 0.2106 - accuracy: 0.9223 - val_loss: 0.5511 - val_accuracy: 0.7760\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2254 - accuracy: 0.9194 - val_loss: 0.6728 - val_accuracy: 0.7373\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2263 - accuracy: 0.9229 - val_loss: 0.5888 - val_accuracy: 0.7827\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.2194 - accuracy: 0.9269 - val_loss: 0.5176 - val_accuracy: 0.8000\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2148 - accuracy: 0.9309 - val_loss: 0.6467 - val_accuracy: 0.7293\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2240 - accuracy: 0.9320 - val_loss: 0.4534 - val_accuracy: 0.7680\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2135 - accuracy: 0.9269 - val_loss: 0.4768 - val_accuracy: 0.7867\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1989 - accuracy: 0.9303 - val_loss: 0.5947 - val_accuracy: 0.7413\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2024 - accuracy: 0.9337 - val_loss: 0.5878 - val_accuracy: 0.7707\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1961 - accuracy: 0.9343 - val_loss: 0.7139 - val_accuracy: 0.7307\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.2197 - accuracy: 0.9320 - val_loss: 0.7189 - val_accuracy: 0.7400\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2014 - accuracy: 0.9360 - val_loss: 0.4991 - val_accuracy: 0.7813\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1928 - accuracy: 0.9411 - val_loss: 0.5167 - val_accuracy: 0.7827\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1862 - accuracy: 0.9349 - val_loss: 0.8419 - val_accuracy: 0.7093\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1759 - accuracy: 0.9406 - val_loss: 0.5057 - val_accuracy: 0.8267\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1986 - accuracy: 0.9337 - val_loss: 0.7590 - val_accuracy: 0.7267\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1908 - accuracy: 0.9394 - val_loss: 0.7402 - val_accuracy: 0.7373\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1788 - accuracy: 0.9440 - val_loss: 0.5428 - val_accuracy: 0.7880\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1568 - accuracy: 0.9520 - val_loss: 0.6905 - val_accuracy: 0.7533\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1779 - accuracy: 0.9434 - val_loss: 0.6206 - val_accuracy: 0.7640\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.1962 - accuracy: 0.9371 - val_loss: 0.4242 - val_accuracy: 0.8173\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1837 - accuracy: 0.9394 - val_loss: 0.7356 - val_accuracy: 0.7427\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1585 - accuracy: 0.9469 - val_loss: 0.6217 - val_accuracy: 0.7547\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1713 - accuracy: 0.9394 - val_loss: 0.6016 - val_accuracy: 0.7440\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1732 - accuracy: 0.9469 - val_loss: 0.6100 - val_accuracy: 0.7587\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1598 - accuracy: 0.9486 - val_loss: 0.4337 - val_accuracy: 0.8107\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1716 - accuracy: 0.9451 - val_loss: 0.5578 - val_accuracy: 0.7813\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1652 - accuracy: 0.9463 - val_loss: 0.4956 - val_accuracy: 0.8133\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1519 - accuracy: 0.9514 - val_loss: 0.7509 - val_accuracy: 0.7653\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1667 - accuracy: 0.9446 - val_loss: 0.7695 - val_accuracy: 0.7240\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.1794 - accuracy: 0.9451 - val_loss: 0.5824 - val_accuracy: 0.7720\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1524 - accuracy: 0.9537 - val_loss: 0.6700 - val_accuracy: 0.7627\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1884 - accuracy: 0.9526 - val_loss: 0.5834 - val_accuracy: 0.7947\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1653 - accuracy: 0.9480 - val_loss: 0.5433 - val_accuracy: 0.8000\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1656 - accuracy: 0.9406 - val_loss: 0.5983 - val_accuracy: 0.7920\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1637 - accuracy: 0.9486 - val_loss: 0.5169 - val_accuracy: 0.7880\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1799 - accuracy: 0.9440 - val_loss: 0.5044 - val_accuracy: 0.7827\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2256 - accuracy: 0.9446 - val_loss: 0.6225 - val_accuracy: 0.7907\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1433 - accuracy: 0.9520 - val_loss: 0.5002 - val_accuracy: 0.8080\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1481 - accuracy: 0.9560 - val_loss: 0.8025 - val_accuracy: 0.7813\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 19s 168ms/step - loss: 0.1547 - accuracy: 0.9543 - val_loss: 0.5287 - val_accuracy: 0.7987\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1554 - accuracy: 0.9514 - val_loss: 0.5064 - val_accuracy: 0.8080\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1516 - accuracy: 0.9486 - val_loss: 0.5901 - val_accuracy: 0.8067\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1420 - accuracy: 0.9594 - val_loss: 0.7090 - val_accuracy: 0.7813\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1318 - accuracy: 0.9594 - val_loss: 0.5380 - val_accuracy: 0.8013\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1418 - accuracy: 0.9526 - val_loss: 0.8149 - val_accuracy: 0.7573\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1493 - accuracy: 0.9509 - val_loss: 0.5013 - val_accuracy: 0.8013\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1454 - accuracy: 0.9520 - val_loss: 0.5479 - val_accuracy: 0.7933\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1551 - accuracy: 0.9491 - val_loss: 0.6529 - val_accuracy: 0.7813\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1188 - accuracy: 0.9617 - val_loss: 0.7104 - val_accuracy: 0.7880\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 19s 168ms/step - loss: 0.1298 - accuracy: 0.9640 - val_loss: 0.6250 - val_accuracy: 0.7987\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1439 - accuracy: 0.9549 - val_loss: 0.4535 - val_accuracy: 0.8280\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1331 - accuracy: 0.9571 - val_loss: 0.6823 - val_accuracy: 0.7867\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1367 - accuracy: 0.9543 - val_loss: 0.5525 - val_accuracy: 0.8053\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1321 - accuracy: 0.9634 - val_loss: 0.6170 - val_accuracy: 0.7987\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1253 - accuracy: 0.9606 - val_loss: 0.3888 - val_accuracy: 0.8467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1299 - accuracy: 0.9554 - val_loss: 0.6050 - val_accuracy: 0.7893\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1255 - accuracy: 0.9589 - val_loss: 0.7135 - val_accuracy: 0.7987\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1172 - accuracy: 0.9606 - val_loss: 0.5958 - val_accuracy: 0.8253\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1313 - accuracy: 0.9577 - val_loss: 0.5295 - val_accuracy: 0.8267\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 19s 170ms/step - loss: 0.1234 - accuracy: 0.9600 - val_loss: 0.4724 - val_accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1297 - accuracy: 0.9634 - val_loss: 0.5710 - val_accuracy: 0.8160\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1218 - accuracy: 0.9589 - val_loss: 0.7323 - val_accuracy: 0.7787\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1275 - accuracy: 0.9577 - val_loss: 0.6144 - val_accuracy: 0.8213\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1379 - accuracy: 0.9640 - val_loss: 0.6388 - val_accuracy: 0.7933\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1099 - accuracy: 0.9640 - val_loss: 0.5986 - val_accuracy: 0.8227\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1173 - accuracy: 0.9606 - val_loss: 0.5237 - val_accuracy: 0.8267\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1113 - accuracy: 0.9669 - val_loss: 0.9703 - val_accuracy: 0.7827\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1307 - accuracy: 0.9629 - val_loss: 0.7193 - val_accuracy: 0.7733\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1220 - accuracy: 0.9589 - val_loss: 0.5805 - val_accuracy: 0.7973\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.1221 - accuracy: 0.9634 - val_loss: 0.5991 - val_accuracy: 0.8133\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1035 - accuracy: 0.9709 - val_loss: 0.5679 - val_accuracy: 0.8320\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1076 - accuracy: 0.9669 - val_loss: 0.7801 - val_accuracy: 0.7960\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1106 - accuracy: 0.9697 - val_loss: 0.5634 - val_accuracy: 0.8133\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1143 - accuracy: 0.9657 - val_loss: 0.4766 - val_accuracy: 0.8360\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1087 - accuracy: 0.9691 - val_loss: 0.6464 - val_accuracy: 0.8173\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1053 - accuracy: 0.9669 - val_loss: 0.5434 - val_accuracy: 0.8253\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1111 - accuracy: 0.9651 - val_loss: 0.5176 - val_accuracy: 0.8453\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1105 - accuracy: 0.9663 - val_loss: 0.5744 - val_accuracy: 0.8267\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1294 - accuracy: 0.9606 - val_loss: 0.5702 - val_accuracy: 0.8093\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.1137 - accuracy: 0.9674 - val_loss: 0.5199 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1145 - accuracy: 0.9629 - val_loss: 0.6077 - val_accuracy: 0.8240\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1149 - accuracy: 0.9669 - val_loss: 0.7133 - val_accuracy: 0.7853\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1138 - accuracy: 0.9617 - val_loss: 0.5073 - val_accuracy: 0.8320\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1040 - accuracy: 0.9674 - val_loss: 0.6013 - val_accuracy: 0.8133\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0987 - accuracy: 0.9691 - val_loss: 0.4886 - val_accuracy: 0.8360\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0985 - accuracy: 0.9709 - val_loss: 0.5661 - val_accuracy: 0.8160\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1063 - accuracy: 0.9657 - val_loss: 0.6667 - val_accuracy: 0.7853\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0869 - accuracy: 0.9737 - val_loss: 0.7148 - val_accuracy: 0.7893\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1104 - accuracy: 0.9674 - val_loss: 0.7434 - val_accuracy: 0.7827\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.1010 - accuracy: 0.9703 - val_loss: 0.8109 - val_accuracy: 0.7773\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1033 - accuracy: 0.9657 - val_loss: 0.5287 - val_accuracy: 0.8187\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1048 - accuracy: 0.9663 - val_loss: 0.5946 - val_accuracy: 0.8133\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0991 - accuracy: 0.9726 - val_loss: 0.6556 - val_accuracy: 0.7867\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1037 - accuracy: 0.9720 - val_loss: 0.6273 - val_accuracy: 0.7933\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0980 - accuracy: 0.9697 - val_loss: 0.6932 - val_accuracy: 0.8040\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1245 - accuracy: 0.9663 - val_loss: 0.5965 - val_accuracy: 0.8173\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0898 - accuracy: 0.9749 - val_loss: 0.4841 - val_accuracy: 0.8227\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1001 - accuracy: 0.9697 - val_loss: 0.6611 - val_accuracy: 0.7853\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0963 - accuracy: 0.9674 - val_loss: 0.5571 - val_accuracy: 0.8227\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 19s 170ms/step - loss: 0.0994 - accuracy: 0.9680 - val_loss: 0.5494 - val_accuracy: 0.8240\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0854 - accuracy: 0.9749 - val_loss: 0.4822 - val_accuracy: 0.8320\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1282 - accuracy: 0.9611 - val_loss: 0.4983 - val_accuracy: 0.8360\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1068 - accuracy: 0.9680 - val_loss: 0.5111 - val_accuracy: 0.8120\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0924 - accuracy: 0.9714 - val_loss: 0.6785 - val_accuracy: 0.8067\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0869 - accuracy: 0.9714 - val_loss: 0.6237 - val_accuracy: 0.8080\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0980 - accuracy: 0.9697 - val_loss: 0.6537 - val_accuracy: 0.8173\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0893 - accuracy: 0.9714 - val_loss: 0.4985 - val_accuracy: 0.8187\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1224 - accuracy: 0.9709 - val_loss: 0.5389 - val_accuracy: 0.8307\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1151 - accuracy: 0.9657 - val_loss: 0.6219 - val_accuracy: 0.8253\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.0843 - accuracy: 0.9749 - val_loss: 0.5502 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1025 - accuracy: 0.9651 - val_loss: 0.5030 - val_accuracy: 0.8227\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0880 - accuracy: 0.9731 - val_loss: 0.5625 - val_accuracy: 0.8240\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0955 - accuracy: 0.9709 - val_loss: 0.7026 - val_accuracy: 0.7987\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1081 - accuracy: 0.9646 - val_loss: 0.5173 - val_accuracy: 0.8240\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1447 - accuracy: 0.9646 - val_loss: 0.6915 - val_accuracy: 0.7920\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0892 - accuracy: 0.9726 - val_loss: 0.5495 - val_accuracy: 0.8320\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0897 - accuracy: 0.9731 - val_loss: 0.5511 - val_accuracy: 0.8067\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0916 - accuracy: 0.9726 - val_loss: 0.5482 - val_accuracy: 0.8187\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0916 - accuracy: 0.9726 - val_loss: 0.6635 - val_accuracy: 0.8107\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.1092 - accuracy: 0.9663 - val_loss: 0.4116 - val_accuracy: 0.8413\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0919 - accuracy: 0.9749 - val_loss: 0.4794 - val_accuracy: 0.8267\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0853 - accuracy: 0.9726 - val_loss: 0.4923 - val_accuracy: 0.8080\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1018 - accuracy: 0.9680 - val_loss: 0.4352 - val_accuracy: 0.8387\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0872 - accuracy: 0.9754 - val_loss: 0.5597 - val_accuracy: 0.8120\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0897 - accuracy: 0.9737 - val_loss: 0.6600 - val_accuracy: 0.7787\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0833 - accuracy: 0.9749 - val_loss: 0.5766 - val_accuracy: 0.8253\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0890 - accuracy: 0.9731 - val_loss: 0.5744 - val_accuracy: 0.8213\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0997 - accuracy: 0.9703 - val_loss: 0.5292 - val_accuracy: 0.8147\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0830 - accuracy: 0.9766 - val_loss: 0.4798 - val_accuracy: 0.8253\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.0944 - accuracy: 0.9680 - val_loss: 0.4609 - val_accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0885 - accuracy: 0.9771 - val_loss: 0.5103 - val_accuracy: 0.8320\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0925 - accuracy: 0.9760 - val_loss: 0.5405 - val_accuracy: 0.8227\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0908 - accuracy: 0.9714 - val_loss: 0.4947 - val_accuracy: 0.8280\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0865 - accuracy: 0.9720 - val_loss: 0.4295 - val_accuracy: 0.8560\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0936 - accuracy: 0.9697 - val_loss: 0.3900 - val_accuracy: 0.8520\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0817 - accuracy: 0.9760 - val_loss: 0.6246 - val_accuracy: 0.8227\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0985 - accuracy: 0.9714 - val_loss: 0.6222 - val_accuracy: 0.8133\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0723 - accuracy: 0.9789 - val_loss: 0.7109 - val_accuracy: 0.8213\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0865 - accuracy: 0.9766 - val_loss: 0.6240 - val_accuracy: 0.8120\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.0764 - accuracy: 0.9783 - val_loss: 0.5305 - val_accuracy: 0.8293\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0868 - accuracy: 0.9714 - val_loss: 0.6372 - val_accuracy: 0.8093\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1067 - accuracy: 0.9703 - val_loss: 0.5210 - val_accuracy: 0.8227\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0950 - accuracy: 0.9686 - val_loss: 0.6147 - val_accuracy: 0.8093\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1177 - accuracy: 0.9691 - val_loss: 0.5363 - val_accuracy: 0.8227\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0817 - accuracy: 0.9760 - val_loss: 0.6904 - val_accuracy: 0.8227\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0840 - accuracy: 0.9760 - val_loss: 0.5361 - val_accuracy: 0.8320\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0772 - accuracy: 0.9794 - val_loss: 0.5707 - val_accuracy: 0.8373\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0976 - accuracy: 0.9686 - val_loss: 0.4414 - val_accuracy: 0.8307\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0642 - accuracy: 0.9834 - val_loss: 0.5436 - val_accuracy: 0.8360\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 19s 170ms/step - loss: 0.1187 - accuracy: 0.9657 - val_loss: 0.5016 - val_accuracy: 0.8480\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0828 - accuracy: 0.9766 - val_loss: 0.5037 - val_accuracy: 0.8360\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0947 - accuracy: 0.9731 - val_loss: 0.5555 - val_accuracy: 0.8240\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0848 - accuracy: 0.9737 - val_loss: 0.4374 - val_accuracy: 0.8480\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0801 - accuracy: 0.9777 - val_loss: 0.5118 - val_accuracy: 0.8227\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0760 - accuracy: 0.9777 - val_loss: 0.6889 - val_accuracy: 0.7800\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0652 - accuracy: 0.9806 - val_loss: 0.5036 - val_accuracy: 0.8253\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0774 - accuracy: 0.9777 - val_loss: 0.5987 - val_accuracy: 0.8133\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0846 - accuracy: 0.9749 - val_loss: 0.5788 - val_accuracy: 0.7933\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0826 - accuracy: 0.9731 - val_loss: 0.6058 - val_accuracy: 0.8240\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 1)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 50s - loss: 4.8495 - accuracy: 0.5312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0866s vs `on_train_batch_end` time: 0.8156s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 167ms/step - loss: 1.3791 - accuracy: 0.7103 - val_loss: 0.8658 - val_accuracy: 0.3720\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.6473 - accuracy: 0.7497 - val_loss: 0.9531 - val_accuracy: 0.3720\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.5066 - accuracy: 0.7891 - val_loss: 1.0156 - val_accuracy: 0.5320\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.5049 - accuracy: 0.8126 - val_loss: 1.1753 - val_accuracy: 0.5720\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.3483 - accuracy: 0.8583 - val_loss: 0.5804 - val_accuracy: 0.8253\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.3321 - accuracy: 0.8897 - val_loss: 0.5516 - val_accuracy: 0.8320\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.3132 - accuracy: 0.8989 - val_loss: 1.4991 - val_accuracy: 0.7187\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.3224 - accuracy: 0.8823 - val_loss: 0.3046 - val_accuracy: 0.8867\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2556 - accuracy: 0.9183 - val_loss: 0.3209 - val_accuracy: 0.8867\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.3101 - accuracy: 0.9057 - val_loss: 0.1986 - val_accuracy: 0.9187\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 17s 153ms/step - loss: 0.2385 - accuracy: 0.9143 - val_loss: 0.4724 - val_accuracy: 0.8520\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2201 - accuracy: 0.9263 - val_loss: 0.2041 - val_accuracy: 0.9107\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2565 - accuracy: 0.9177 - val_loss: 0.1775 - val_accuracy: 0.9253\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2238 - accuracy: 0.9251 - val_loss: 0.2726 - val_accuracy: 0.9147\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2040 - accuracy: 0.9331 - val_loss: 0.3311 - val_accuracy: 0.8760\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.2233 - accuracy: 0.9200 - val_loss: 0.2712 - val_accuracy: 0.8840\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2117 - accuracy: 0.9331 - val_loss: 0.2052 - val_accuracy: 0.9213\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2182 - accuracy: 0.9354 - val_loss: 0.2028 - val_accuracy: 0.9267\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1944 - accuracy: 0.9354 - val_loss: 0.2051 - val_accuracy: 0.9267\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1860 - accuracy: 0.9360 - val_loss: 0.2091 - val_accuracy: 0.9293\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.2536 - accuracy: 0.9097 - val_loss: 0.2599 - val_accuracy: 0.9227\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.3127 - accuracy: 0.9091 - val_loss: 0.3617 - val_accuracy: 0.8867\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.4280 - accuracy: 0.8543 - val_loss: 1.6620 - val_accuracy: 0.9107\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.3121 - accuracy: 0.8823 - val_loss: 0.3984 - val_accuracy: 0.8533\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.3029 - accuracy: 0.9011 - val_loss: 0.3162 - val_accuracy: 0.8627\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2570 - accuracy: 0.9057 - val_loss: 0.3558 - val_accuracy: 0.8413\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2548 - accuracy: 0.9137 - val_loss: 0.3578 - val_accuracy: 0.8720\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2077 - accuracy: 0.9274 - val_loss: 0.2001 - val_accuracy: 0.9253\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2298 - accuracy: 0.9211 - val_loss: 0.2372 - val_accuracy: 0.9053\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2167 - accuracy: 0.9223 - val_loss: 0.2633 - val_accuracy: 0.8893\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.2060 - accuracy: 0.9257 - val_loss: 0.1967 - val_accuracy: 0.9293\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1907 - accuracy: 0.9400 - val_loss: 0.1986 - val_accuracy: 0.9227\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1870 - accuracy: 0.9343 - val_loss: 0.2375 - val_accuracy: 0.9133\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2441 - accuracy: 0.9217 - val_loss: 0.3240 - val_accuracy: 0.8853\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1962 - accuracy: 0.9354 - val_loss: 0.2117 - val_accuracy: 0.9307\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1962 - accuracy: 0.9429 - val_loss: 0.2371 - val_accuracy: 0.9147\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1736 - accuracy: 0.9480 - val_loss: 0.1968 - val_accuracy: 0.9360\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1916 - accuracy: 0.9331 - val_loss: 0.2117 - val_accuracy: 0.9320\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1729 - accuracy: 0.9491 - val_loss: 0.2326 - val_accuracy: 0.9253\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1720 - accuracy: 0.9429 - val_loss: 0.2236 - val_accuracy: 0.9173\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1635 - accuracy: 0.9429 - val_loss: 0.2742 - val_accuracy: 0.9120\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1851 - accuracy: 0.9486 - val_loss: 0.2202 - val_accuracy: 0.9227\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1818 - accuracy: 0.9423 - val_loss: 0.1951 - val_accuracy: 0.9360\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1730 - accuracy: 0.9486 - val_loss: 0.1841 - val_accuracy: 0.9453\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1741 - accuracy: 0.9503 - val_loss: 0.2037 - val_accuracy: 0.9253\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1577 - accuracy: 0.9531 - val_loss: 0.2434 - val_accuracy: 0.9267\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1926 - accuracy: 0.9400 - val_loss: 0.2091 - val_accuracy: 0.9320\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1496 - accuracy: 0.9531 - val_loss: 0.1616 - val_accuracy: 0.9427\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1483 - accuracy: 0.9554 - val_loss: 0.2181 - val_accuracy: 0.9333\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1413 - accuracy: 0.9549 - val_loss: 0.2307 - val_accuracy: 0.9227\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.1481 - accuracy: 0.9537 - val_loss: 0.2353 - val_accuracy: 0.9187\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1641 - accuracy: 0.9474 - val_loss: 0.1959 - val_accuracy: 0.9333\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1848 - accuracy: 0.9560 - val_loss: 0.1915 - val_accuracy: 0.9347\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1534 - accuracy: 0.9480 - val_loss: 0.2438 - val_accuracy: 0.9307\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1487 - accuracy: 0.9554 - val_loss: 0.2029 - val_accuracy: 0.9307\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1553 - accuracy: 0.9577 - val_loss: 0.1706 - val_accuracy: 0.9480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1586 - accuracy: 0.9554 - val_loss: 0.3226 - val_accuracy: 0.9000\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1633 - accuracy: 0.9549 - val_loss: 0.2588 - val_accuracy: 0.9067\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1847 - accuracy: 0.9491 - val_loss: 0.1954 - val_accuracy: 0.9267\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1474 - accuracy: 0.9537 - val_loss: 0.1873 - val_accuracy: 0.9400\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1767 - accuracy: 0.9509 - val_loss: 0.2185 - val_accuracy: 0.9267\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1588 - accuracy: 0.9480 - val_loss: 0.2539 - val_accuracy: 0.9253\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1525 - accuracy: 0.9537 - val_loss: 0.1719 - val_accuracy: 0.9387\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1649 - accuracy: 0.9491 - val_loss: 0.2260 - val_accuracy: 0.9240\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1332 - accuracy: 0.9617 - val_loss: 0.2279 - val_accuracy: 0.9387\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1178 - accuracy: 0.9646 - val_loss: 0.2568 - val_accuracy: 0.9293\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1365 - accuracy: 0.9629 - val_loss: 0.2893 - val_accuracy: 0.9333\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1345 - accuracy: 0.9611 - val_loss: 0.2020 - val_accuracy: 0.9427\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1442 - accuracy: 0.9640 - val_loss: 0.2330 - val_accuracy: 0.9293\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1797 - accuracy: 0.9463 - val_loss: 0.2793 - val_accuracy: 0.9053\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.1384 - accuracy: 0.9537 - val_loss: 0.2148 - val_accuracy: 0.9333\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1569 - accuracy: 0.9594 - val_loss: 0.1849 - val_accuracy: 0.9400\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1581 - accuracy: 0.9537 - val_loss: 0.1929 - val_accuracy: 0.9320\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1315 - accuracy: 0.9611 - val_loss: 0.1957 - val_accuracy: 0.9320\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1315 - accuracy: 0.9583 - val_loss: 0.2210 - val_accuracy: 0.9360\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1395 - accuracy: 0.9571 - val_loss: 0.2132 - val_accuracy: 0.9373\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1180 - accuracy: 0.9606 - val_loss: 0.2088 - val_accuracy: 0.9387\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1322 - accuracy: 0.9589 - val_loss: 0.1507 - val_accuracy: 0.9520\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1561 - accuracy: 0.9651 - val_loss: 0.1584 - val_accuracy: 0.9467\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1275 - accuracy: 0.9611 - val_loss: 0.1910 - val_accuracy: 0.9453\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1293 - accuracy: 0.9611 - val_loss: 0.1662 - val_accuracy: 0.9507\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1045 - accuracy: 0.9697 - val_loss: 0.1730 - val_accuracy: 0.9453\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1273 - accuracy: 0.9623 - val_loss: 0.1906 - val_accuracy: 0.9427\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1676 - accuracy: 0.9600 - val_loss: 0.1754 - val_accuracy: 0.9427\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1262 - accuracy: 0.9623 - val_loss: 0.1878 - val_accuracy: 0.9440\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1006 - accuracy: 0.9714 - val_loss: 0.1742 - val_accuracy: 0.9400\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1438 - accuracy: 0.9623 - val_loss: 0.2358 - val_accuracy: 0.9280\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1423 - accuracy: 0.9589 - val_loss: 0.2234 - val_accuracy: 0.9347\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1181 - accuracy: 0.9663 - val_loss: 0.2020 - val_accuracy: 0.9440\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1140 - accuracy: 0.9629 - val_loss: 0.1758 - val_accuracy: 0.9400\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1037 - accuracy: 0.9714 - val_loss: 0.2535 - val_accuracy: 0.9333\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1186 - accuracy: 0.9634 - val_loss: 0.1951 - val_accuracy: 0.9413\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1046 - accuracy: 0.9680 - val_loss: 0.1805 - val_accuracy: 0.9373\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1412 - accuracy: 0.9600 - val_loss: 0.2383 - val_accuracy: 0.9320\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1096 - accuracy: 0.9669 - val_loss: 0.1633 - val_accuracy: 0.9467\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0955 - accuracy: 0.9697 - val_loss: 0.2489 - val_accuracy: 0.9347\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1003 - accuracy: 0.9680 - val_loss: 0.1699 - val_accuracy: 0.9387\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0975 - accuracy: 0.9709 - val_loss: 0.1604 - val_accuracy: 0.9480\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1193 - accuracy: 0.9674 - val_loss: 0.1969 - val_accuracy: 0.9307\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1125 - accuracy: 0.9646 - val_loss: 0.2568 - val_accuracy: 0.9293\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 17s 153ms/step - loss: 0.1001 - accuracy: 0.9697 - val_loss: 0.1543 - val_accuracy: 0.9533\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0897 - accuracy: 0.9714 - val_loss: 0.1685 - val_accuracy: 0.9467\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1048 - accuracy: 0.9674 - val_loss: 0.1833 - val_accuracy: 0.9427\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1370 - accuracy: 0.9651 - val_loss: 0.1813 - val_accuracy: 0.9507\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1295 - accuracy: 0.9617 - val_loss: 0.2557 - val_accuracy: 0.9187\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1216 - accuracy: 0.9583 - val_loss: 0.1864 - val_accuracy: 0.9320\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1510 - accuracy: 0.9543 - val_loss: 0.1711 - val_accuracy: 0.9360\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1196 - accuracy: 0.9634 - val_loss: 0.2135 - val_accuracy: 0.9307\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1040 - accuracy: 0.9697 - val_loss: 0.1744 - val_accuracy: 0.9453\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1193 - accuracy: 0.9634 - val_loss: 0.1553 - val_accuracy: 0.9493\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 17s 153ms/step - loss: 0.1107 - accuracy: 0.9674 - val_loss: 0.2168 - val_accuracy: 0.9373\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1345 - accuracy: 0.9657 - val_loss: 0.1815 - val_accuracy: 0.9520\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1166 - accuracy: 0.9646 - val_loss: 0.1789 - val_accuracy: 0.9520\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1058 - accuracy: 0.9766 - val_loss: 0.1747 - val_accuracy: 0.9440\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0899 - accuracy: 0.9726 - val_loss: 0.1725 - val_accuracy: 0.9480\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0844 - accuracy: 0.9731 - val_loss: 0.1711 - val_accuracy: 0.9467\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1182 - accuracy: 0.9674 - val_loss: 0.1476 - val_accuracy: 0.9507\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1021 - accuracy: 0.9709 - val_loss: 0.1519 - val_accuracy: 0.9560\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0830 - accuracy: 0.9771 - val_loss: 0.1705 - val_accuracy: 0.9520\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0870 - accuracy: 0.9749 - val_loss: 0.2116 - val_accuracy: 0.9467\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1029 - accuracy: 0.9720 - val_loss: 0.1791 - val_accuracy: 0.9493\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0901 - accuracy: 0.9731 - val_loss: 0.1817 - val_accuracy: 0.9373\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1140 - accuracy: 0.9629 - val_loss: 0.1727 - val_accuracy: 0.9427\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1056 - accuracy: 0.9686 - val_loss: 0.1829 - val_accuracy: 0.9453\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0947 - accuracy: 0.9743 - val_loss: 0.1854 - val_accuracy: 0.9453\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1229 - accuracy: 0.9714 - val_loss: 0.1479 - val_accuracy: 0.9533\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0850 - accuracy: 0.9777 - val_loss: 0.1566 - val_accuracy: 0.9547\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1101 - accuracy: 0.9680 - val_loss: 0.1693 - val_accuracy: 0.9440\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0881 - accuracy: 0.9749 - val_loss: 0.1710 - val_accuracy: 0.9453\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1034 - accuracy: 0.9674 - val_loss: 0.1743 - val_accuracy: 0.9440\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.0794 - accuracy: 0.9811 - val_loss: 0.1632 - val_accuracy: 0.9533\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0952 - accuracy: 0.9714 - val_loss: 0.1637 - val_accuracy: 0.9400\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1010 - accuracy: 0.9691 - val_loss: 0.1426 - val_accuracy: 0.9547\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0948 - accuracy: 0.9749 - val_loss: 0.1518 - val_accuracy: 0.9480\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0835 - accuracy: 0.9777 - val_loss: 0.1172 - val_accuracy: 0.9627\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0857 - accuracy: 0.9749 - val_loss: 0.1465 - val_accuracy: 0.9547\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0806 - accuracy: 0.9743 - val_loss: 0.1366 - val_accuracy: 0.9520\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0852 - accuracy: 0.9754 - val_loss: 0.1815 - val_accuracy: 0.9507\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1094 - accuracy: 0.9777 - val_loss: 0.1951 - val_accuracy: 0.9400\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0805 - accuracy: 0.9749 - val_loss: 0.2322 - val_accuracy: 0.9240\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 17s 153ms/step - loss: 0.1160 - accuracy: 0.9583 - val_loss: 0.1510 - val_accuracy: 0.9467\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1022 - accuracy: 0.9691 - val_loss: 0.1340 - val_accuracy: 0.9587\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0834 - accuracy: 0.9754 - val_loss: 0.1694 - val_accuracy: 0.9520\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0798 - accuracy: 0.9766 - val_loss: 0.1518 - val_accuracy: 0.9547\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0911 - accuracy: 0.9737 - val_loss: 0.1591 - val_accuracy: 0.9507\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1084 - accuracy: 0.9766 - val_loss: 0.1391 - val_accuracy: 0.9493\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1251 - accuracy: 0.9669 - val_loss: 0.1577 - val_accuracy: 0.9440\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0986 - accuracy: 0.9663 - val_loss: 0.1344 - val_accuracy: 0.9560\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1043 - accuracy: 0.9697 - val_loss: 0.1629 - val_accuracy: 0.9533\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0935 - accuracy: 0.9720 - val_loss: 0.1700 - val_accuracy: 0.9413\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.0872 - accuracy: 0.9766 - val_loss: 0.1957 - val_accuracy: 0.9293\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1040 - accuracy: 0.9669 - val_loss: 0.1566 - val_accuracy: 0.9533\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0832 - accuracy: 0.9771 - val_loss: 0.1584 - val_accuracy: 0.9507\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0830 - accuracy: 0.9726 - val_loss: 0.1611 - val_accuracy: 0.9547\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0714 - accuracy: 0.9789 - val_loss: 0.1572 - val_accuracy: 0.9533\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1044 - accuracy: 0.9731 - val_loss: 0.1875 - val_accuracy: 0.9333\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1124 - accuracy: 0.9703 - val_loss: 0.1793 - val_accuracy: 0.9453\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0933 - accuracy: 0.9714 - val_loss: 0.2169 - val_accuracy: 0.9333\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1171 - accuracy: 0.9731 - val_loss: 0.2298 - val_accuracy: 0.9307\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1122 - accuracy: 0.9726 - val_loss: 0.1393 - val_accuracy: 0.9547\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.0962 - accuracy: 0.9720 - val_loss: 0.1550 - val_accuracy: 0.9533\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0913 - accuracy: 0.9731 - val_loss: 0.1406 - val_accuracy: 0.9520\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0764 - accuracy: 0.9766 - val_loss: 0.1545 - val_accuracy: 0.9533\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0839 - accuracy: 0.9771 - val_loss: 0.1631 - val_accuracy: 0.9493\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0915 - accuracy: 0.9766 - val_loss: 0.1598 - val_accuracy: 0.9533\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0794 - accuracy: 0.9783 - val_loss: 0.1502 - val_accuracy: 0.9507\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1027 - accuracy: 0.9754 - val_loss: 0.1241 - val_accuracy: 0.9613\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0795 - accuracy: 0.9783 - val_loss: 0.1686 - val_accuracy: 0.9547\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0745 - accuracy: 0.9789 - val_loss: 0.1946 - val_accuracy: 0.9413\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0941 - accuracy: 0.9703 - val_loss: 0.1451 - val_accuracy: 0.9547\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.0844 - accuracy: 0.9783 - val_loss: 0.1365 - val_accuracy: 0.9560\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0745 - accuracy: 0.9777 - val_loss: 0.2044 - val_accuracy: 0.9333\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0805 - accuracy: 0.9726 - val_loss: 0.1533 - val_accuracy: 0.9520\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0750 - accuracy: 0.9771 - val_loss: 0.1230 - val_accuracy: 0.9600\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0866 - accuracy: 0.9737 - val_loss: 0.1222 - val_accuracy: 0.9587\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0737 - accuracy: 0.9771 - val_loss: 0.1361 - val_accuracy: 0.9613\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0979 - accuracy: 0.9754 - val_loss: 0.1303 - val_accuracy: 0.9560\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0814 - accuracy: 0.9731 - val_loss: 0.1270 - val_accuracy: 0.9600\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0831 - accuracy: 0.9754 - val_loss: 0.1808 - val_accuracy: 0.9427\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.0843 - accuracy: 0.9726 - val_loss: 0.2727 - val_accuracy: 0.9293\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.0850 - accuracy: 0.9737 - val_loss: 0.2115 - val_accuracy: 0.9373\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0784 - accuracy: 0.9800 - val_loss: 0.1808 - val_accuracy: 0.9480\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1051 - accuracy: 0.9731 - val_loss: 0.1944 - val_accuracy: 0.9373\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0819 - accuracy: 0.9766 - val_loss: 0.1517 - val_accuracy: 0.9533\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0879 - accuracy: 0.9726 - val_loss: 0.1989 - val_accuracy: 0.9360\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0992 - accuracy: 0.9754 - val_loss: 0.1387 - val_accuracy: 0.9547\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1292 - accuracy: 0.9680 - val_loss: 0.1707 - val_accuracy: 0.9480\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1105 - accuracy: 0.9691 - val_loss: 0.3065 - val_accuracy: 0.9067\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0829 - accuracy: 0.9806 - val_loss: 0.1502 - val_accuracy: 0.9493\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0772 - accuracy: 0.9749 - val_loss: 0.1403 - val_accuracy: 0.9573\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.0780 - accuracy: 0.9749 - val_loss: 0.2002 - val_accuracy: 0.9347\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0733 - accuracy: 0.9771 - val_loss: 0.1358 - val_accuracy: 0.9573\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0808 - accuracy: 0.9783 - val_loss: 0.1537 - val_accuracy: 0.9453\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0856 - accuracy: 0.9720 - val_loss: 0.1633 - val_accuracy: 0.9453\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0902 - accuracy: 0.9760 - val_loss: 0.1262 - val_accuracy: 0.9573\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0758 - accuracy: 0.9777 - val_loss: 0.1295 - val_accuracy: 0.9560\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1248 - accuracy: 0.9663 - val_loss: 0.1394 - val_accuracy: 0.9507\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0847 - accuracy: 0.9737 - val_loss: 0.1145 - val_accuracy: 0.9573\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0714 - accuracy: 0.9783 - val_loss: 0.1913 - val_accuracy: 0.9400\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0813 - accuracy: 0.9731 - val_loss: 0.1181 - val_accuracy: 0.9613\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 1)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 49s - loss: 1.9259 - accuracy: 0.5625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0575s vs `on_train_batch_end` time: 0.8204s). Check your callbacks.\n",
      "110/110 [==============================] - 19s 168ms/step - loss: 1.1814 - accuracy: 0.6823 - val_loss: 0.7664 - val_accuracy: 0.3720\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.7178 - accuracy: 0.7257 - val_loss: 0.6631 - val_accuracy: 0.6280\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.7921 - accuracy: 0.7303 - val_loss: 0.5627 - val_accuracy: 0.7533\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.5834 - accuracy: 0.7686 - val_loss: 0.6519 - val_accuracy: 0.6720\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.4843 - accuracy: 0.7891 - val_loss: 0.5135 - val_accuracy: 0.7613\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.4909 - accuracy: 0.8017 - val_loss: 1.3668 - val_accuracy: 0.7093\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.4452 - accuracy: 0.8091 - val_loss: 0.3909 - val_accuracy: 0.8227\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.4741 - accuracy: 0.8206 - val_loss: 0.8847 - val_accuracy: 0.7267\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.3964 - accuracy: 0.8240 - val_loss: 0.5507 - val_accuracy: 0.8053\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.3509 - accuracy: 0.8411 - val_loss: 0.4726 - val_accuracy: 0.8067\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 17s 154ms/step - loss: 0.3223 - accuracy: 0.8731 - val_loss: 0.4722 - val_accuracy: 0.8307\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.3124 - accuracy: 0.8726 - val_loss: 0.5215 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.3012 - accuracy: 0.8840 - val_loss: 0.4915 - val_accuracy: 0.8307\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.3152 - accuracy: 0.8777 - val_loss: 0.4125 - val_accuracy: 0.8280\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.2680 - accuracy: 0.9006 - val_loss: 0.2741 - val_accuracy: 0.8747\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.2581 - accuracy: 0.8994 - val_loss: 0.2998 - val_accuracy: 0.8773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.2526 - accuracy: 0.9103 - val_loss: 0.2845 - val_accuracy: 0.8840\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.2634 - accuracy: 0.9109 - val_loss: 0.2602 - val_accuracy: 0.8880\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2379 - accuracy: 0.9200 - val_loss: 0.3111 - val_accuracy: 0.8653\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2482 - accuracy: 0.9200 - val_loss: 0.2922 - val_accuracy: 0.8893\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 17s 154ms/step - loss: 0.2315 - accuracy: 0.9303 - val_loss: 0.3034 - val_accuracy: 0.8973\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.2164 - accuracy: 0.9360 - val_loss: 0.2056 - val_accuracy: 0.9187\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.2329 - accuracy: 0.9349 - val_loss: 0.3542 - val_accuracy: 0.8800\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2215 - accuracy: 0.9274 - val_loss: 0.2155 - val_accuracy: 0.9080\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.2367 - accuracy: 0.9274 - val_loss: 0.2685 - val_accuracy: 0.8880\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2338 - accuracy: 0.9280 - val_loss: 0.2742 - val_accuracy: 0.9067\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1797 - accuracy: 0.9463 - val_loss: 0.2563 - val_accuracy: 0.9067\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.2327 - accuracy: 0.9234 - val_loss: 0.5108 - val_accuracy: 0.7573\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2384 - accuracy: 0.9200 - val_loss: 0.4096 - val_accuracy: 0.8827\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2018 - accuracy: 0.9326 - val_loss: 0.3112 - val_accuracy: 0.8813\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 17s 153ms/step - loss: 0.2176 - accuracy: 0.9366 - val_loss: 0.4127 - val_accuracy: 0.8853\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.2397 - accuracy: 0.9263 - val_loss: 0.3166 - val_accuracy: 0.8733\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2092 - accuracy: 0.9223 - val_loss: 0.8617 - val_accuracy: 0.8693\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2442 - accuracy: 0.9143 - val_loss: 0.3473 - val_accuracy: 0.8760\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.2046 - accuracy: 0.9417 - val_loss: 0.1972 - val_accuracy: 0.9280\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1974 - accuracy: 0.9360 - val_loss: 0.2094 - val_accuracy: 0.9160\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2107 - accuracy: 0.9423 - val_loss: 0.2623 - val_accuracy: 0.9187\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.2341 - accuracy: 0.9337 - val_loss: 0.2281 - val_accuracy: 0.9213\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1938 - accuracy: 0.9383 - val_loss: 0.1896 - val_accuracy: 0.9293\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1742 - accuracy: 0.9469 - val_loss: 0.4260 - val_accuracy: 0.8987\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.1865 - accuracy: 0.9377 - val_loss: 0.1825 - val_accuracy: 0.9280\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1495 - accuracy: 0.9549 - val_loss: 0.2884 - val_accuracy: 0.9000\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1553 - accuracy: 0.9497 - val_loss: 0.2252 - val_accuracy: 0.9280\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1733 - accuracy: 0.9486 - val_loss: 0.1939 - val_accuracy: 0.9307\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1477 - accuracy: 0.9531 - val_loss: 0.2554 - val_accuracy: 0.9213\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1647 - accuracy: 0.9520 - val_loss: 0.2004 - val_accuracy: 0.9293\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1450 - accuracy: 0.9549 - val_loss: 0.2504 - val_accuracy: 0.9173\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1503 - accuracy: 0.9497 - val_loss: 0.2476 - val_accuracy: 0.9280\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1602 - accuracy: 0.9543 - val_loss: 0.1815 - val_accuracy: 0.9400\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1402 - accuracy: 0.9526 - val_loss: 0.2521 - val_accuracy: 0.9267\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 17s 153ms/step - loss: 0.1798 - accuracy: 0.9497 - val_loss: 0.3382 - val_accuracy: 0.9147\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2500 - accuracy: 0.9211 - val_loss: 0.3126 - val_accuracy: 0.9227\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2013 - accuracy: 0.9417 - val_loss: 0.2721 - val_accuracy: 0.8920\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1793 - accuracy: 0.9383 - val_loss: 0.1788 - val_accuracy: 0.9320\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1635 - accuracy: 0.9469 - val_loss: 0.2032 - val_accuracy: 0.9293\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.2136 - accuracy: 0.9354 - val_loss: 0.3440 - val_accuracy: 0.8587\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2176 - accuracy: 0.9286 - val_loss: 0.2695 - val_accuracy: 0.9000\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1961 - accuracy: 0.9440 - val_loss: 0.1881 - val_accuracy: 0.9280\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1786 - accuracy: 0.9429 - val_loss: 0.2106 - val_accuracy: 0.9267\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1734 - accuracy: 0.9440 - val_loss: 0.1820 - val_accuracy: 0.9333\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 17s 153ms/step - loss: 0.1656 - accuracy: 0.9429 - val_loss: 0.1872 - val_accuracy: 0.9240\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1663 - accuracy: 0.9480 - val_loss: 0.2110 - val_accuracy: 0.9267\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1694 - accuracy: 0.9469 - val_loss: 0.2594 - val_accuracy: 0.9213\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1507 - accuracy: 0.9526 - val_loss: 0.1992 - val_accuracy: 0.9333\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1527 - accuracy: 0.9577 - val_loss: 0.2312 - val_accuracy: 0.9240\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1962 - accuracy: 0.9417 - val_loss: 0.2162 - val_accuracy: 0.9213\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1766 - accuracy: 0.9474 - val_loss: 0.2067 - val_accuracy: 0.9267\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1550 - accuracy: 0.9543 - val_loss: 0.1748 - val_accuracy: 0.9413\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1727 - accuracy: 0.9509 - val_loss: 0.1858 - val_accuracy: 0.9307\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1593 - accuracy: 0.9577 - val_loss: 0.2038 - val_accuracy: 0.9360\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 17s 154ms/step - loss: 0.1345 - accuracy: 0.9583 - val_loss: 0.1863 - val_accuracy: 0.9440\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1586 - accuracy: 0.9463 - val_loss: 0.1864 - val_accuracy: 0.9253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1304 - accuracy: 0.9606 - val_loss: 0.2122 - val_accuracy: 0.9293\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1419 - accuracy: 0.9560 - val_loss: 0.1927 - val_accuracy: 0.9360\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1382 - accuracy: 0.9589 - val_loss: 0.3240 - val_accuracy: 0.9107\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1357 - accuracy: 0.9577 - val_loss: 0.1792 - val_accuracy: 0.9333\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1335 - accuracy: 0.9566 - val_loss: 0.1637 - val_accuracy: 0.9467\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1390 - accuracy: 0.9554 - val_loss: 0.1919 - val_accuracy: 0.9400\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1379 - accuracy: 0.9520 - val_loss: 0.2110 - val_accuracy: 0.9267\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1586 - accuracy: 0.9526 - val_loss: 0.1751 - val_accuracy: 0.9373\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.1434 - accuracy: 0.9571 - val_loss: 0.2000 - val_accuracy: 0.9267\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1403 - accuracy: 0.9571 - val_loss: 0.2222 - val_accuracy: 0.9320\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1343 - accuracy: 0.9549 - val_loss: 0.1966 - val_accuracy: 0.9373\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1308 - accuracy: 0.9629 - val_loss: 0.1736 - val_accuracy: 0.9427\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1289 - accuracy: 0.9594 - val_loss: 0.1814 - val_accuracy: 0.9427\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1262 - accuracy: 0.9594 - val_loss: 0.1878 - val_accuracy: 0.9373\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1277 - accuracy: 0.9589 - val_loss: 0.2057 - val_accuracy: 0.9307\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1178 - accuracy: 0.9600 - val_loss: 0.1908 - val_accuracy: 0.9360\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1154 - accuracy: 0.9634 - val_loss: 0.1707 - val_accuracy: 0.9453\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1508 - accuracy: 0.9583 - val_loss: 0.2827 - val_accuracy: 0.9040\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 17s 153ms/step - loss: 0.1692 - accuracy: 0.9560 - val_loss: 0.1994 - val_accuracy: 0.9427\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1291 - accuracy: 0.9623 - val_loss: 0.2288 - val_accuracy: 0.9347\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1565 - accuracy: 0.9531 - val_loss: 0.1770 - val_accuracy: 0.9467\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1317 - accuracy: 0.9594 - val_loss: 0.1963 - val_accuracy: 0.9427\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1349 - accuracy: 0.9577 - val_loss: 0.1795 - val_accuracy: 0.9440\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.1256 - accuracy: 0.9617 - val_loss: 0.1859 - val_accuracy: 0.9493\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1238 - accuracy: 0.9623 - val_loss: 0.2089 - val_accuracy: 0.9280\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.1210 - accuracy: 0.9617 - val_loss: 0.1637 - val_accuracy: 0.9493\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1220 - accuracy: 0.9589 - val_loss: 0.1855 - val_accuracy: 0.9360\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1082 - accuracy: 0.9657 - val_loss: 0.1729 - val_accuracy: 0.9373\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 17s 154ms/step - loss: 0.1246 - accuracy: 0.9611 - val_loss: 0.2237 - val_accuracy: 0.9067\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1290 - accuracy: 0.9594 - val_loss: 0.1513 - val_accuracy: 0.9440\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1217 - accuracy: 0.9583 - val_loss: 0.1436 - val_accuracy: 0.9547\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1479 - accuracy: 0.9640 - val_loss: 0.1536 - val_accuracy: 0.9467\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1149 - accuracy: 0.9651 - val_loss: 0.1801 - val_accuracy: 0.9413\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.1202 - accuracy: 0.9657 - val_loss: 0.1554 - val_accuracy: 0.9493\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1054 - accuracy: 0.9703 - val_loss: 0.1373 - val_accuracy: 0.9573\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1231 - accuracy: 0.9589 - val_loss: 0.1728 - val_accuracy: 0.9467\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1190 - accuracy: 0.9669 - val_loss: 0.3904 - val_accuracy: 0.8920\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1751 - accuracy: 0.9509 - val_loss: 0.1445 - val_accuracy: 0.9467\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.1354 - accuracy: 0.9623 - val_loss: 0.1553 - val_accuracy: 0.9453\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1131 - accuracy: 0.9634 - val_loss: 0.1868 - val_accuracy: 0.9347\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1116 - accuracy: 0.9651 - val_loss: 0.1808 - val_accuracy: 0.9480\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1132 - accuracy: 0.9623 - val_loss: 0.1639 - val_accuracy: 0.9467\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1253 - accuracy: 0.9589 - val_loss: 0.1582 - val_accuracy: 0.9480\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1375 - accuracy: 0.9560 - val_loss: 0.1595 - val_accuracy: 0.9467\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1263 - accuracy: 0.9617 - val_loss: 0.2501 - val_accuracy: 0.9333\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.1283 - accuracy: 0.9669 - val_loss: 0.1556 - val_accuracy: 0.9467\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1402 - accuracy: 0.9566 - val_loss: 0.1585 - val_accuracy: 0.9493\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.1392 - accuracy: 0.9537 - val_loss: 0.2633 - val_accuracy: 0.9240\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 17s 155ms/step - loss: 0.1089 - accuracy: 0.9651 - val_loss: 0.1961 - val_accuracy: 0.9400\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.1110 - accuracy: 0.9634 - val_loss: 0.1831 - val_accuracy: 0.9373\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1088 - accuracy: 0.9680 - val_loss: 0.1703 - val_accuracy: 0.9360\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1288 - accuracy: 0.9703 - val_loss: 0.1508 - val_accuracy: 0.9507\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1192 - accuracy: 0.9629 - val_loss: 0.1711 - val_accuracy: 0.9387\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.1554 - accuracy: 0.9491 - val_loss: 0.2402 - val_accuracy: 0.9173\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1290 - accuracy: 0.9589 - val_loss: 0.1776 - val_accuracy: 0.9333\n",
      "Epoch 128/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1199 - accuracy: 0.9623 - val_loss: 0.1853 - val_accuracy: 0.9360\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1355 - accuracy: 0.9617 - val_loss: 0.1777 - val_accuracy: 0.9400\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1231 - accuracy: 0.9589 - val_loss: 0.1745 - val_accuracy: 0.9440\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 17s 154ms/step - loss: 0.1084 - accuracy: 0.9646 - val_loss: 0.1746 - val_accuracy: 0.9400\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1153 - accuracy: 0.9629 - val_loss: 0.1580 - val_accuracy: 0.9373\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.1197 - accuracy: 0.9691 - val_loss: 0.1709 - val_accuracy: 0.9400\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.0971 - accuracy: 0.9703 - val_loss: 0.1787 - val_accuracy: 0.9453\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1114 - accuracy: 0.9697 - val_loss: 0.1537 - val_accuracy: 0.9547\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1086 - accuracy: 0.9680 - val_loss: 0.1654 - val_accuracy: 0.9453\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.0934 - accuracy: 0.9737 - val_loss: 0.1912 - val_accuracy: 0.9427\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1006 - accuracy: 0.9720 - val_loss: 0.1750 - val_accuracy: 0.9427\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1065 - accuracy: 0.9657 - val_loss: 0.1714 - val_accuracy: 0.9413\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.0965 - accuracy: 0.9714 - val_loss: 0.1791 - val_accuracy: 0.9453\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 17s 154ms/step - loss: 0.1067 - accuracy: 0.9697 - val_loss: 0.1598 - val_accuracy: 0.9480\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0958 - accuracy: 0.9714 - val_loss: 0.1517 - val_accuracy: 0.9467\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1110 - accuracy: 0.9691 - val_loss: 0.1736 - val_accuracy: 0.9400\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0989 - accuracy: 0.9674 - val_loss: 0.1538 - val_accuracy: 0.9493\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0958 - accuracy: 0.9720 - val_loss: 0.1850 - val_accuracy: 0.9427\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1050 - accuracy: 0.9714 - val_loss: 0.1991 - val_accuracy: 0.9400\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1007 - accuracy: 0.9691 - val_loss: 0.2004 - val_accuracy: 0.9400\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0932 - accuracy: 0.9731 - val_loss: 0.1663 - val_accuracy: 0.9507\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0918 - accuracy: 0.9714 - val_loss: 0.1673 - val_accuracy: 0.9547\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0880 - accuracy: 0.9691 - val_loss: 0.1738 - val_accuracy: 0.9467\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 17s 153ms/step - loss: 0.0936 - accuracy: 0.9714 - val_loss: 0.1769 - val_accuracy: 0.9467\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0774 - accuracy: 0.9754 - val_loss: 0.2072 - val_accuracy: 0.9427\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0963 - accuracy: 0.9703 - val_loss: 0.1665 - val_accuracy: 0.9493\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0877 - accuracy: 0.9720 - val_loss: 0.1779 - val_accuracy: 0.9373\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0984 - accuracy: 0.9691 - val_loss: 0.2216 - val_accuracy: 0.9333\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0862 - accuracy: 0.9714 - val_loss: 0.1395 - val_accuracy: 0.9520\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1054 - accuracy: 0.9720 - val_loss: 0.1771 - val_accuracy: 0.9480\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0850 - accuracy: 0.9731 - val_loss: 0.1364 - val_accuracy: 0.9493\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1050 - accuracy: 0.9731 - val_loss: 0.1704 - val_accuracy: 0.9427\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0849 - accuracy: 0.9766 - val_loss: 0.1437 - val_accuracy: 0.9573\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 17s 154ms/step - loss: 0.1083 - accuracy: 0.9657 - val_loss: 0.1785 - val_accuracy: 0.9467\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0939 - accuracy: 0.9686 - val_loss: 0.1489 - val_accuracy: 0.9573\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0941 - accuracy: 0.9697 - val_loss: 0.1769 - val_accuracy: 0.9440\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0938 - accuracy: 0.9726 - val_loss: 0.1556 - val_accuracy: 0.9547\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0891 - accuracy: 0.9743 - val_loss: 0.1761 - val_accuracy: 0.9507\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1024 - accuracy: 0.9669 - val_loss: 0.1720 - val_accuracy: 0.9453\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0789 - accuracy: 0.9754 - val_loss: 0.1941 - val_accuracy: 0.9400\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0827 - accuracy: 0.9709 - val_loss: 0.2908 - val_accuracy: 0.9280\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0799 - accuracy: 0.9789 - val_loss: 0.1342 - val_accuracy: 0.9573\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0930 - accuracy: 0.9709 - val_loss: 0.1417 - val_accuracy: 0.9507\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.0852 - accuracy: 0.9760 - val_loss: 0.1411 - val_accuracy: 0.9560\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0861 - accuracy: 0.9731 - val_loss: 0.1514 - val_accuracy: 0.9520\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0900 - accuracy: 0.9720 - val_loss: 0.1627 - val_accuracy: 0.9467\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1028 - accuracy: 0.9703 - val_loss: 0.1288 - val_accuracy: 0.9547\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1089 - accuracy: 0.9697 - val_loss: 0.2246 - val_accuracy: 0.9307\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0967 - accuracy: 0.9680 - val_loss: 0.1352 - val_accuracy: 0.9587\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1078 - accuracy: 0.9703 - val_loss: 0.1778 - val_accuracy: 0.9360\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.0825 - accuracy: 0.9760 - val_loss: 0.1427 - val_accuracy: 0.9533\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0809 - accuracy: 0.9749 - val_loss: 0.1539 - val_accuracy: 0.9507\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0989 - accuracy: 0.9714 - val_loss: 0.3136 - val_accuracy: 0.9093\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.1001 - accuracy: 0.9720 - val_loss: 0.1456 - val_accuracy: 0.9573\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1167 - accuracy: 0.9703 - val_loss: 0.1715 - val_accuracy: 0.9400\n",
      "Epoch 183/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0969 - accuracy: 0.9686 - val_loss: 0.1310 - val_accuracy: 0.9587\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0866 - accuracy: 0.9760 - val_loss: 0.2084 - val_accuracy: 0.9373\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.0892 - accuracy: 0.9737 - val_loss: 0.1614 - val_accuracy: 0.9587\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0827 - accuracy: 0.9726 - val_loss: 0.1234 - val_accuracy: 0.9600\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0809 - accuracy: 0.9743 - val_loss: 0.1459 - val_accuracy: 0.9480\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0785 - accuracy: 0.9749 - val_loss: 0.1471 - val_accuracy: 0.9587\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0913 - accuracy: 0.9737 - val_loss: 0.1297 - val_accuracy: 0.9547\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0862 - accuracy: 0.9731 - val_loss: 0.1719 - val_accuracy: 0.9507\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.0810 - accuracy: 0.9749 - val_loss: 0.1497 - val_accuracy: 0.9493\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0927 - accuracy: 0.9709 - val_loss: 0.1713 - val_accuracy: 0.9453\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.0806 - accuracy: 0.9771 - val_loss: 0.1821 - val_accuracy: 0.9373\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0728 - accuracy: 0.9800 - val_loss: 0.1920 - val_accuracy: 0.9387\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0809 - accuracy: 0.9726 - val_loss: 0.1349 - val_accuracy: 0.9613\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0647 - accuracy: 0.9794 - val_loss: 0.2181 - val_accuracy: 0.9347\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.0788 - accuracy: 0.9743 - val_loss: 0.1210 - val_accuracy: 0.9613\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1002 - accuracy: 0.9737 - val_loss: 0.2209 - val_accuracy: 0.9173\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0875 - accuracy: 0.9754 - val_loss: 0.1827 - val_accuracy: 0.9413\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1134 - accuracy: 0.9749 - val_loss: 0.1278 - val_accuracy: 0.9600\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 1)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 50s - loss: 1.3234 - accuracy: 0.4688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0968s vs `on_train_batch_end` time: 0.7967s). Check your callbacks.\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.9655 - accuracy: 0.6600 - val_loss: 0.6666 - val_accuracy: 0.6280\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.6733 - accuracy: 0.7114 - val_loss: 0.8253 - val_accuracy: 0.3720\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.6983 - accuracy: 0.7429 - val_loss: 0.7900 - val_accuracy: 0.4827\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.6312 - accuracy: 0.7594 - val_loss: 0.4961 - val_accuracy: 0.8213\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.6673 - accuracy: 0.7480 - val_loss: 0.5876 - val_accuracy: 0.7013\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.5687 - accuracy: 0.7720 - val_loss: 0.4001 - val_accuracy: 0.8467\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.5152 - accuracy: 0.7823 - val_loss: 0.4428 - val_accuracy: 0.7720\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.6005 - accuracy: 0.7509 - val_loss: 0.5474 - val_accuracy: 0.7200\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.5086 - accuracy: 0.7737 - val_loss: 0.4011 - val_accuracy: 0.8267\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.5745 - accuracy: 0.7714 - val_loss: 0.4039 - val_accuracy: 0.8093\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 17s 153ms/step - loss: 0.6082 - accuracy: 0.7766 - val_loss: 0.4469 - val_accuracy: 0.7760\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.5717 - accuracy: 0.7543 - val_loss: 0.4542 - val_accuracy: 0.7880\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.4942 - accuracy: 0.7937 - val_loss: 0.3896 - val_accuracy: 0.8093\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.5084 - accuracy: 0.7931 - val_loss: 0.4563 - val_accuracy: 0.7813\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.5040 - accuracy: 0.7926 - val_loss: 0.5163 - val_accuracy: 0.7653\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.4969 - accuracy: 0.7989 - val_loss: 0.6243 - val_accuracy: 0.7573\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.5018 - accuracy: 0.7926 - val_loss: 0.4467 - val_accuracy: 0.8187\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.4776 - accuracy: 0.8051 - val_loss: 0.5506 - val_accuracy: 0.7613\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.4209 - accuracy: 0.8251 - val_loss: 0.3037 - val_accuracy: 0.8640\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.4758 - accuracy: 0.7943 - val_loss: 0.2994 - val_accuracy: 0.8867\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.5012 - accuracy: 0.8051 - val_loss: 0.3628 - val_accuracy: 0.8267\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.4207 - accuracy: 0.8200 - val_loss: 0.4031 - val_accuracy: 0.8307\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.4370 - accuracy: 0.8297 - val_loss: 0.3613 - val_accuracy: 0.8467\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.3940 - accuracy: 0.8286 - val_loss: 0.4549 - val_accuracy: 0.8173\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.4329 - accuracy: 0.8251 - val_loss: 0.2845 - val_accuracy: 0.8867\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.3851 - accuracy: 0.8526 - val_loss: 0.5223 - val_accuracy: 0.7987\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.3746 - accuracy: 0.8423 - val_loss: 0.3001 - val_accuracy: 0.9013\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.4230 - accuracy: 0.8303 - val_loss: 0.3703 - val_accuracy: 0.8707\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.3827 - accuracy: 0.8554 - val_loss: 0.3332 - val_accuracy: 0.8600\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.3701 - accuracy: 0.8343 - val_loss: 0.3663 - val_accuracy: 0.8467\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 17s 153ms/step - loss: 0.4231 - accuracy: 0.8480 - val_loss: 2.9833 - val_accuracy: 0.8200\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.3571 - accuracy: 0.8531 - val_loss: 0.3531 - val_accuracy: 0.8893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.3961 - accuracy: 0.8543 - val_loss: 0.3019 - val_accuracy: 0.8867\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.3305 - accuracy: 0.8651 - val_loss: 0.5618 - val_accuracy: 0.8267\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.3803 - accuracy: 0.8617 - val_loss: 0.2861 - val_accuracy: 0.9067\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.3139 - accuracy: 0.8760 - val_loss: 0.3097 - val_accuracy: 0.8480\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.3485 - accuracy: 0.8743 - val_loss: 0.4091 - val_accuracy: 0.8427\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 16s 146ms/step - loss: 0.3406 - accuracy: 0.8594 - val_loss: 0.5420 - val_accuracy: 0.8187\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.3178 - accuracy: 0.8749 - val_loss: 0.3157 - val_accuracy: 0.8613\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.3156 - accuracy: 0.8754 - val_loss: 0.3798 - val_accuracy: 0.8453\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 17s 153ms/step - loss: 0.3597 - accuracy: 0.8691 - val_loss: 0.5343 - val_accuracy: 0.8387\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.3484 - accuracy: 0.8760 - val_loss: 0.4143 - val_accuracy: 0.8493\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.3074 - accuracy: 0.8737 - val_loss: 0.3137 - val_accuracy: 0.8653\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.3428 - accuracy: 0.8669 - val_loss: 0.3392 - val_accuracy: 0.8573\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.3019 - accuracy: 0.8851 - val_loss: 0.3477 - val_accuracy: 0.8653\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.3325 - accuracy: 0.8720 - val_loss: 0.2338 - val_accuracy: 0.9040\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.3822 - accuracy: 0.8709 - val_loss: 0.2666 - val_accuracy: 0.8840\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2968 - accuracy: 0.8863 - val_loss: 0.4449 - val_accuracy: 0.8547\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2984 - accuracy: 0.8989 - val_loss: 0.3322 - val_accuracy: 0.8547\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.3097 - accuracy: 0.8840 - val_loss: 0.4499 - val_accuracy: 0.8307\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.2729 - accuracy: 0.8931 - val_loss: 0.7309 - val_accuracy: 0.8347\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.3622 - accuracy: 0.8777 - val_loss: 0.4019 - val_accuracy: 0.8653\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.3050 - accuracy: 0.8789 - val_loss: 0.4560 - val_accuracy: 0.8627\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.3014 - accuracy: 0.8874 - val_loss: 0.4547 - val_accuracy: 0.8520\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2893 - accuracy: 0.8897 - val_loss: 0.3099 - val_accuracy: 0.8787\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2627 - accuracy: 0.9023 - val_loss: 0.3515 - val_accuracy: 0.8680\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2896 - accuracy: 0.8960 - val_loss: 0.3239 - val_accuracy: 0.8680\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2510 - accuracy: 0.9120 - val_loss: 0.4713 - val_accuracy: 0.8600\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2563 - accuracy: 0.8926 - val_loss: 0.2885 - val_accuracy: 0.8773\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2513 - accuracy: 0.9051 - val_loss: 0.3126 - val_accuracy: 0.8560\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.2527 - accuracy: 0.9029 - val_loss: 0.2962 - val_accuracy: 0.8707\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2680 - accuracy: 0.8914 - val_loss: 0.5531 - val_accuracy: 0.8560\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2619 - accuracy: 0.8943 - val_loss: 0.3009 - val_accuracy: 0.8680\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2592 - accuracy: 0.8994 - val_loss: 0.3397 - val_accuracy: 0.8667\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2643 - accuracy: 0.8943 - val_loss: 0.5791 - val_accuracy: 0.8453\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2763 - accuracy: 0.9057 - val_loss: 0.3481 - val_accuracy: 0.8560\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2896 - accuracy: 0.9097 - val_loss: 0.3214 - val_accuracy: 0.8667\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2470 - accuracy: 0.9120 - val_loss: 0.3037 - val_accuracy: 0.8787\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2253 - accuracy: 0.9183 - val_loss: 0.3049 - val_accuracy: 0.8773\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2116 - accuracy: 0.9229 - val_loss: 0.3286 - val_accuracy: 0.8760\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.2407 - accuracy: 0.9091 - val_loss: 0.3897 - val_accuracy: 0.8760\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2208 - accuracy: 0.9183 - val_loss: 0.2613 - val_accuracy: 0.8853\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2076 - accuracy: 0.9217 - val_loss: 0.2809 - val_accuracy: 0.8773\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2109 - accuracy: 0.9217 - val_loss: 0.4008 - val_accuracy: 0.8693\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2134 - accuracy: 0.9206 - val_loss: 0.3361 - val_accuracy: 0.8787\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2042 - accuracy: 0.9211 - val_loss: 0.3585 - val_accuracy: 0.8773\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2612 - accuracy: 0.9274 - val_loss: 0.3334 - val_accuracy: 0.8787\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2067 - accuracy: 0.9211 - val_loss: 0.3499 - val_accuracy: 0.8747\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2259 - accuracy: 0.9217 - val_loss: 0.3028 - val_accuracy: 0.8840\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2083 - accuracy: 0.9211 - val_loss: 0.2794 - val_accuracy: 0.8840\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.2813 - accuracy: 0.9280 - val_loss: 0.3418 - val_accuracy: 0.8800\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1988 - accuracy: 0.9291 - val_loss: 0.2795 - val_accuracy: 0.8987\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2503 - accuracy: 0.9280 - val_loss: 0.2820 - val_accuracy: 0.8947\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2032 - accuracy: 0.9223 - val_loss: 0.3841 - val_accuracy: 0.8893\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1943 - accuracy: 0.9320 - val_loss: 0.3092 - val_accuracy: 0.8813\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2251 - accuracy: 0.9326 - val_loss: 0.2677 - val_accuracy: 0.9040\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2124 - accuracy: 0.9269 - val_loss: 0.3643 - val_accuracy: 0.8893\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.2355 - accuracy: 0.9280 - val_loss: 0.2922 - val_accuracy: 0.8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2525 - accuracy: 0.9257 - val_loss: 0.2975 - val_accuracy: 0.8933\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2012 - accuracy: 0.9240 - val_loss: 0.3146 - val_accuracy: 0.8893\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1964 - accuracy: 0.9354 - val_loss: 0.3397 - val_accuracy: 0.9000\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.2051 - accuracy: 0.9320 - val_loss: 0.3328 - val_accuracy: 0.8947\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1882 - accuracy: 0.9366 - val_loss: 0.3144 - val_accuracy: 0.8973\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1722 - accuracy: 0.9400 - val_loss: 0.3417 - val_accuracy: 0.8960\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1902 - accuracy: 0.9337 - val_loss: 0.2825 - val_accuracy: 0.8933\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1916 - accuracy: 0.9349 - val_loss: 0.2472 - val_accuracy: 0.9040\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2078 - accuracy: 0.9337 - val_loss: 0.3296 - val_accuracy: 0.8893\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1746 - accuracy: 0.9417 - val_loss: 0.3257 - val_accuracy: 0.9013\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1826 - accuracy: 0.9389 - val_loss: 0.2398 - val_accuracy: 0.9067\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1844 - accuracy: 0.9354 - val_loss: 0.2697 - val_accuracy: 0.8947\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1743 - accuracy: 0.9406 - val_loss: 0.2076 - val_accuracy: 0.9093\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1621 - accuracy: 0.9423 - val_loss: 0.4420 - val_accuracy: 0.8787\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1601 - accuracy: 0.9417 - val_loss: 0.3110 - val_accuracy: 0.8960\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1559 - accuracy: 0.9469 - val_loss: 0.2242 - val_accuracy: 0.9173\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1633 - accuracy: 0.9469 - val_loss: 0.2087 - val_accuracy: 0.9227\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1765 - accuracy: 0.9469 - val_loss: 0.2601 - val_accuracy: 0.8973\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1606 - accuracy: 0.9457 - val_loss: 0.2513 - val_accuracy: 0.9053\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1704 - accuracy: 0.9469 - val_loss: 0.3125 - val_accuracy: 0.9093\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1590 - accuracy: 0.9474 - val_loss: 0.2734 - val_accuracy: 0.9093\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1690 - accuracy: 0.9451 - val_loss: 0.2940 - val_accuracy: 0.9040\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1796 - accuracy: 0.9394 - val_loss: 0.2201 - val_accuracy: 0.9200\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1586 - accuracy: 0.9446 - val_loss: 0.2360 - val_accuracy: 0.9027\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1739 - accuracy: 0.9451 - val_loss: 0.2514 - val_accuracy: 0.9120\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1576 - accuracy: 0.9463 - val_loss: 0.2710 - val_accuracy: 0.9147\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1680 - accuracy: 0.9446 - val_loss: 0.2822 - val_accuracy: 0.9040\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1774 - accuracy: 0.9440 - val_loss: 0.2676 - val_accuracy: 0.9080\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1591 - accuracy: 0.9474 - val_loss: 0.2555 - val_accuracy: 0.8973\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1531 - accuracy: 0.9509 - val_loss: 0.2295 - val_accuracy: 0.9200\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1626 - accuracy: 0.9457 - val_loss: 0.2468 - val_accuracy: 0.9120\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1578 - accuracy: 0.9457 - val_loss: 0.2266 - val_accuracy: 0.9187\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.1525 - accuracy: 0.9486 - val_loss: 0.2979 - val_accuracy: 0.9080\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1447 - accuracy: 0.9531 - val_loss: 0.2037 - val_accuracy: 0.9187\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1547 - accuracy: 0.9520 - val_loss: 0.2535 - val_accuracy: 0.9147\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1493 - accuracy: 0.9509 - val_loss: 0.1898 - val_accuracy: 0.9373\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1356 - accuracy: 0.9560 - val_loss: 0.2395 - val_accuracy: 0.9213\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1493 - accuracy: 0.9554 - val_loss: 0.2772 - val_accuracy: 0.9133\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1461 - accuracy: 0.9520 - val_loss: 0.3500 - val_accuracy: 0.8853\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 16s 150ms/step - loss: 0.1510 - accuracy: 0.9503 - val_loss: 0.2090 - val_accuracy: 0.9253\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1654 - accuracy: 0.9543 - val_loss: 0.2164 - val_accuracy: 0.9267\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1642 - accuracy: 0.9491 - val_loss: 0.2327 - val_accuracy: 0.9200\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 17s 153ms/step - loss: 0.1453 - accuracy: 0.9531 - val_loss: 0.1953 - val_accuracy: 0.9280\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1354 - accuracy: 0.9543 - val_loss: 0.2360 - val_accuracy: 0.9200\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1431 - accuracy: 0.9554 - val_loss: 0.2042 - val_accuracy: 0.9347\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1609 - accuracy: 0.9463 - val_loss: 0.2420 - val_accuracy: 0.9240\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1341 - accuracy: 0.9571 - val_loss: 0.2457 - val_accuracy: 0.9200\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1477 - accuracy: 0.9514 - val_loss: 0.2411 - val_accuracy: 0.9307\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1500 - accuracy: 0.9509 - val_loss: 0.2133 - val_accuracy: 0.9320\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1541 - accuracy: 0.9531 - val_loss: 0.2251 - val_accuracy: 0.9293\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1314 - accuracy: 0.9571 - val_loss: 0.3741 - val_accuracy: 0.8760\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1260 - accuracy: 0.9549 - val_loss: 0.2041 - val_accuracy: 0.9333\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1323 - accuracy: 0.9600 - val_loss: 0.2227 - val_accuracy: 0.9427\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1359 - accuracy: 0.9566 - val_loss: 0.2281 - val_accuracy: 0.9253\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1121 - accuracy: 0.9611 - val_loss: 0.3090 - val_accuracy: 0.9080\n",
      "Epoch 144/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1351 - accuracy: 0.9571 - val_loss: 0.2281 - val_accuracy: 0.9227\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1292 - accuracy: 0.9583 - val_loss: 0.1531 - val_accuracy: 0.9547\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1201 - accuracy: 0.9571 - val_loss: 0.2275 - val_accuracy: 0.9320\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1379 - accuracy: 0.9600 - val_loss: 0.1937 - val_accuracy: 0.9427\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1259 - accuracy: 0.9549 - val_loss: 0.2601 - val_accuracy: 0.9227\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1182 - accuracy: 0.9657 - val_loss: 0.2024 - val_accuracy: 0.9373\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1232 - accuracy: 0.9640 - val_loss: 0.2701 - val_accuracy: 0.9253\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1185 - accuracy: 0.9589 - val_loss: 0.1834 - val_accuracy: 0.9453\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1053 - accuracy: 0.9617 - val_loss: 0.1940 - val_accuracy: 0.9507\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1170 - accuracy: 0.9634 - val_loss: 0.1717 - val_accuracy: 0.9493\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1242 - accuracy: 0.9617 - val_loss: 0.2040 - val_accuracy: 0.9387\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1249 - accuracy: 0.9611 - val_loss: 0.2622 - val_accuracy: 0.9280\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1274 - accuracy: 0.9577 - val_loss: 0.1838 - val_accuracy: 0.9520\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1096 - accuracy: 0.9657 - val_loss: 0.2237 - val_accuracy: 0.9413\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1189 - accuracy: 0.9617 - val_loss: 0.1908 - val_accuracy: 0.9427\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1150 - accuracy: 0.9646 - val_loss: 0.1995 - val_accuracy: 0.9373\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1267 - accuracy: 0.9611 - val_loss: 0.2672 - val_accuracy: 0.9267\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 17s 151ms/step - loss: 0.1117 - accuracy: 0.9629 - val_loss: 0.2198 - val_accuracy: 0.9360\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1093 - accuracy: 0.9680 - val_loss: 0.1803 - val_accuracy: 0.9467\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1175 - accuracy: 0.9634 - val_loss: 0.1879 - val_accuracy: 0.9493\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1291 - accuracy: 0.9577 - val_loss: 0.1650 - val_accuracy: 0.9507\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1164 - accuracy: 0.9646 - val_loss: 0.1860 - val_accuracy: 0.9360\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1135 - accuracy: 0.9640 - val_loss: 0.2139 - val_accuracy: 0.9387\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1151 - accuracy: 0.9606 - val_loss: 0.1870 - val_accuracy: 0.9427\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.2014 - accuracy: 0.9491 - val_loss: 0.2816 - val_accuracy: 0.9040\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1315 - accuracy: 0.9606 - val_loss: 0.1805 - val_accuracy: 0.9387\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1191 - accuracy: 0.9600 - val_loss: 0.2341 - val_accuracy: 0.9213\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 17s 152ms/step - loss: 0.1142 - accuracy: 0.9663 - val_loss: 0.1728 - val_accuracy: 0.9453\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1157 - accuracy: 0.9611 - val_loss: 0.1915 - val_accuracy: 0.9467\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1150 - accuracy: 0.9634 - val_loss: 0.1948 - val_accuracy: 0.9387\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1219 - accuracy: 0.9583 - val_loss: 0.1564 - val_accuracy: 0.9467\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1109 - accuracy: 0.9611 - val_loss: 0.2164 - val_accuracy: 0.9387\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1191 - accuracy: 0.9674 - val_loss: 0.1922 - val_accuracy: 0.9493\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1441 - accuracy: 0.9617 - val_loss: 0.3191 - val_accuracy: 0.8947\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1351 - accuracy: 0.9606 - val_loss: 0.2092 - val_accuracy: 0.9387\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1026 - accuracy: 0.9663 - val_loss: 0.2346 - val_accuracy: 0.9320\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1082 - accuracy: 0.9714 - val_loss: 0.2112 - val_accuracy: 0.9387\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 17s 153ms/step - loss: 0.1074 - accuracy: 0.9657 - val_loss: 0.2260 - val_accuracy: 0.9360\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1024 - accuracy: 0.9640 - val_loss: 0.1434 - val_accuracy: 0.9507\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1126 - accuracy: 0.9669 - val_loss: 0.1732 - val_accuracy: 0.9440\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1510 - accuracy: 0.9669 - val_loss: 0.1809 - val_accuracy: 0.9387\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0989 - accuracy: 0.9686 - val_loss: 0.1987 - val_accuracy: 0.9427\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.1196 - accuracy: 0.9646 - val_loss: 0.1390 - val_accuracy: 0.9493\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0995 - accuracy: 0.9686 - val_loss: 0.2122 - val_accuracy: 0.9400\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1004 - accuracy: 0.9703 - val_loss: 0.1652 - val_accuracy: 0.9427\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1002 - accuracy: 0.9663 - val_loss: 0.1878 - val_accuracy: 0.9493\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1133 - accuracy: 0.9686 - val_loss: 0.1518 - val_accuracy: 0.9547\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 17s 153ms/step - loss: 0.1098 - accuracy: 0.9663 - val_loss: 0.1801 - val_accuracy: 0.9360\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 17s 150ms/step - loss: 0.1025 - accuracy: 0.9651 - val_loss: 0.1647 - val_accuracy: 0.9480\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1102 - accuracy: 0.9680 - val_loss: 0.1577 - val_accuracy: 0.9493\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.0965 - accuracy: 0.9680 - val_loss: 0.2367 - val_accuracy: 0.9160\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1080 - accuracy: 0.9669 - val_loss: 0.1465 - val_accuracy: 0.9587\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.1077 - accuracy: 0.9646 - val_loss: 0.1648 - val_accuracy: 0.9467\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0985 - accuracy: 0.9691 - val_loss: 0.1395 - val_accuracy: 0.9480\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0969 - accuracy: 0.9703 - val_loss: 0.1825 - val_accuracy: 0.9427\n",
      "Epoch 199/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 16s 148ms/step - loss: 0.0771 - accuracy: 0.9754 - val_loss: 0.1881 - val_accuracy: 0.9480\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 16s 149ms/step - loss: 0.1137 - accuracy: 0.9640 - val_loss: 0.2147 - val_accuracy: 0.9347\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 4)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 51s - loss: 11.1457 - accuracy: 0.5000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0859s vs `on_train_batch_end` time: 0.8034s). Check your callbacks.\n",
      "110/110 [==============================] - 20s 179ms/step - loss: 1.5557 - accuracy: 0.7463 - val_loss: 0.8064 - val_accuracy: 0.3720\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.5628 - accuracy: 0.8154 - val_loss: 1.0670 - val_accuracy: 0.3707\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.4264 - accuracy: 0.8526 - val_loss: 0.6232 - val_accuracy: 0.6773\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.3797 - accuracy: 0.8526 - val_loss: 9.9558 - val_accuracy: 0.5747\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.3931 - accuracy: 0.8749 - val_loss: 1.5489 - val_accuracy: 0.6733\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.4562 - accuracy: 0.8663 - val_loss: 2.4897 - val_accuracy: 0.8600\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.3252 - accuracy: 0.8886 - val_loss: 0.4230 - val_accuracy: 0.8440\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2284 - accuracy: 0.9206 - val_loss: 0.4861 - val_accuracy: 0.8013\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2538 - accuracy: 0.9217 - val_loss: 0.3633 - val_accuracy: 0.8707\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2705 - accuracy: 0.9223 - val_loss: 0.4912 - val_accuracy: 0.8347\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2885 - accuracy: 0.9223 - val_loss: 0.3349 - val_accuracy: 0.8640\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2456 - accuracy: 0.9371 - val_loss: 0.5777 - val_accuracy: 0.7827\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1965 - accuracy: 0.9371 - val_loss: 0.8276 - val_accuracy: 0.8120\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.2694 - accuracy: 0.9251 - val_loss: 0.3590 - val_accuracy: 0.8520\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2419 - accuracy: 0.9251 - val_loss: 1.0731 - val_accuracy: 0.8480\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.2149 - accuracy: 0.9314 - val_loss: 0.2983 - val_accuracy: 0.8840\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2097 - accuracy: 0.9354 - val_loss: 0.6182 - val_accuracy: 0.7760\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2195 - accuracy: 0.9349 - val_loss: 0.4636 - val_accuracy: 0.8133\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.2751 - accuracy: 0.9274 - val_loss: 0.5324 - val_accuracy: 0.8693\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2369 - accuracy: 0.9326 - val_loss: 0.3757 - val_accuracy: 0.8507\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2389 - accuracy: 0.9286 - val_loss: 0.4495 - val_accuracy: 0.8280\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2078 - accuracy: 0.9389 - val_loss: 0.4798 - val_accuracy: 0.8053\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.2145 - accuracy: 0.9343 - val_loss: 0.4039 - val_accuracy: 0.8333\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2055 - accuracy: 0.9349 - val_loss: 0.3420 - val_accuracy: 0.8587\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1777 - accuracy: 0.9446 - val_loss: 0.4863 - val_accuracy: 0.8387\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1707 - accuracy: 0.9526 - val_loss: 0.3171 - val_accuracy: 0.8787\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1788 - accuracy: 0.9469 - val_loss: 0.3194 - val_accuracy: 0.8840\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.2360 - accuracy: 0.9417 - val_loss: 0.3197 - val_accuracy: 0.8907\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2141 - accuracy: 0.9331 - val_loss: 0.2618 - val_accuracy: 0.8960\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1927 - accuracy: 0.9497 - val_loss: 0.2760 - val_accuracy: 0.8840\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1816 - accuracy: 0.9440 - val_loss: 0.3876 - val_accuracy: 0.8200\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1695 - accuracy: 0.9537 - val_loss: 0.3146 - val_accuracy: 0.8547\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1854 - accuracy: 0.9486 - val_loss: 0.7372 - val_accuracy: 0.7640\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1789 - accuracy: 0.9440 - val_loss: 0.3701 - val_accuracy: 0.8453\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1684 - accuracy: 0.9537 - val_loss: 0.2665 - val_accuracy: 0.8947\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.2053 - accuracy: 0.9509 - val_loss: 0.3946 - val_accuracy: 0.8453\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1626 - accuracy: 0.9503 - val_loss: 0.3271 - val_accuracy: 0.8493\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1970 - accuracy: 0.9469 - val_loss: 0.2309 - val_accuracy: 0.9187\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1764 - accuracy: 0.9526 - val_loss: 0.4055 - val_accuracy: 0.8387\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1470 - accuracy: 0.9509 - val_loss: 0.3140 - val_accuracy: 0.8840\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1605 - accuracy: 0.9503 - val_loss: 0.3585 - val_accuracy: 0.8720\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1765 - accuracy: 0.9520 - val_loss: 0.3350 - val_accuracy: 0.8747\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1583 - accuracy: 0.9543 - val_loss: 0.3226 - val_accuracy: 0.8867\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1654 - accuracy: 0.9514 - val_loss: 0.3386 - val_accuracy: 0.8520\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1486 - accuracy: 0.9520 - val_loss: 0.3870 - val_accuracy: 0.8907\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1469 - accuracy: 0.9571 - val_loss: 0.4101 - val_accuracy: 0.8387\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1520 - accuracy: 0.9480 - val_loss: 0.3389 - val_accuracy: 0.8693\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1707 - accuracy: 0.9526 - val_loss: 0.8036 - val_accuracy: 0.8093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1746 - accuracy: 0.9571 - val_loss: 0.3888 - val_accuracy: 0.8613\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1750 - accuracy: 0.9451 - val_loss: 0.5051 - val_accuracy: 0.8133\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1599 - accuracy: 0.9566 - val_loss: 0.4251 - val_accuracy: 0.8427\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1543 - accuracy: 0.9606 - val_loss: 0.6347 - val_accuracy: 0.7587\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1624 - accuracy: 0.9526 - val_loss: 0.3349 - val_accuracy: 0.8547\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1435 - accuracy: 0.9554 - val_loss: 0.3971 - val_accuracy: 0.8453\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1375 - accuracy: 0.9617 - val_loss: 0.3871 - val_accuracy: 0.8427\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 21s 188ms/step - loss: 0.1665 - accuracy: 0.9514 - val_loss: 0.2659 - val_accuracy: 0.9013\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.1301 - accuracy: 0.9663 - val_loss: 0.3292 - val_accuracy: 0.8627\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1278 - accuracy: 0.9571 - val_loss: 0.3834 - val_accuracy: 0.8627\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1406 - accuracy: 0.9589 - val_loss: 0.4965 - val_accuracy: 0.8173\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1321 - accuracy: 0.9571 - val_loss: 0.5612 - val_accuracy: 0.7867\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1432 - accuracy: 0.9606 - val_loss: 0.5194 - val_accuracy: 0.8173\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1190 - accuracy: 0.9623 - val_loss: 0.4619 - val_accuracy: 0.8213\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1399 - accuracy: 0.9560 - val_loss: 0.3595 - val_accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1502 - accuracy: 0.9583 - val_loss: 0.3190 - val_accuracy: 0.8587\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1258 - accuracy: 0.9657 - val_loss: 0.3506 - val_accuracy: 0.8760\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1256 - accuracy: 0.9611 - val_loss: 0.4850 - val_accuracy: 0.8080\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1271 - accuracy: 0.9589 - val_loss: 0.3130 - val_accuracy: 0.8947\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1257 - accuracy: 0.9617 - val_loss: 0.3574 - val_accuracy: 0.8600\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1399 - accuracy: 0.9560 - val_loss: 0.2490 - val_accuracy: 0.9027\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1155 - accuracy: 0.9646 - val_loss: 0.4521 - val_accuracy: 0.8200\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1252 - accuracy: 0.9646 - val_loss: 0.4076 - val_accuracy: 0.8493\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1371 - accuracy: 0.9634 - val_loss: 0.4310 - val_accuracy: 0.8413\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1394 - accuracy: 0.9594 - val_loss: 0.2490 - val_accuracy: 0.9173\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1274 - accuracy: 0.9606 - val_loss: 0.3748 - val_accuracy: 0.8760\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1397 - accuracy: 0.9549 - val_loss: 0.3123 - val_accuracy: 0.8960\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1137 - accuracy: 0.9669 - val_loss: 0.4661 - val_accuracy: 0.8533\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1076 - accuracy: 0.9657 - val_loss: 0.4094 - val_accuracy: 0.8613\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1135 - accuracy: 0.9611 - val_loss: 0.4199 - val_accuracy: 0.8653\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1121 - accuracy: 0.9640 - val_loss: 0.3582 - val_accuracy: 0.8760\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1090 - accuracy: 0.9691 - val_loss: 0.5931 - val_accuracy: 0.8707\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1017 - accuracy: 0.9714 - val_loss: 0.4142 - val_accuracy: 0.8613\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0980 - accuracy: 0.9726 - val_loss: 0.6589 - val_accuracy: 0.8080\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1507 - accuracy: 0.9537 - val_loss: 0.3804 - val_accuracy: 0.8680\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0881 - accuracy: 0.9697 - val_loss: 0.7223 - val_accuracy: 0.7440\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1107 - accuracy: 0.9634 - val_loss: 0.3183 - val_accuracy: 0.8813\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1067 - accuracy: 0.9691 - val_loss: 0.5656 - val_accuracy: 0.7867\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1070 - accuracy: 0.9686 - val_loss: 0.4704 - val_accuracy: 0.8160\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1424 - accuracy: 0.9571 - val_loss: 0.2748 - val_accuracy: 0.8800\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1016 - accuracy: 0.9680 - val_loss: 0.4722 - val_accuracy: 0.8147\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1048 - accuracy: 0.9691 - val_loss: 0.5599 - val_accuracy: 0.8107\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0941 - accuracy: 0.9714 - val_loss: 0.5256 - val_accuracy: 0.8147\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1010 - accuracy: 0.9697 - val_loss: 0.3097 - val_accuracy: 0.9013\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0871 - accuracy: 0.9749 - val_loss: 0.7459 - val_accuracy: 0.8173\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0907 - accuracy: 0.9766 - val_loss: 0.4547 - val_accuracy: 0.8520\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0914 - accuracy: 0.9731 - val_loss: 0.4354 - val_accuracy: 0.8613\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0842 - accuracy: 0.9754 - val_loss: 0.2869 - val_accuracy: 0.8840\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0918 - accuracy: 0.9720 - val_loss: 0.5334 - val_accuracy: 0.8307\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0899 - accuracy: 0.9760 - val_loss: 0.4991 - val_accuracy: 0.8440\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1406 - accuracy: 0.9663 - val_loss: 0.5491 - val_accuracy: 0.8413\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0997 - accuracy: 0.9709 - val_loss: 0.3344 - val_accuracy: 0.8747\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1065 - accuracy: 0.9657 - val_loss: 0.4016 - val_accuracy: 0.8573\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0751 - accuracy: 0.9771 - val_loss: 0.3342 - val_accuracy: 0.8733\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0901 - accuracy: 0.9731 - val_loss: 0.4509 - val_accuracy: 0.8720\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0789 - accuracy: 0.9777 - val_loss: 0.3458 - val_accuracy: 0.8813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0991 - accuracy: 0.9709 - val_loss: 0.3177 - val_accuracy: 0.8787\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0796 - accuracy: 0.9789 - val_loss: 0.4515 - val_accuracy: 0.8347\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0867 - accuracy: 0.9771 - val_loss: 0.4131 - val_accuracy: 0.8613\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0912 - accuracy: 0.9731 - val_loss: 0.3940 - val_accuracy: 0.8453\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0794 - accuracy: 0.9760 - val_loss: 0.3746 - val_accuracy: 0.8800\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0938 - accuracy: 0.9691 - val_loss: 0.6347 - val_accuracy: 0.7373\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0936 - accuracy: 0.9709 - val_loss: 0.3842 - val_accuracy: 0.8707\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1041 - accuracy: 0.9663 - val_loss: 0.3777 - val_accuracy: 0.8853\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0807 - accuracy: 0.9766 - val_loss: 0.4362 - val_accuracy: 0.8093\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0867 - accuracy: 0.9794 - val_loss: 0.3333 - val_accuracy: 0.8640\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1013 - accuracy: 0.9709 - val_loss: 0.5431 - val_accuracy: 0.8560\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0842 - accuracy: 0.9726 - val_loss: 0.4766 - val_accuracy: 0.8547\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0949 - accuracy: 0.9691 - val_loss: 0.3186 - val_accuracy: 0.8800\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0823 - accuracy: 0.9771 - val_loss: 0.4294 - val_accuracy: 0.8493\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0857 - accuracy: 0.9754 - val_loss: 0.4562 - val_accuracy: 0.8653\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0775 - accuracy: 0.9760 - val_loss: 0.5608 - val_accuracy: 0.8240\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0764 - accuracy: 0.9731 - val_loss: 0.3586 - val_accuracy: 0.8253\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0781 - accuracy: 0.9737 - val_loss: 0.4604 - val_accuracy: 0.8440\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0855 - accuracy: 0.9766 - val_loss: 0.6029 - val_accuracy: 0.7147\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0834 - accuracy: 0.9771 - val_loss: 0.6202 - val_accuracy: 0.8240\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0745 - accuracy: 0.9760 - val_loss: 0.4744 - val_accuracy: 0.8613\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0926 - accuracy: 0.9726 - val_loss: 0.4056 - val_accuracy: 0.8667\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0671 - accuracy: 0.9783 - val_loss: 0.4732 - val_accuracy: 0.8467\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0783 - accuracy: 0.9749 - val_loss: 0.6071 - val_accuracy: 0.7333\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0766 - accuracy: 0.9800 - val_loss: 0.5601 - val_accuracy: 0.8680\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0854 - accuracy: 0.9720 - val_loss: 0.5243 - val_accuracy: 0.7947\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1213 - accuracy: 0.9657 - val_loss: 0.4753 - val_accuracy: 0.8453\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0896 - accuracy: 0.9760 - val_loss: 0.4447 - val_accuracy: 0.8400\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0755 - accuracy: 0.9743 - val_loss: 0.3914 - val_accuracy: 0.8160\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0785 - accuracy: 0.9817 - val_loss: 0.6157 - val_accuracy: 0.7640\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0864 - accuracy: 0.9783 - val_loss: 0.5420 - val_accuracy: 0.8227\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0862 - accuracy: 0.9766 - val_loss: 0.6258 - val_accuracy: 0.7600\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0889 - accuracy: 0.9686 - val_loss: 0.6795 - val_accuracy: 0.8147\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0641 - accuracy: 0.9817 - val_loss: 0.4484 - val_accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0812 - accuracy: 0.9777 - val_loss: 0.6956 - val_accuracy: 0.8040\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0862 - accuracy: 0.9777 - val_loss: 0.5558 - val_accuracy: 0.8347\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0745 - accuracy: 0.9760 - val_loss: 0.4996 - val_accuracy: 0.8040\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0814 - accuracy: 0.9777 - val_loss: 0.4588 - val_accuracy: 0.8253\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0778 - accuracy: 0.9766 - val_loss: 0.5484 - val_accuracy: 0.7973\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0647 - accuracy: 0.9811 - val_loss: 0.5669 - val_accuracy: 0.8053\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0762 - accuracy: 0.9800 - val_loss: 0.3632 - val_accuracy: 0.8480\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0786 - accuracy: 0.9794 - val_loss: 0.4615 - val_accuracy: 0.8467\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0763 - accuracy: 0.9777 - val_loss: 0.2513 - val_accuracy: 0.9187\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0849 - accuracy: 0.9726 - val_loss: 0.4059 - val_accuracy: 0.8520\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0849 - accuracy: 0.9760 - val_loss: 0.3881 - val_accuracy: 0.8600\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0798 - accuracy: 0.9760 - val_loss: 0.4808 - val_accuracy: 0.8373\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0743 - accuracy: 0.9771 - val_loss: 0.4803 - val_accuracy: 0.8507\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0628 - accuracy: 0.9823 - val_loss: 1.7393 - val_accuracy: 0.7387\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0623 - accuracy: 0.9840 - val_loss: 0.8275 - val_accuracy: 0.7600\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0916 - accuracy: 0.9737 - val_loss: 0.7497 - val_accuracy: 0.8133\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0783 - accuracy: 0.9771 - val_loss: 0.5871 - val_accuracy: 0.8267\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0793 - accuracy: 0.9800 - val_loss: 0.5824 - val_accuracy: 0.7907\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1041 - accuracy: 0.9749 - val_loss: 0.5770 - val_accuracy: 0.8147\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1163 - accuracy: 0.9686 - val_loss: 0.5252 - val_accuracy: 0.8413\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0884 - accuracy: 0.9766 - val_loss: 0.3610 - val_accuracy: 0.8667\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0751 - accuracy: 0.9806 - val_loss: 0.5682 - val_accuracy: 0.8187\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0776 - accuracy: 0.9726 - val_loss: 0.5699 - val_accuracy: 0.8227\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1025 - accuracy: 0.9720 - val_loss: 0.5739 - val_accuracy: 0.8213\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0875 - accuracy: 0.9766 - val_loss: 0.5148 - val_accuracy: 0.8507\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0854 - accuracy: 0.9737 - val_loss: 0.5214 - val_accuracy: 0.8293\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0867 - accuracy: 0.9714 - val_loss: 0.6871 - val_accuracy: 0.7960\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0808 - accuracy: 0.9783 - val_loss: 0.5712 - val_accuracy: 0.8400\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0736 - accuracy: 0.9783 - val_loss: 0.6439 - val_accuracy: 0.8013\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0669 - accuracy: 0.9806 - val_loss: 0.5454 - val_accuracy: 0.8520\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0634 - accuracy: 0.9817 - val_loss: 0.5767 - val_accuracy: 0.8280\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0644 - accuracy: 0.9823 - val_loss: 0.4946 - val_accuracy: 0.8547\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0491 - accuracy: 0.9874 - val_loss: 0.6751 - val_accuracy: 0.8400\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0628 - accuracy: 0.9834 - val_loss: 0.6675 - val_accuracy: 0.8027\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0539 - accuracy: 0.9829 - val_loss: 0.6312 - val_accuracy: 0.8067\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0529 - accuracy: 0.9863 - val_loss: 0.5710 - val_accuracy: 0.8600\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0686 - accuracy: 0.9800 - val_loss: 0.4238 - val_accuracy: 0.8480\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0742 - accuracy: 0.9834 - val_loss: 0.5385 - val_accuracy: 0.8667\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0638 - accuracy: 0.9834 - val_loss: 0.4528 - val_accuracy: 0.8747\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0845 - accuracy: 0.9749 - val_loss: 0.5156 - val_accuracy: 0.8533\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0668 - accuracy: 0.9800 - val_loss: 0.5905 - val_accuracy: 0.8573\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0698 - accuracy: 0.9840 - val_loss: 0.5685 - val_accuracy: 0.8507\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0564 - accuracy: 0.9840 - val_loss: 0.5232 - val_accuracy: 0.8613\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0671 - accuracy: 0.9829 - val_loss: 0.4899 - val_accuracy: 0.8573\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0579 - accuracy: 0.9857 - val_loss: 0.7186 - val_accuracy: 0.8027\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0567 - accuracy: 0.9851 - val_loss: 0.6227 - val_accuracy: 0.8240\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0801 - accuracy: 0.9766 - val_loss: 0.5226 - val_accuracy: 0.8520\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0781 - accuracy: 0.9794 - val_loss: 0.5705 - val_accuracy: 0.8440\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0536 - accuracy: 0.9851 - val_loss: 0.4807 - val_accuracy: 0.8573\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0590 - accuracy: 0.9846 - val_loss: 0.5474 - val_accuracy: 0.8440\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0487 - accuracy: 0.9880 - val_loss: 0.5914 - val_accuracy: 0.8493\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0770 - accuracy: 0.9829 - val_loss: 0.5103 - val_accuracy: 0.8053\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0649 - accuracy: 0.9806 - val_loss: 0.4753 - val_accuracy: 0.8093\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0665 - accuracy: 0.9811 - val_loss: 0.6378 - val_accuracy: 0.8253\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0676 - accuracy: 0.9800 - val_loss: 0.7278 - val_accuracy: 0.7933\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0686 - accuracy: 0.9800 - val_loss: 0.5317 - val_accuracy: 0.8640\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0491 - accuracy: 0.9863 - val_loss: 0.7025 - val_accuracy: 0.8267\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.0716 - accuracy: 0.9800 - val_loss: 0.6541 - val_accuracy: 0.8160\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0427 - accuracy: 0.9891 - val_loss: 0.6676 - val_accuracy: 0.8453\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0638 - accuracy: 0.9806 - val_loss: 0.5984 - val_accuracy: 0.8307\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0573 - accuracy: 0.9840 - val_loss: 0.8906 - val_accuracy: 0.7933\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0644 - accuracy: 0.9823 - val_loss: 0.7382 - val_accuracy: 0.7893\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 4)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 48s - loss: 4.9121 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0943s vs `on_train_batch_end` time: 0.7655s). Check your callbacks.\n",
      "110/110 [==============================] - 20s 179ms/step - loss: 1.1736 - accuracy: 0.7137 - val_loss: 0.6593 - val_accuracy: 0.6280\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.6956 - accuracy: 0.7851 - val_loss: 0.8588 - val_accuracy: 0.4040\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.6466 - accuracy: 0.8114 - val_loss: 1.0157 - val_accuracy: 0.5787\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.5523 - accuracy: 0.8229 - val_loss: 0.9637 - val_accuracy: 0.6800\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.4583 - accuracy: 0.8514 - val_loss: 1.1519 - val_accuracy: 0.7187\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.4360 - accuracy: 0.8497 - val_loss: 1.1297 - val_accuracy: 0.6653\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.4625 - accuracy: 0.8566 - val_loss: 1.5099 - val_accuracy: 0.6307\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.3548 - accuracy: 0.8766 - val_loss: 1.6763 - val_accuracy: 0.6080\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 162ms/step - loss: 0.3590 - accuracy: 0.8817 - val_loss: 0.5389 - val_accuracy: 0.7600\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2914 - accuracy: 0.8909 - val_loss: 0.6253 - val_accuracy: 0.7360\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2844 - accuracy: 0.9017 - val_loss: 0.7481 - val_accuracy: 0.7320\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.3379 - accuracy: 0.9000 - val_loss: 0.9321 - val_accuracy: 0.7880\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.2856 - accuracy: 0.9029 - val_loss: 1.6286 - val_accuracy: 0.7907\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2659 - accuracy: 0.9166 - val_loss: 0.7697 - val_accuracy: 0.7333\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2428 - accuracy: 0.9211 - val_loss: 0.8926 - val_accuracy: 0.7507\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2126 - accuracy: 0.9291 - val_loss: 8.7602 - val_accuracy: 0.7640\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2493 - accuracy: 0.9280 - val_loss: 0.5394 - val_accuracy: 0.8507\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.2404 - accuracy: 0.9217 - val_loss: 1.3625 - val_accuracy: 0.7413\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1966 - accuracy: 0.9411 - val_loss: 1.3425 - val_accuracy: 0.7800\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2063 - accuracy: 0.9331 - val_loss: 1.6048 - val_accuracy: 0.7307\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1977 - accuracy: 0.9394 - val_loss: 0.9613 - val_accuracy: 0.6440\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2004 - accuracy: 0.9383 - val_loss: 0.6783 - val_accuracy: 0.7800\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1827 - accuracy: 0.9411 - val_loss: 0.9082 - val_accuracy: 0.7733\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1713 - accuracy: 0.9406 - val_loss: 1.1450 - val_accuracy: 0.7387\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1884 - accuracy: 0.9429 - val_loss: 1.1388 - val_accuracy: 0.7640\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1829 - accuracy: 0.9434 - val_loss: 0.5395 - val_accuracy: 0.8467\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.2255 - accuracy: 0.9434 - val_loss: 0.5767 - val_accuracy: 0.8093\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1881 - accuracy: 0.9463 - val_loss: 0.7195 - val_accuracy: 0.7680\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1905 - accuracy: 0.9400 - val_loss: 1.0610 - val_accuracy: 0.7853\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1674 - accuracy: 0.9440 - val_loss: 1.8309 - val_accuracy: 0.7853\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1600 - accuracy: 0.9520 - val_loss: 1.5903 - val_accuracy: 0.7853\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1480 - accuracy: 0.9503 - val_loss: 1.4565 - val_accuracy: 0.7747\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1523 - accuracy: 0.9503 - val_loss: 1.5030 - val_accuracy: 0.7427\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1677 - accuracy: 0.9457 - val_loss: 1.7805 - val_accuracy: 0.7653\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1518 - accuracy: 0.9491 - val_loss: 1.5052 - val_accuracy: 0.8133\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1605 - accuracy: 0.9474 - val_loss: 2.1269 - val_accuracy: 0.7427\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2077 - accuracy: 0.9440 - val_loss: 0.8454 - val_accuracy: 0.8147\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2026 - accuracy: 0.9514 - val_loss: 0.8555 - val_accuracy: 0.7853\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1657 - accuracy: 0.9491 - val_loss: 0.6966 - val_accuracy: 0.7787\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1566 - accuracy: 0.9520 - val_loss: 0.5331 - val_accuracy: 0.8293\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1684 - accuracy: 0.9480 - val_loss: 0.6708 - val_accuracy: 0.7987\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1482 - accuracy: 0.9560 - val_loss: 0.6433 - val_accuracy: 0.7733\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1546 - accuracy: 0.9549 - val_loss: 0.8114 - val_accuracy: 0.7907\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1600 - accuracy: 0.9474 - val_loss: 0.5440 - val_accuracy: 0.8067\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1444 - accuracy: 0.9480 - val_loss: 0.5680 - val_accuracy: 0.8280\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1545 - accuracy: 0.9537 - val_loss: 0.7375 - val_accuracy: 0.8200\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1375 - accuracy: 0.9531 - val_loss: 0.5967 - val_accuracy: 0.8253\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1293 - accuracy: 0.9583 - val_loss: 0.5286 - val_accuracy: 0.8360\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1286 - accuracy: 0.9577 - val_loss: 0.4593 - val_accuracy: 0.8507\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1553 - accuracy: 0.9486 - val_loss: 0.7216 - val_accuracy: 0.7893\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1557 - accuracy: 0.9560 - val_loss: 0.6368 - val_accuracy: 0.7853\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1263 - accuracy: 0.9571 - val_loss: 0.4962 - val_accuracy: 0.8267\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1243 - accuracy: 0.9606 - val_loss: 0.5084 - val_accuracy: 0.8307\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1329 - accuracy: 0.9554 - val_loss: 0.5453 - val_accuracy: 0.8120\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1333 - accuracy: 0.9554 - val_loss: 0.5760 - val_accuracy: 0.8000\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1183 - accuracy: 0.9611 - val_loss: 0.6642 - val_accuracy: 0.8253\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1254 - accuracy: 0.9623 - val_loss: 0.5548 - val_accuracy: 0.8387\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1331 - accuracy: 0.9651 - val_loss: 0.7598 - val_accuracy: 0.7960\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1406 - accuracy: 0.9549 - val_loss: 0.5332 - val_accuracy: 0.8373\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1238 - accuracy: 0.9583 - val_loss: 0.4453 - val_accuracy: 0.8267\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1310 - accuracy: 0.9549 - val_loss: 0.7581 - val_accuracy: 0.7547\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1377 - accuracy: 0.9554 - val_loss: 0.7350 - val_accuracy: 0.7613\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1114 - accuracy: 0.9629 - val_loss: 0.5284 - val_accuracy: 0.8013\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1394 - accuracy: 0.9549 - val_loss: 0.5157 - val_accuracy: 0.8387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1171 - accuracy: 0.9594 - val_loss: 0.4496 - val_accuracy: 0.8507\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1063 - accuracy: 0.9657 - val_loss: 0.4890 - val_accuracy: 0.8347\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1208 - accuracy: 0.9623 - val_loss: 0.4889 - val_accuracy: 0.8213\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1188 - accuracy: 0.9629 - val_loss: 0.6934 - val_accuracy: 0.7880\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1120 - accuracy: 0.9617 - val_loss: 0.4710 - val_accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1258 - accuracy: 0.9560 - val_loss: 0.3474 - val_accuracy: 0.8707\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1242 - accuracy: 0.9583 - val_loss: 0.4931 - val_accuracy: 0.8373\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1141 - accuracy: 0.9623 - val_loss: 0.5864 - val_accuracy: 0.8000\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1154 - accuracy: 0.9629 - val_loss: 0.5053 - val_accuracy: 0.8280\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1161 - accuracy: 0.9611 - val_loss: 0.3616 - val_accuracy: 0.8533\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1754 - accuracy: 0.9440 - val_loss: 0.7093 - val_accuracy: 0.7373\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1329 - accuracy: 0.9537 - val_loss: 0.6840 - val_accuracy: 0.7707\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1256 - accuracy: 0.9640 - val_loss: 0.6073 - val_accuracy: 0.8080\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1157 - accuracy: 0.9600 - val_loss: 0.6409 - val_accuracy: 0.7787\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1176 - accuracy: 0.9577 - val_loss: 0.4937 - val_accuracy: 0.8413\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1292 - accuracy: 0.9560 - val_loss: 0.8147 - val_accuracy: 0.7653\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1147 - accuracy: 0.9589 - val_loss: 0.6816 - val_accuracy: 0.7880\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1195 - accuracy: 0.9617 - val_loss: 0.6467 - val_accuracy: 0.8040\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1129 - accuracy: 0.9634 - val_loss: 0.5835 - val_accuracy: 0.8040\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0921 - accuracy: 0.9709 - val_loss: 0.7096 - val_accuracy: 0.7800\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1056 - accuracy: 0.9640 - val_loss: 0.7665 - val_accuracy: 0.7680\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0963 - accuracy: 0.9709 - val_loss: 0.8126 - val_accuracy: 0.7720\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1256 - accuracy: 0.9640 - val_loss: 0.5281 - val_accuracy: 0.8200\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1071 - accuracy: 0.9674 - val_loss: 0.5735 - val_accuracy: 0.7827\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0968 - accuracy: 0.9703 - val_loss: 0.7504 - val_accuracy: 0.7400\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1111 - accuracy: 0.9657 - val_loss: 0.9317 - val_accuracy: 0.7320\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1230 - accuracy: 0.9617 - val_loss: 0.6251 - val_accuracy: 0.7853\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1057 - accuracy: 0.9674 - val_loss: 0.6036 - val_accuracy: 0.8053\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0983 - accuracy: 0.9697 - val_loss: 0.7694 - val_accuracy: 0.7653\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1049 - accuracy: 0.9680 - val_loss: 0.6861 - val_accuracy: 0.7667\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 20s 184ms/step - loss: 0.0915 - accuracy: 0.9743 - val_loss: 0.8794 - val_accuracy: 0.7760\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 20s 184ms/step - loss: 0.0964 - accuracy: 0.9697 - val_loss: 0.9763 - val_accuracy: 0.7600\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1076 - accuracy: 0.9634 - val_loss: 0.6421 - val_accuracy: 0.7840\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1107 - accuracy: 0.9663 - val_loss: 0.4434 - val_accuracy: 0.8213\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0985 - accuracy: 0.9640 - val_loss: 0.7675 - val_accuracy: 0.7520\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1062 - accuracy: 0.9634 - val_loss: 0.6022 - val_accuracy: 0.7840\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1151 - accuracy: 0.9606 - val_loss: 0.7952 - val_accuracy: 0.7840\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0933 - accuracy: 0.9663 - val_loss: 1.0174 - val_accuracy: 0.7387\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1184 - accuracy: 0.9606 - val_loss: 0.8061 - val_accuracy: 0.8040\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0996 - accuracy: 0.9674 - val_loss: 0.5086 - val_accuracy: 0.8360\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0793 - accuracy: 0.9754 - val_loss: 0.7780 - val_accuracy: 0.7840\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0986 - accuracy: 0.9703 - val_loss: 0.6417 - val_accuracy: 0.8053\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0974 - accuracy: 0.9674 - val_loss: 0.6756 - val_accuracy: 0.7360\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0930 - accuracy: 0.9703 - val_loss: 0.6854 - val_accuracy: 0.7707\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0937 - accuracy: 0.9737 - val_loss: 0.5832 - val_accuracy: 0.7880\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0921 - accuracy: 0.9691 - val_loss: 0.5906 - val_accuracy: 0.8053\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0897 - accuracy: 0.9691 - val_loss: 0.3483 - val_accuracy: 0.8747\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0942 - accuracy: 0.9720 - val_loss: 0.6534 - val_accuracy: 0.7960\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0826 - accuracy: 0.9743 - val_loss: 0.4502 - val_accuracy: 0.8493\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0914 - accuracy: 0.9697 - val_loss: 0.7222 - val_accuracy: 0.7560\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0976 - accuracy: 0.9703 - val_loss: 0.7079 - val_accuracy: 0.7827\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0984 - accuracy: 0.9691 - val_loss: 0.6346 - val_accuracy: 0.7680\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0909 - accuracy: 0.9697 - val_loss: 0.4387 - val_accuracy: 0.8560\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0855 - accuracy: 0.9709 - val_loss: 0.4750 - val_accuracy: 0.8453\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1298 - accuracy: 0.9714 - val_loss: 0.5450 - val_accuracy: 0.8173\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0843 - accuracy: 0.9691 - val_loss: 0.5040 - val_accuracy: 0.8107\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1306 - accuracy: 0.9686 - val_loss: 0.3065 - val_accuracy: 0.8840\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0992 - accuracy: 0.9617 - val_loss: 0.3151 - val_accuracy: 0.8827\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1008 - accuracy: 0.9657 - val_loss: 1.9498 - val_accuracy: 0.8773\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0916 - accuracy: 0.9731 - val_loss: 0.5318 - val_accuracy: 0.8213\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1068 - accuracy: 0.9743 - val_loss: 0.5952 - val_accuracy: 0.7933\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0820 - accuracy: 0.9754 - val_loss: 0.5264 - val_accuracy: 0.8187\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0996 - accuracy: 0.9703 - val_loss: 0.3281 - val_accuracy: 0.8653\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1278 - accuracy: 0.9651 - val_loss: 0.6763 - val_accuracy: 0.7640\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1131 - accuracy: 0.9629 - val_loss: 0.3969 - val_accuracy: 0.8520\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0897 - accuracy: 0.9697 - val_loss: 0.4021 - val_accuracy: 0.8347\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1143 - accuracy: 0.9669 - val_loss: 0.4139 - val_accuracy: 0.8453\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1245 - accuracy: 0.9669 - val_loss: 0.2679 - val_accuracy: 0.8827\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0904 - accuracy: 0.9737 - val_loss: 0.3842 - val_accuracy: 0.8613\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1281 - accuracy: 0.9686 - val_loss: 0.4843 - val_accuracy: 0.8320\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1039 - accuracy: 0.9697 - val_loss: 0.4080 - val_accuracy: 0.8560\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0873 - accuracy: 0.9686 - val_loss: 0.5522 - val_accuracy: 0.8227\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0874 - accuracy: 0.9766 - val_loss: 0.5109 - val_accuracy: 0.8253\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1437 - accuracy: 0.9589 - val_loss: 0.4341 - val_accuracy: 0.8400\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1041 - accuracy: 0.9703 - val_loss: 0.4154 - val_accuracy: 0.8720\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0992 - accuracy: 0.9657 - val_loss: 0.3863 - val_accuracy: 0.8640\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0995 - accuracy: 0.9726 - val_loss: 0.6280 - val_accuracy: 0.7960\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0841 - accuracy: 0.9731 - val_loss: 0.4042 - val_accuracy: 0.8640\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0921 - accuracy: 0.9766 - val_loss: 0.5352 - val_accuracy: 0.8227\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1015 - accuracy: 0.9697 - val_loss: 0.5736 - val_accuracy: 0.8347\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0991 - accuracy: 0.9686 - val_loss: 0.6719 - val_accuracy: 0.8213\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1043 - accuracy: 0.9640 - val_loss: 0.4190 - val_accuracy: 0.8507\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0913 - accuracy: 0.9737 - val_loss: 0.4360 - val_accuracy: 0.8707\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0847 - accuracy: 0.9743 - val_loss: 0.4641 - val_accuracy: 0.8493\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0948 - accuracy: 0.9777 - val_loss: 0.4541 - val_accuracy: 0.8480\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0866 - accuracy: 0.9691 - val_loss: 0.4886 - val_accuracy: 0.8347\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0823 - accuracy: 0.9731 - val_loss: 0.3336 - val_accuracy: 0.8800\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0807 - accuracy: 0.9737 - val_loss: 0.4521 - val_accuracy: 0.8360\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0970 - accuracy: 0.9766 - val_loss: 0.4859 - val_accuracy: 0.8480\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0748 - accuracy: 0.9771 - val_loss: 0.5665 - val_accuracy: 0.8293\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0770 - accuracy: 0.9760 - val_loss: 0.3547 - val_accuracy: 0.8907\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0718 - accuracy: 0.9783 - val_loss: 0.3405 - val_accuracy: 0.8853\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0585 - accuracy: 0.9840 - val_loss: 0.5634 - val_accuracy: 0.8413\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0705 - accuracy: 0.9771 - val_loss: 0.3640 - val_accuracy: 0.8693\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0731 - accuracy: 0.9811 - val_loss: 0.4698 - val_accuracy: 0.8707\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0770 - accuracy: 0.9766 - val_loss: 0.5768 - val_accuracy: 0.7747\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0686 - accuracy: 0.9800 - val_loss: 0.4009 - val_accuracy: 0.8480\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0901 - accuracy: 0.9743 - val_loss: 0.7607 - val_accuracy: 0.7467\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0858 - accuracy: 0.9743 - val_loss: 0.4741 - val_accuracy: 0.8493\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0782 - accuracy: 0.9800 - val_loss: 0.4815 - val_accuracy: 0.8573\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0929 - accuracy: 0.9743 - val_loss: 0.2805 - val_accuracy: 0.8920\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0763 - accuracy: 0.9737 - val_loss: 0.4184 - val_accuracy: 0.8507\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0955 - accuracy: 0.9789 - val_loss: 0.5569 - val_accuracy: 0.8187\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0902 - accuracy: 0.9680 - val_loss: 0.6940 - val_accuracy: 0.7627\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0795 - accuracy: 0.9777 - val_loss: 0.4542 - val_accuracy: 0.8240\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0683 - accuracy: 0.9800 - val_loss: 0.5518 - val_accuracy: 0.8320\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0797 - accuracy: 0.9760 - val_loss: 0.4669 - val_accuracy: 0.8427\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0721 - accuracy: 0.9794 - val_loss: 0.4707 - val_accuracy: 0.8280\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0777 - accuracy: 0.9789 - val_loss: 0.3199 - val_accuracy: 0.8640\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1045 - accuracy: 0.9800 - val_loss: 0.3047 - val_accuracy: 0.8933\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0798 - accuracy: 0.9771 - val_loss: 0.3981 - val_accuracy: 0.8613\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0902 - accuracy: 0.9783 - val_loss: 0.3478 - val_accuracy: 0.8827\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1044 - accuracy: 0.9714 - val_loss: 0.4225 - val_accuracy: 0.8373\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0713 - accuracy: 0.9800 - val_loss: 0.4936 - val_accuracy: 0.8320\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0740 - accuracy: 0.9789 - val_loss: 0.4687 - val_accuracy: 0.8373\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0683 - accuracy: 0.9823 - val_loss: 0.6378 - val_accuracy: 0.8373\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0648 - accuracy: 0.9794 - val_loss: 0.3498 - val_accuracy: 0.8613\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0706 - accuracy: 0.9777 - val_loss: 0.3321 - val_accuracy: 0.8840\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1092 - accuracy: 0.9709 - val_loss: 0.2647 - val_accuracy: 0.8960\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0723 - accuracy: 0.9783 - val_loss: 0.2399 - val_accuracy: 0.9027\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0773 - accuracy: 0.9783 - val_loss: 0.2241 - val_accuracy: 0.9067\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.0667 - accuracy: 0.9783 - val_loss: 0.3410 - val_accuracy: 0.8760\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0696 - accuracy: 0.9800 - val_loss: 0.3052 - val_accuracy: 0.8773\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0725 - accuracy: 0.9777 - val_loss: 0.3444 - val_accuracy: 0.8680\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0783 - accuracy: 0.9743 - val_loss: 0.2663 - val_accuracy: 0.8800\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0701 - accuracy: 0.9783 - val_loss: 0.4038 - val_accuracy: 0.8547\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0814 - accuracy: 0.9766 - val_loss: 0.5965 - val_accuracy: 0.8133\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.0550 - accuracy: 0.9857 - val_loss: 0.3873 - val_accuracy: 0.8693\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0754 - accuracy: 0.9794 - val_loss: 0.2777 - val_accuracy: 0.8813\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0694 - accuracy: 0.9806 - val_loss: 0.4799 - val_accuracy: 0.8360\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0572 - accuracy: 0.9840 - val_loss: 0.4176 - val_accuracy: 0.8640\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0692 - accuracy: 0.9811 - val_loss: 0.3704 - val_accuracy: 0.8667\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0658 - accuracy: 0.9817 - val_loss: 0.4943 - val_accuracy: 0.8440\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0637 - accuracy: 0.9817 - val_loss: 0.5171 - val_accuracy: 0.8267\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0661 - accuracy: 0.9794 - val_loss: 0.4065 - val_accuracy: 0.8587\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0819 - accuracy: 0.9754 - val_loss: 0.3396 - val_accuracy: 0.8760\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 4)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 48s - loss: 1.4066 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0967s vs `on_train_batch_end` time: 0.7655s). Check your callbacks.\n",
      "110/110 [==============================] - 19s 177ms/step - loss: 0.7770 - accuracy: 0.7166 - val_loss: 0.6641 - val_accuracy: 0.6280\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.5845 - accuracy: 0.7994 - val_loss: 0.8762 - val_accuracy: 0.3720\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.5017 - accuracy: 0.8086 - val_loss: 0.9862 - val_accuracy: 0.4320\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.5091 - accuracy: 0.8160 - val_loss: 0.6816 - val_accuracy: 0.6413\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.4743 - accuracy: 0.8274 - val_loss: 0.8185 - val_accuracy: 0.6560\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.4878 - accuracy: 0.8349 - val_loss: 1.5669 - val_accuracy: 0.6533\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.4005 - accuracy: 0.8577 - val_loss: 2.5695 - val_accuracy: 0.5947\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.4183 - accuracy: 0.8509 - val_loss: 1.1952 - val_accuracy: 0.6253\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.5257 - accuracy: 0.8291 - val_loss: 2.9737 - val_accuracy: 0.7680\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.3979 - accuracy: 0.8571 - val_loss: 1.5025 - val_accuracy: 0.7027\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.4247 - accuracy: 0.8343 - val_loss: 0.9291 - val_accuracy: 0.6813\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.3859 - accuracy: 0.8480 - val_loss: 0.9861 - val_accuracy: 0.6227\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.3792 - accuracy: 0.8600 - val_loss: 1.0294 - val_accuracy: 0.6440\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.4348 - accuracy: 0.8549 - val_loss: 0.7286 - val_accuracy: 0.7173\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.3699 - accuracy: 0.8629 - val_loss: 0.9001 - val_accuracy: 0.6480\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.4353 - accuracy: 0.8617 - val_loss: 3.1843 - val_accuracy: 0.6960\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.3356 - accuracy: 0.8629 - val_loss: 0.7649 - val_accuracy: 0.7253\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.3574 - accuracy: 0.8691 - val_loss: 0.9417 - val_accuracy: 0.7267\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.3710 - accuracy: 0.8549 - val_loss: 1.5450 - val_accuracy: 0.6853\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.3573 - accuracy: 0.8686 - val_loss: 2.2595 - val_accuracy: 0.6360\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.4068 - accuracy: 0.8669 - val_loss: 2.6862 - val_accuracy: 0.6067\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.4166 - accuracy: 0.8497 - val_loss: 8.8144 - val_accuracy: 0.5560\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.3999 - accuracy: 0.8743 - val_loss: 2.0196 - val_accuracy: 0.6573\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.3164 - accuracy: 0.8840 - val_loss: 1.1004 - val_accuracy: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.4388 - accuracy: 0.8611 - val_loss: 1.4576 - val_accuracy: 0.6520\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.3982 - accuracy: 0.8600 - val_loss: 1.1343 - val_accuracy: 0.6187\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.3633 - accuracy: 0.8657 - val_loss: 1.0528 - val_accuracy: 0.6333\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.3648 - accuracy: 0.8749 - val_loss: 0.9091 - val_accuracy: 0.6360\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.3791 - accuracy: 0.8749 - val_loss: 0.8659 - val_accuracy: 0.6667\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.3134 - accuracy: 0.8937 - val_loss: 1.0821 - val_accuracy: 0.7267\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.3628 - accuracy: 0.8691 - val_loss: 1.6309 - val_accuracy: 0.6480\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.3258 - accuracy: 0.8834 - val_loss: 1.3695 - val_accuracy: 0.7373\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.3137 - accuracy: 0.8846 - val_loss: 1.4467 - val_accuracy: 0.7333\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3237 - accuracy: 0.8869 - val_loss: 1.6428 - val_accuracy: 0.6760\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3308 - accuracy: 0.8886 - val_loss: 1.3409 - val_accuracy: 0.6720\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2958 - accuracy: 0.8966 - val_loss: 1.4052 - val_accuracy: 0.6760\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.3342 - accuracy: 0.8886 - val_loss: 1.6595 - val_accuracy: 0.6947\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3137 - accuracy: 0.8846 - val_loss: 1.3561 - val_accuracy: 0.6653\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.3060 - accuracy: 0.8971 - val_loss: 1.1239 - val_accuracy: 0.7187\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.2768 - accuracy: 0.8977 - val_loss: 1.5174 - val_accuracy: 0.5787\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2902 - accuracy: 0.8863 - val_loss: 1.5242 - val_accuracy: 0.6347\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2794 - accuracy: 0.9149 - val_loss: 1.4860 - val_accuracy: 0.7360\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2634 - accuracy: 0.9051 - val_loss: 2.4494 - val_accuracy: 0.7147\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2930 - accuracy: 0.9046 - val_loss: 1.0726 - val_accuracy: 0.7453\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.3270 - accuracy: 0.8897 - val_loss: 1.7568 - val_accuracy: 0.6787\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2955 - accuracy: 0.9074 - val_loss: 2.3692 - val_accuracy: 0.7067\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2826 - accuracy: 0.8949 - val_loss: 1.8647 - val_accuracy: 0.6893\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.2713 - accuracy: 0.9040 - val_loss: 1.1187 - val_accuracy: 0.7360\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.2302 - accuracy: 0.9223 - val_loss: 1.0799 - val_accuracy: 0.7427\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.2552 - accuracy: 0.9177 - val_loss: 1.4000 - val_accuracy: 0.6747\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2872 - accuracy: 0.9091 - val_loss: 1.1630 - val_accuracy: 0.6973\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2482 - accuracy: 0.9143 - val_loss: 0.7685 - val_accuracy: 0.6960\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.2257 - accuracy: 0.9149 - val_loss: 0.7601 - val_accuracy: 0.7200\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.2163 - accuracy: 0.9309 - val_loss: 0.7569 - val_accuracy: 0.6840\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2502 - accuracy: 0.9131 - val_loss: 0.7896 - val_accuracy: 0.7093\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.3288 - accuracy: 0.9166 - val_loss: 1.2307 - val_accuracy: 0.6453\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.2452 - accuracy: 0.9194 - val_loss: 1.3052 - val_accuracy: 0.6933\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2420 - accuracy: 0.9171 - val_loss: 2.1966 - val_accuracy: 0.6507\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2208 - accuracy: 0.9257 - val_loss: 1.9893 - val_accuracy: 0.6293\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.2000 - accuracy: 0.9349 - val_loss: 2.0545 - val_accuracy: 0.6573\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.2096 - accuracy: 0.9331 - val_loss: 5.6956 - val_accuracy: 0.6093\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2156 - accuracy: 0.9280 - val_loss: 2.3544 - val_accuracy: 0.5813\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.2108 - accuracy: 0.9309 - val_loss: 1.6470 - val_accuracy: 0.6293\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.2315 - accuracy: 0.9309 - val_loss: 2.3440 - val_accuracy: 0.6667\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.2009 - accuracy: 0.9331 - val_loss: 1.4695 - val_accuracy: 0.6613\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1994 - accuracy: 0.9337 - val_loss: 0.7991 - val_accuracy: 0.7120\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1958 - accuracy: 0.9343 - val_loss: 0.9173 - val_accuracy: 0.6787\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1924 - accuracy: 0.9326 - val_loss: 0.7348 - val_accuracy: 0.7440\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1889 - accuracy: 0.9343 - val_loss: 1.0753 - val_accuracy: 0.7280\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.2007 - accuracy: 0.9269 - val_loss: 1.4486 - val_accuracy: 0.7053\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1868 - accuracy: 0.9383 - val_loss: 1.9440 - val_accuracy: 0.6560\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1960 - accuracy: 0.9291 - val_loss: 1.6311 - val_accuracy: 0.6813\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.2177 - accuracy: 0.9309 - val_loss: 2.1627 - val_accuracy: 0.7120\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.2062 - accuracy: 0.9303 - val_loss: 2.2006 - val_accuracy: 0.6880\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1894 - accuracy: 0.9389 - val_loss: 3.7825 - val_accuracy: 0.6413\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1956 - accuracy: 0.9349 - val_loss: 3.5367 - val_accuracy: 0.6560\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1646 - accuracy: 0.9457 - val_loss: 3.4543 - val_accuracy: 0.6813\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1698 - accuracy: 0.9440 - val_loss: 3.4085 - val_accuracy: 0.6867\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1747 - accuracy: 0.9469 - val_loss: 2.5211 - val_accuracy: 0.6933\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1915 - accuracy: 0.9417 - val_loss: 4.5451 - val_accuracy: 0.6653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1765 - accuracy: 0.9434 - val_loss: 1.5612 - val_accuracy: 0.7120\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2391 - accuracy: 0.9400 - val_loss: 1.0793 - val_accuracy: 0.6827\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1663 - accuracy: 0.9389 - val_loss: 1.1357 - val_accuracy: 0.6787\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1968 - accuracy: 0.9371 - val_loss: 1.0352 - val_accuracy: 0.7600\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1508 - accuracy: 0.9537 - val_loss: 1.2858 - val_accuracy: 0.6933\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1790 - accuracy: 0.9423 - val_loss: 1.6326 - val_accuracy: 0.7333\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1786 - accuracy: 0.9509 - val_loss: 3.5830 - val_accuracy: 0.7107\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1735 - accuracy: 0.9509 - val_loss: 3.9106 - val_accuracy: 0.7147\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1779 - accuracy: 0.9469 - val_loss: 1.6525 - val_accuracy: 0.7267\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1597 - accuracy: 0.9503 - val_loss: 1.0867 - val_accuracy: 0.7267\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1580 - accuracy: 0.9474 - val_loss: 0.8870 - val_accuracy: 0.7640\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1541 - accuracy: 0.9474 - val_loss: 0.9963 - val_accuracy: 0.7213\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1537 - accuracy: 0.9531 - val_loss: 1.0390 - val_accuracy: 0.7600\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1516 - accuracy: 0.9514 - val_loss: 0.9670 - val_accuracy: 0.7347\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1590 - accuracy: 0.9509 - val_loss: 0.7335 - val_accuracy: 0.7667\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1389 - accuracy: 0.9549 - val_loss: 0.7265 - val_accuracy: 0.7613\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1652 - accuracy: 0.9486 - val_loss: 0.9159 - val_accuracy: 0.7240\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1812 - accuracy: 0.9440 - val_loss: 0.7708 - val_accuracy: 0.7813\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1741 - accuracy: 0.9389 - val_loss: 0.8189 - val_accuracy: 0.7373\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1479 - accuracy: 0.9566 - val_loss: 0.8916 - val_accuracy: 0.7453\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1684 - accuracy: 0.9491 - val_loss: 0.8311 - val_accuracy: 0.7427\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1582 - accuracy: 0.9526 - val_loss: 0.6452 - val_accuracy: 0.7333\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.2230 - accuracy: 0.9469 - val_loss: 1.3709 - val_accuracy: 0.6947\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1531 - accuracy: 0.9509 - val_loss: 0.6495 - val_accuracy: 0.7613\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1419 - accuracy: 0.9571 - val_loss: 0.5951 - val_accuracy: 0.7747\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1681 - accuracy: 0.9526 - val_loss: 1.1045 - val_accuracy: 0.7147\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2107 - accuracy: 0.9440 - val_loss: 1.1501 - val_accuracy: 0.7120\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.2130 - accuracy: 0.9531 - val_loss: 0.4995 - val_accuracy: 0.7653\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 18s 161ms/step - loss: 0.1943 - accuracy: 0.9509 - val_loss: 0.7811 - val_accuracy: 0.7267\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1389 - accuracy: 0.9560 - val_loss: 0.7104 - val_accuracy: 0.7227\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1361 - accuracy: 0.9577 - val_loss: 0.7873 - val_accuracy: 0.7080\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1350 - accuracy: 0.9583 - val_loss: 0.7420 - val_accuracy: 0.7133\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1740 - accuracy: 0.9509 - val_loss: 0.9464 - val_accuracy: 0.6760\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1459 - accuracy: 0.9537 - val_loss: 10.1858 - val_accuracy: 0.7533\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1340 - accuracy: 0.9566 - val_loss: 0.8884 - val_accuracy: 0.7227\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1289 - accuracy: 0.9600 - val_loss: 0.8027 - val_accuracy: 0.7187\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1488 - accuracy: 0.9549 - val_loss: 0.7289 - val_accuracy: 0.7093\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1222 - accuracy: 0.9611 - val_loss: 0.7338 - val_accuracy: 0.7307\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1273 - accuracy: 0.9634 - val_loss: 0.8098 - val_accuracy: 0.7213\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1133 - accuracy: 0.9606 - val_loss: 0.7892 - val_accuracy: 0.7160\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1444 - accuracy: 0.9543 - val_loss: 0.5795 - val_accuracy: 0.7427\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1527 - accuracy: 0.9491 - val_loss: 0.6578 - val_accuracy: 0.7253\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1220 - accuracy: 0.9589 - val_loss: 0.5334 - val_accuracy: 0.7587\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1241 - accuracy: 0.9623 - val_loss: 0.6881 - val_accuracy: 0.7347\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1301 - accuracy: 0.9566 - val_loss: 0.8145 - val_accuracy: 0.7347\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1185 - accuracy: 0.9617 - val_loss: 0.6525 - val_accuracy: 0.7520\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1310 - accuracy: 0.9549 - val_loss: 0.6824 - val_accuracy: 0.7387\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1256 - accuracy: 0.9566 - val_loss: 0.7398 - val_accuracy: 0.7400\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1220 - accuracy: 0.9617 - val_loss: 0.9020 - val_accuracy: 0.7453\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1243 - accuracy: 0.9611 - val_loss: 0.5756 - val_accuracy: 0.7813\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1243 - accuracy: 0.9577 - val_loss: 0.8969 - val_accuracy: 0.7747\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1270 - accuracy: 0.9583 - val_loss: 0.8001 - val_accuracy: 0.7027\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1485 - accuracy: 0.9480 - val_loss: 0.6324 - val_accuracy: 0.7320\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1244 - accuracy: 0.9583 - val_loss: 0.5444 - val_accuracy: 0.7373\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1249 - accuracy: 0.9606 - val_loss: 0.6286 - val_accuracy: 0.7613\n",
      "Epoch 136/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1335 - accuracy: 0.9537 - val_loss: 0.5870 - val_accuracy: 0.7293\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1244 - accuracy: 0.9606 - val_loss: 0.8610 - val_accuracy: 0.7120\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1263 - accuracy: 0.9617 - val_loss: 0.5460 - val_accuracy: 0.7547\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1143 - accuracy: 0.9623 - val_loss: 0.4820 - val_accuracy: 0.7467\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1188 - accuracy: 0.9594 - val_loss: 0.6157 - val_accuracy: 0.7400\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1334 - accuracy: 0.9606 - val_loss: 0.4550 - val_accuracy: 0.7960\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1307 - accuracy: 0.9554 - val_loss: 1.6120 - val_accuracy: 0.7653\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1288 - accuracy: 0.9594 - val_loss: 0.6082 - val_accuracy: 0.7573\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1307 - accuracy: 0.9577 - val_loss: 0.7249 - val_accuracy: 0.7347\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1162 - accuracy: 0.9629 - val_loss: 0.7120 - val_accuracy: 0.7693\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1994 - accuracy: 0.9503 - val_loss: 0.4572 - val_accuracy: 0.7707\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1553 - accuracy: 0.9469 - val_loss: 0.4611 - val_accuracy: 0.7853\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1178 - accuracy: 0.9651 - val_loss: 0.5426 - val_accuracy: 0.7653\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1162 - accuracy: 0.9629 - val_loss: 0.6397 - val_accuracy: 0.7387\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1369 - accuracy: 0.9520 - val_loss: 0.4810 - val_accuracy: 0.7493\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1256 - accuracy: 0.9549 - val_loss: 0.5160 - val_accuracy: 0.7587\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1127 - accuracy: 0.9640 - val_loss: 0.5619 - val_accuracy: 0.7347\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1229 - accuracy: 0.9560 - val_loss: 0.5303 - val_accuracy: 0.7667\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 17s 157ms/step - loss: 0.1154 - accuracy: 0.9640 - val_loss: 0.4461 - val_accuracy: 0.7867\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1125 - accuracy: 0.9589 - val_loss: 0.5648 - val_accuracy: 0.7627\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1081 - accuracy: 0.9640 - val_loss: 0.6704 - val_accuracy: 0.7547\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1121 - accuracy: 0.9611 - val_loss: 0.5873 - val_accuracy: 0.7667\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0981 - accuracy: 0.9703 - val_loss: 0.5998 - val_accuracy: 0.7720\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1334 - accuracy: 0.9606 - val_loss: 0.5595 - val_accuracy: 0.7533\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1107 - accuracy: 0.9583 - val_loss: 0.4017 - val_accuracy: 0.8107\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1066 - accuracy: 0.9629 - val_loss: 0.5620 - val_accuracy: 0.7600\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1042 - accuracy: 0.9657 - val_loss: 0.5541 - val_accuracy: 0.7680\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1026 - accuracy: 0.9697 - val_loss: 0.5951 - val_accuracy: 0.7853\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1131 - accuracy: 0.9634 - val_loss: 0.6699 - val_accuracy: 0.7400\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1033 - accuracy: 0.9680 - val_loss: 0.6784 - val_accuracy: 0.7547\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1094 - accuracy: 0.9640 - val_loss: 0.6147 - val_accuracy: 0.7467\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1188 - accuracy: 0.9606 - val_loss: 0.5008 - val_accuracy: 0.7747\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1160 - accuracy: 0.9651 - val_loss: 0.4712 - val_accuracy: 0.7640\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1123 - accuracy: 0.9674 - val_loss: 0.4736 - val_accuracy: 0.8013\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1173 - accuracy: 0.9646 - val_loss: 0.6210 - val_accuracy: 0.7773\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1019 - accuracy: 0.9657 - val_loss: 0.6473 - val_accuracy: 0.7720\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0939 - accuracy: 0.9686 - val_loss: 0.5175 - val_accuracy: 0.8107\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1225 - accuracy: 0.9594 - val_loss: 0.5087 - val_accuracy: 0.7947\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1043 - accuracy: 0.9663 - val_loss: 0.4830 - val_accuracy: 0.8160\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1021 - accuracy: 0.9657 - val_loss: 0.4428 - val_accuracy: 0.8160\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1196 - accuracy: 0.9589 - val_loss: 0.6514 - val_accuracy: 0.7773\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.0950 - accuracy: 0.9691 - val_loss: 0.5461 - val_accuracy: 0.7920\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1041 - accuracy: 0.9697 - val_loss: 0.6259 - val_accuracy: 0.7773\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1115 - accuracy: 0.9674 - val_loss: 0.5462 - val_accuracy: 0.7960\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1116 - accuracy: 0.9657 - val_loss: 0.6045 - val_accuracy: 0.7773\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1271 - accuracy: 0.9571 - val_loss: 0.4705 - val_accuracy: 0.8067\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1013 - accuracy: 0.9657 - val_loss: 0.4854 - val_accuracy: 0.8040\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1038 - accuracy: 0.9669 - val_loss: 0.6635 - val_accuracy: 0.7653\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1270 - accuracy: 0.9634 - val_loss: 0.5991 - val_accuracy: 0.7680\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1023 - accuracy: 0.9674 - val_loss: 0.5172 - val_accuracy: 0.7947\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 17s 158ms/step - loss: 0.1089 - accuracy: 0.9651 - val_loss: 0.4748 - val_accuracy: 0.8053\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1012 - accuracy: 0.9691 - val_loss: 0.5327 - val_accuracy: 0.7947\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.1071 - accuracy: 0.9669 - val_loss: 0.6560 - val_accuracy: 0.7440\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0979 - accuracy: 0.9640 - val_loss: 0.5433 - val_accuracy: 0.7907\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0981 - accuracy: 0.9709 - val_loss: 0.5706 - val_accuracy: 0.7853\n",
      "Epoch 191/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0875 - accuracy: 0.9703 - val_loss: 0.6503 - val_accuracy: 0.7707\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1076 - accuracy: 0.9686 - val_loss: 0.7683 - val_accuracy: 0.7387\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 18s 162ms/step - loss: 0.1086 - accuracy: 0.9657 - val_loss: 0.6510 - val_accuracy: 0.7587\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1012 - accuracy: 0.9714 - val_loss: 0.4903 - val_accuracy: 0.7920\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0928 - accuracy: 0.9726 - val_loss: 0.7377 - val_accuracy: 0.7253\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 17s 159ms/step - loss: 0.1520 - accuracy: 0.9623 - val_loss: 0.7061 - val_accuracy: 0.7347\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1011 - accuracy: 0.9646 - val_loss: 0.5736 - val_accuracy: 0.7600\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.1040 - accuracy: 0.9663 - val_loss: 0.7146 - val_accuracy: 0.7493\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 18s 159ms/step - loss: 0.0972 - accuracy: 0.9680 - val_loss: 0.6688 - val_accuracy: 0.7547\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 18s 160ms/step - loss: 0.0848 - accuracy: 0.9749 - val_loss: 0.9342 - val_accuracy: 0.7493\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 5)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 49s - loss: 8.1952 - accuracy: 0.5000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0680s vs `on_train_batch_end` time: 0.7968s). Check your callbacks.\n",
      "110/110 [==============================] - 20s 181ms/step - loss: 1.3904 - accuracy: 0.7594 - val_loss: 1.4080 - val_accuracy: 0.3720\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.5759 - accuracy: 0.8154 - val_loss: 2.1463 - val_accuracy: 0.3787\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.4443 - accuracy: 0.8583 - val_loss: 0.9974 - val_accuracy: 0.6547\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.4095 - accuracy: 0.8469 - val_loss: 5.3249 - val_accuracy: 0.7133\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.3418 - accuracy: 0.8869 - val_loss: 1.6286 - val_accuracy: 0.7867\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2802 - accuracy: 0.9046 - val_loss: 0.7367 - val_accuracy: 0.8120\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2969 - accuracy: 0.9063 - val_loss: 0.5032 - val_accuracy: 0.7960\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2803 - accuracy: 0.9080 - val_loss: 0.4534 - val_accuracy: 0.8693\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.3230 - accuracy: 0.9091 - val_loss: 4.4344 - val_accuracy: 0.7667\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.3039 - accuracy: 0.9080 - val_loss: 5.8953 - val_accuracy: 0.8640\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.2711 - accuracy: 0.9183 - val_loss: 0.3140 - val_accuracy: 0.8640\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2245 - accuracy: 0.9206 - val_loss: 0.3956 - val_accuracy: 0.8293\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2484 - accuracy: 0.9320 - val_loss: 0.4006 - val_accuracy: 0.8320\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2020 - accuracy: 0.9389 - val_loss: 0.6286 - val_accuracy: 0.8320\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2154 - accuracy: 0.9366 - val_loss: 0.3313 - val_accuracy: 0.8973\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2312 - accuracy: 0.9406 - val_loss: 22.3326 - val_accuracy: 0.7640\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2420 - accuracy: 0.9377 - val_loss: 0.2682 - val_accuracy: 0.9040\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2626 - accuracy: 0.9429 - val_loss: 0.3697 - val_accuracy: 0.8493\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2282 - accuracy: 0.9354 - val_loss: 0.3969 - val_accuracy: 0.8360\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2019 - accuracy: 0.9451 - val_loss: 0.4822 - val_accuracy: 0.8533\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1825 - accuracy: 0.9520 - val_loss: 0.7137 - val_accuracy: 0.7880\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2197 - accuracy: 0.9509 - val_loss: 0.4121 - val_accuracy: 0.8413\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1973 - accuracy: 0.9451 - val_loss: 0.4004 - val_accuracy: 0.8587\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2079 - accuracy: 0.9486 - val_loss: 0.8296 - val_accuracy: 0.7853\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1964 - accuracy: 0.9417 - val_loss: 0.4356 - val_accuracy: 0.8680\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2032 - accuracy: 0.9423 - val_loss: 0.3066 - val_accuracy: 0.8733\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1570 - accuracy: 0.9566 - val_loss: 0.2587 - val_accuracy: 0.9027\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1634 - accuracy: 0.9520 - val_loss: 0.4586 - val_accuracy: 0.8120\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1904 - accuracy: 0.9497 - val_loss: 0.2130 - val_accuracy: 0.9093\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1950 - accuracy: 0.9383 - val_loss: 0.4982 - val_accuracy: 0.8120\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1552 - accuracy: 0.9577 - val_loss: 0.5135 - val_accuracy: 0.8173\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1438 - accuracy: 0.9583 - val_loss: 0.2658 - val_accuracy: 0.9227\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1808 - accuracy: 0.9503 - val_loss: 0.3569 - val_accuracy: 0.8533\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1502 - accuracy: 0.9531 - val_loss: 1.0247 - val_accuracy: 0.8707\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1425 - accuracy: 0.9554 - val_loss: 0.2773 - val_accuracy: 0.8920\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1632 - accuracy: 0.9560 - val_loss: 0.6988 - val_accuracy: 0.7800\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1394 - accuracy: 0.9634 - val_loss: 0.4767 - val_accuracy: 0.8333\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1380 - accuracy: 0.9594 - val_loss: 0.5087 - val_accuracy: 0.8253\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1218 - accuracy: 0.9629 - val_loss: 0.6984 - val_accuracy: 0.7787\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1538 - accuracy: 0.9514 - val_loss: 0.5072 - val_accuracy: 0.8427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1302 - accuracy: 0.9594 - val_loss: 0.5254 - val_accuracy: 0.8333\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1246 - accuracy: 0.9611 - val_loss: 0.4057 - val_accuracy: 0.8427\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1177 - accuracy: 0.9686 - val_loss: 0.8954 - val_accuracy: 0.7067\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1373 - accuracy: 0.9594 - val_loss: 0.6289 - val_accuracy: 0.7920\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1235 - accuracy: 0.9611 - val_loss: 0.4992 - val_accuracy: 0.7880\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1260 - accuracy: 0.9617 - val_loss: 0.4782 - val_accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1007 - accuracy: 0.9697 - val_loss: 0.4255 - val_accuracy: 0.8573\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1552 - accuracy: 0.9571 - val_loss: 0.3922 - val_accuracy: 0.8347\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1714 - accuracy: 0.9480 - val_loss: 0.3459 - val_accuracy: 0.8907\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1477 - accuracy: 0.9606 - val_loss: 0.2531 - val_accuracy: 0.9173\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 19s 168ms/step - loss: 0.1572 - accuracy: 0.9514 - val_loss: 0.2527 - val_accuracy: 0.9173\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1519 - accuracy: 0.9577 - val_loss: 0.2968 - val_accuracy: 0.9213\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1757 - accuracy: 0.9577 - val_loss: 0.3287 - val_accuracy: 0.8893\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1550 - accuracy: 0.9554 - val_loss: 0.2603 - val_accuracy: 0.9000\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1764 - accuracy: 0.9491 - val_loss: 0.2646 - val_accuracy: 0.8973\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1358 - accuracy: 0.9600 - val_loss: 0.3587 - val_accuracy: 0.8400\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1494 - accuracy: 0.9600 - val_loss: 0.2634 - val_accuracy: 0.9107\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1722 - accuracy: 0.9543 - val_loss: 0.2910 - val_accuracy: 0.8853\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1596 - accuracy: 0.9554 - val_loss: 0.3673 - val_accuracy: 0.8747\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1262 - accuracy: 0.9617 - val_loss: 0.3404 - val_accuracy: 0.8973\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.1319 - accuracy: 0.9589 - val_loss: 0.2995 - val_accuracy: 0.8973\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1264 - accuracy: 0.9623 - val_loss: 0.2755 - val_accuracy: 0.9040\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1376 - accuracy: 0.9623 - val_loss: 0.3381 - val_accuracy: 0.8987\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1363 - accuracy: 0.9571 - val_loss: 0.3089 - val_accuracy: 0.8960\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1285 - accuracy: 0.9583 - val_loss: 0.3873 - val_accuracy: 0.8747\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1284 - accuracy: 0.9623 - val_loss: 0.2790 - val_accuracy: 0.9000\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1120 - accuracy: 0.9657 - val_loss: 0.2973 - val_accuracy: 0.8893\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1087 - accuracy: 0.9674 - val_loss: 0.3085 - val_accuracy: 0.8920\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1175 - accuracy: 0.9663 - val_loss: 0.2762 - val_accuracy: 0.9027\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1149 - accuracy: 0.9634 - val_loss: 0.2551 - val_accuracy: 0.8960\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0923 - accuracy: 0.9720 - val_loss: 0.3315 - val_accuracy: 0.8920\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1010 - accuracy: 0.9697 - val_loss: 0.2886 - val_accuracy: 0.8973\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0996 - accuracy: 0.9714 - val_loss: 0.3252 - val_accuracy: 0.8973\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1154 - accuracy: 0.9669 - val_loss: 0.2923 - val_accuracy: 0.8867\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1129 - accuracy: 0.9674 - val_loss: 0.3385 - val_accuracy: 0.9000\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1959 - accuracy: 0.9429 - val_loss: 0.5185 - val_accuracy: 0.8560\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1414 - accuracy: 0.9617 - val_loss: 0.3475 - val_accuracy: 0.8680\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1322 - accuracy: 0.9583 - val_loss: 0.3456 - val_accuracy: 0.8680\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1483 - accuracy: 0.9566 - val_loss: 0.3248 - val_accuracy: 0.8880\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1316 - accuracy: 0.9560 - val_loss: 0.3750 - val_accuracy: 0.8707\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0975 - accuracy: 0.9686 - val_loss: 0.3097 - val_accuracy: 0.8933\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1227 - accuracy: 0.9606 - val_loss: 0.2558 - val_accuracy: 0.9013\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1103 - accuracy: 0.9674 - val_loss: 0.3446 - val_accuracy: 0.8880\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1097 - accuracy: 0.9663 - val_loss: 0.3194 - val_accuracy: 0.8893\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1248 - accuracy: 0.9663 - val_loss: 0.4849 - val_accuracy: 0.8600\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1314 - accuracy: 0.9651 - val_loss: 0.3317 - val_accuracy: 0.9027\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1094 - accuracy: 0.9663 - val_loss: 0.3403 - val_accuracy: 0.8933\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1223 - accuracy: 0.9669 - val_loss: 0.2473 - val_accuracy: 0.9053\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1057 - accuracy: 0.9714 - val_loss: 0.3149 - val_accuracy: 0.9080\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1007 - accuracy: 0.9697 - val_loss: 0.2712 - val_accuracy: 0.8973\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.1102 - accuracy: 0.9674 - val_loss: 0.5069 - val_accuracy: 0.7853\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1034 - accuracy: 0.9657 - val_loss: 0.4298 - val_accuracy: 0.8680\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0986 - accuracy: 0.9743 - val_loss: 0.3054 - val_accuracy: 0.9013\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1085 - accuracy: 0.9680 - val_loss: 0.6478 - val_accuracy: 0.7867\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0905 - accuracy: 0.9766 - val_loss: 0.2720 - val_accuracy: 0.9173\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0985 - accuracy: 0.9680 - val_loss: 0.3998 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1031 - accuracy: 0.9726 - val_loss: 0.2863 - val_accuracy: 0.9133\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0847 - accuracy: 0.9731 - val_loss: 0.4984 - val_accuracy: 0.8453\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0954 - accuracy: 0.9726 - val_loss: 0.4420 - val_accuracy: 0.8453\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1090 - accuracy: 0.9680 - val_loss: 0.3468 - val_accuracy: 0.9080\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0928 - accuracy: 0.9743 - val_loss: 0.3149 - val_accuracy: 0.8813\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0979 - accuracy: 0.9726 - val_loss: 0.5074 - val_accuracy: 0.8400\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0920 - accuracy: 0.9754 - val_loss: 0.4721 - val_accuracy: 0.8440\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0866 - accuracy: 0.9777 - val_loss: 0.3685 - val_accuracy: 0.8893\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0918 - accuracy: 0.9731 - val_loss: 0.5584 - val_accuracy: 0.8547\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1215 - accuracy: 0.9634 - val_loss: 0.2324 - val_accuracy: 0.9187\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0991 - accuracy: 0.9674 - val_loss: 0.4827 - val_accuracy: 0.8373\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0972 - accuracy: 0.9754 - val_loss: 0.3555 - val_accuracy: 0.8693\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0787 - accuracy: 0.9794 - val_loss: 0.4275 - val_accuracy: 0.8733\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0916 - accuracy: 0.9754 - val_loss: 0.4768 - val_accuracy: 0.8413\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 19s 168ms/step - loss: 0.0949 - accuracy: 0.9749 - val_loss: 0.3992 - val_accuracy: 0.8373\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0954 - accuracy: 0.9731 - val_loss: 0.3679 - val_accuracy: 0.8733\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0980 - accuracy: 0.9731 - val_loss: 0.3111 - val_accuracy: 0.8867\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0843 - accuracy: 0.9771 - val_loss: 0.4272 - val_accuracy: 0.8693\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0922 - accuracy: 0.9754 - val_loss: 0.9265 - val_accuracy: 0.7240\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0867 - accuracy: 0.9783 - val_loss: 0.4232 - val_accuracy: 0.8787\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0798 - accuracy: 0.9771 - val_loss: 0.3251 - val_accuracy: 0.8787\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0900 - accuracy: 0.9766 - val_loss: 0.5510 - val_accuracy: 0.8173\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0966 - accuracy: 0.9720 - val_loss: 0.4624 - val_accuracy: 0.8560\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0902 - accuracy: 0.9743 - val_loss: 0.4028 - val_accuracy: 0.8680\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.0860 - accuracy: 0.9749 - val_loss: 0.5201 - val_accuracy: 0.8320\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0838 - accuracy: 0.9789 - val_loss: 0.3891 - val_accuracy: 0.8587\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0818 - accuracy: 0.9760 - val_loss: 0.3582 - val_accuracy: 0.8613\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0916 - accuracy: 0.9760 - val_loss: 0.2963 - val_accuracy: 0.8987\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0908 - accuracy: 0.9731 - val_loss: 0.2778 - val_accuracy: 0.9120\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0721 - accuracy: 0.9771 - val_loss: 0.2935 - val_accuracy: 0.8987\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0705 - accuracy: 0.9806 - val_loss: 0.4369 - val_accuracy: 0.8773\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0927 - accuracy: 0.9743 - val_loss: 0.8131 - val_accuracy: 0.7093\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1040 - accuracy: 0.9754 - val_loss: 0.5422 - val_accuracy: 0.7840\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1333 - accuracy: 0.9640 - val_loss: 0.2469 - val_accuracy: 0.9267\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1011 - accuracy: 0.9703 - val_loss: 0.3454 - val_accuracy: 0.8827\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0879 - accuracy: 0.9743 - val_loss: 0.3015 - val_accuracy: 0.8907\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0843 - accuracy: 0.9766 - val_loss: 0.6831 - val_accuracy: 0.8133\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0956 - accuracy: 0.9726 - val_loss: 0.3967 - val_accuracy: 0.8573\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0790 - accuracy: 0.9771 - val_loss: 0.2842 - val_accuracy: 0.8987\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0817 - accuracy: 0.9789 - val_loss: 0.3661 - val_accuracy: 0.8800\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0840 - accuracy: 0.9737 - val_loss: 0.5461 - val_accuracy: 0.8453\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0880 - accuracy: 0.9749 - val_loss: 0.4375 - val_accuracy: 0.8627\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0750 - accuracy: 0.9789 - val_loss: 0.8432 - val_accuracy: 0.6760\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0855 - accuracy: 0.9771 - val_loss: 0.3905 - val_accuracy: 0.8440\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.1022 - accuracy: 0.9680 - val_loss: 0.4211 - val_accuracy: 0.8600\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0852 - accuracy: 0.9754 - val_loss: 0.2714 - val_accuracy: 0.9040\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0677 - accuracy: 0.9800 - val_loss: 0.2872 - val_accuracy: 0.8947\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0728 - accuracy: 0.9766 - val_loss: 0.4247 - val_accuracy: 0.8640\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0742 - accuracy: 0.9737 - val_loss: 0.2846 - val_accuracy: 0.9173\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1236 - accuracy: 0.9686 - val_loss: 0.2540 - val_accuracy: 0.9160\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0704 - accuracy: 0.9777 - val_loss: 0.3390 - val_accuracy: 0.8787\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0646 - accuracy: 0.9783 - val_loss: 0.4412 - val_accuracy: 0.8573\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0734 - accuracy: 0.9789 - val_loss: 0.6986 - val_accuracy: 0.7867\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0719 - accuracy: 0.9817 - val_loss: 0.4088 - val_accuracy: 0.8640\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.0712 - accuracy: 0.9800 - val_loss: 0.3693 - val_accuracy: 0.8693\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0620 - accuracy: 0.9823 - val_loss: 0.4494 - val_accuracy: 0.8613\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0708 - accuracy: 0.9789 - val_loss: 0.4761 - val_accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0836 - accuracy: 0.9720 - val_loss: 0.3682 - val_accuracy: 0.8733\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0890 - accuracy: 0.9789 - val_loss: 0.1491 - val_accuracy: 0.9373\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1238 - accuracy: 0.9640 - val_loss: 0.3398 - val_accuracy: 0.8867\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1046 - accuracy: 0.9720 - val_loss: 0.3672 - val_accuracy: 0.8893\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0994 - accuracy: 0.9714 - val_loss: 0.2841 - val_accuracy: 0.9040\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0997 - accuracy: 0.9669 - val_loss: 0.3005 - val_accuracy: 0.8840\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0805 - accuracy: 0.9749 - val_loss: 0.6035 - val_accuracy: 0.8173\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 19s 170ms/step - loss: 0.0894 - accuracy: 0.9754 - val_loss: 0.4078 - val_accuracy: 0.8693\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0836 - accuracy: 0.9771 - val_loss: 0.4422 - val_accuracy: 0.8667\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0681 - accuracy: 0.9789 - val_loss: 0.5581 - val_accuracy: 0.7933\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0716 - accuracy: 0.9811 - val_loss: 0.4301 - val_accuracy: 0.8760\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0818 - accuracy: 0.9731 - val_loss: 0.5620 - val_accuracy: 0.8293\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0703 - accuracy: 0.9777 - val_loss: 0.4570 - val_accuracy: 0.8453\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0642 - accuracy: 0.9823 - val_loss: 0.3504 - val_accuracy: 0.8787\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0742 - accuracy: 0.9771 - val_loss: 0.3075 - val_accuracy: 0.8893\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0649 - accuracy: 0.9777 - val_loss: 0.3925 - val_accuracy: 0.8867\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0757 - accuracy: 0.9771 - val_loss: 0.6386 - val_accuracy: 0.8413\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0814 - accuracy: 0.9771 - val_loss: 0.3860 - val_accuracy: 0.8787\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0567 - accuracy: 0.9857 - val_loss: 0.5208 - val_accuracy: 0.8307\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0621 - accuracy: 0.9834 - val_loss: 0.3119 - val_accuracy: 0.8867\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0636 - accuracy: 0.9846 - val_loss: 0.3937 - val_accuracy: 0.8613\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0864 - accuracy: 0.9749 - val_loss: 0.3161 - val_accuracy: 0.9053\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0867 - accuracy: 0.9714 - val_loss: 0.4547 - val_accuracy: 0.8387\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0693 - accuracy: 0.9789 - val_loss: 0.3805 - val_accuracy: 0.8947\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0694 - accuracy: 0.9829 - val_loss: 0.2812 - val_accuracy: 0.9133\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0597 - accuracy: 0.9880 - val_loss: 0.3578 - val_accuracy: 0.8960\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0642 - accuracy: 0.9806 - val_loss: 0.3360 - val_accuracy: 0.8947\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.0528 - accuracy: 0.9829 - val_loss: 0.3610 - val_accuracy: 0.8853\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0643 - accuracy: 0.9851 - val_loss: 0.3250 - val_accuracy: 0.8920\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0664 - accuracy: 0.9806 - val_loss: 0.5026 - val_accuracy: 0.8333\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0622 - accuracy: 0.9834 - val_loss: 0.7213 - val_accuracy: 0.8200\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0652 - accuracy: 0.9823 - val_loss: 0.2900 - val_accuracy: 0.8987\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0695 - accuracy: 0.9800 - val_loss: 0.2665 - val_accuracy: 0.9040\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0575 - accuracy: 0.9800 - val_loss: 0.4650 - val_accuracy: 0.8520\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0698 - accuracy: 0.9806 - val_loss: 0.3452 - val_accuracy: 0.8853\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0704 - accuracy: 0.9789 - val_loss: 0.4540 - val_accuracy: 0.8733\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0708 - accuracy: 0.9811 - val_loss: 0.2653 - val_accuracy: 0.9040\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0642 - accuracy: 0.9857 - val_loss: 0.5833 - val_accuracy: 0.8413\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0669 - accuracy: 0.9794 - val_loss: 0.4109 - val_accuracy: 0.8973\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0536 - accuracy: 0.9869 - val_loss: 0.5002 - val_accuracy: 0.8667\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0614 - accuracy: 0.9823 - val_loss: 0.4023 - val_accuracy: 0.8787\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0708 - accuracy: 0.9829 - val_loss: 0.2687 - val_accuracy: 0.9253\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0749 - accuracy: 0.9783 - val_loss: 0.3424 - val_accuracy: 0.8907\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0610 - accuracy: 0.9794 - val_loss: 0.3457 - val_accuracy: 0.8933\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0631 - accuracy: 0.9811 - val_loss: 0.2909 - val_accuracy: 0.9107\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0644 - accuracy: 0.9811 - val_loss: 0.4181 - val_accuracy: 0.8547\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0528 - accuracy: 0.9851 - val_loss: 0.4467 - val_accuracy: 0.8747\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 5)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 50s - loss: 1.4133 - accuracy: 0.6562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0709s vs `on_train_batch_end` time: 0.7968s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 20s 182ms/step - loss: 0.9944 - accuracy: 0.7474 - val_loss: 3.5313 - val_accuracy: 0.3720\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.8826 - accuracy: 0.7869 - val_loss: 0.6434 - val_accuracy: 0.6080\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.5498 - accuracy: 0.8143 - val_loss: 1.4141 - val_accuracy: 0.4987\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.6888 - accuracy: 0.8023 - val_loss: 1.1126 - val_accuracy: 0.7160\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.6011 - accuracy: 0.8183 - val_loss: 0.5984 - val_accuracy: 0.7893\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.4647 - accuracy: 0.8514 - val_loss: 0.9067 - val_accuracy: 0.7200\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.5119 - accuracy: 0.8394 - val_loss: 0.6652 - val_accuracy: 0.7547\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.3548 - accuracy: 0.8760 - val_loss: 0.4755 - val_accuracy: 0.8053\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.3688 - accuracy: 0.8880 - val_loss: 0.8324 - val_accuracy: 0.7280\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2714 - accuracy: 0.9074 - val_loss: 0.6001 - val_accuracy: 0.7893\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.4019 - accuracy: 0.8823 - val_loss: 0.5988 - val_accuracy: 0.8693\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2930 - accuracy: 0.9183 - val_loss: 4.3004 - val_accuracy: 0.8720\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2445 - accuracy: 0.9189 - val_loss: 1.1386 - val_accuracy: 0.8533\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2962 - accuracy: 0.9206 - val_loss: 0.7100 - val_accuracy: 0.7040\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2508 - accuracy: 0.9149 - val_loss: 0.6347 - val_accuracy: 0.8253\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2123 - accuracy: 0.9291 - val_loss: 0.3816 - val_accuracy: 0.8493\n",
      "Epoch 17/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1879 - accuracy: 0.9457 - val_loss: 0.4919 - val_accuracy: 0.8093\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2226 - accuracy: 0.9349 - val_loss: 0.4616 - val_accuracy: 0.8440\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2417 - accuracy: 0.9326 - val_loss: 0.4559 - val_accuracy: 0.8280\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2667 - accuracy: 0.9326 - val_loss: 0.4010 - val_accuracy: 0.8587\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.2070 - accuracy: 0.9337 - val_loss: 0.3613 - val_accuracy: 0.8547\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2060 - accuracy: 0.9394 - val_loss: 0.3514 - val_accuracy: 0.8520\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1810 - accuracy: 0.9429 - val_loss: 0.3868 - val_accuracy: 0.8293\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1638 - accuracy: 0.9474 - val_loss: 0.3198 - val_accuracy: 0.8813\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1734 - accuracy: 0.9463 - val_loss: 0.4173 - val_accuracy: 0.8453\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1538 - accuracy: 0.9503 - val_loss: 0.4534 - val_accuracy: 0.8280\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1474 - accuracy: 0.9514 - val_loss: 0.5612 - val_accuracy: 0.8000\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1509 - accuracy: 0.9549 - val_loss: 0.3179 - val_accuracy: 0.8720\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1728 - accuracy: 0.9434 - val_loss: 0.3482 - val_accuracy: 0.8547\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1587 - accuracy: 0.9509 - val_loss: 0.3863 - val_accuracy: 0.8653\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.1871 - accuracy: 0.9560 - val_loss: 0.3740 - val_accuracy: 0.8707\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1648 - accuracy: 0.9526 - val_loss: 0.3110 - val_accuracy: 0.8813\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1499 - accuracy: 0.9611 - val_loss: 0.3705 - val_accuracy: 0.8480\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1719 - accuracy: 0.9560 - val_loss: 0.3355 - val_accuracy: 0.8853\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1206 - accuracy: 0.9646 - val_loss: 0.4622 - val_accuracy: 0.8733\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1404 - accuracy: 0.9571 - val_loss: 0.4274 - val_accuracy: 0.8707\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1180 - accuracy: 0.9663 - val_loss: 0.3571 - val_accuracy: 0.8747\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1375 - accuracy: 0.9577 - val_loss: 0.7475 - val_accuracy: 0.8147\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1322 - accuracy: 0.9531 - val_loss: 0.4869 - val_accuracy: 0.8333\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1189 - accuracy: 0.9617 - val_loss: 0.5555 - val_accuracy: 0.8413\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 19s 170ms/step - loss: 0.1729 - accuracy: 0.9537 - val_loss: 0.3573 - val_accuracy: 0.8587\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1389 - accuracy: 0.9606 - val_loss: 0.4337 - val_accuracy: 0.8453\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1222 - accuracy: 0.9669 - val_loss: 0.4548 - val_accuracy: 0.8520\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1346 - accuracy: 0.9577 - val_loss: 0.5368 - val_accuracy: 0.8373\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1080 - accuracy: 0.9691 - val_loss: 0.4797 - val_accuracy: 0.8613\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1303 - accuracy: 0.9600 - val_loss: 0.5174 - val_accuracy: 0.8160\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1116 - accuracy: 0.9669 - val_loss: 0.3912 - val_accuracy: 0.8693\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1227 - accuracy: 0.9646 - val_loss: 0.5476 - val_accuracy: 0.8240\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1276 - accuracy: 0.9646 - val_loss: 0.3398 - val_accuracy: 0.8867\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1082 - accuracy: 0.9657 - val_loss: 0.5606 - val_accuracy: 0.8280\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 19s 168ms/step - loss: 0.1119 - accuracy: 0.9669 - val_loss: 0.7166 - val_accuracy: 0.8120\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1045 - accuracy: 0.9686 - val_loss: 0.5047 - val_accuracy: 0.8373\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1043 - accuracy: 0.9726 - val_loss: 0.3379 - val_accuracy: 0.8720\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0990 - accuracy: 0.9726 - val_loss: 0.3441 - val_accuracy: 0.8627\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0973 - accuracy: 0.9714 - val_loss: 0.5615 - val_accuracy: 0.8413\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0927 - accuracy: 0.9720 - val_loss: 0.4967 - val_accuracy: 0.8507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1234 - accuracy: 0.9617 - val_loss: 0.5778 - val_accuracy: 0.7920\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1088 - accuracy: 0.9714 - val_loss: 0.2739 - val_accuracy: 0.9040\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1355 - accuracy: 0.9697 - val_loss: 4.5610 - val_accuracy: 0.8947\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1201 - accuracy: 0.9680 - val_loss: 0.3471 - val_accuracy: 0.8747\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1235 - accuracy: 0.9617 - val_loss: 0.4418 - val_accuracy: 0.8187\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1047 - accuracy: 0.9714 - val_loss: 0.4002 - val_accuracy: 0.8360\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1330 - accuracy: 0.9640 - val_loss: 0.7104 - val_accuracy: 0.7760\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1189 - accuracy: 0.9663 - val_loss: 0.4188 - val_accuracy: 0.8480\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1156 - accuracy: 0.9663 - val_loss: 0.4272 - val_accuracy: 0.8547\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1133 - accuracy: 0.9697 - val_loss: 0.5107 - val_accuracy: 0.8613\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0958 - accuracy: 0.9686 - val_loss: 0.6838 - val_accuracy: 0.7973\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1017 - accuracy: 0.9674 - val_loss: 0.3434 - val_accuracy: 0.8680\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1539 - accuracy: 0.9703 - val_loss: 0.4384 - val_accuracy: 0.8267\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1010 - accuracy: 0.9731 - val_loss: 0.7153 - val_accuracy: 0.7827\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.1467 - accuracy: 0.9617 - val_loss: 0.5032 - val_accuracy: 0.8080\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1113 - accuracy: 0.9691 - val_loss: 0.3763 - val_accuracy: 0.8747\n",
      "Epoch 73/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1582 - accuracy: 0.9617 - val_loss: 0.4382 - val_accuracy: 0.8120\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1619 - accuracy: 0.9594 - val_loss: 0.5302 - val_accuracy: 0.8133\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1231 - accuracy: 0.9600 - val_loss: 0.4179 - val_accuracy: 0.8640\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1197 - accuracy: 0.9669 - val_loss: 0.4633 - val_accuracy: 0.8427\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0984 - accuracy: 0.9726 - val_loss: 0.7072 - val_accuracy: 0.8093\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1045 - accuracy: 0.9697 - val_loss: 0.4102 - val_accuracy: 0.8293\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0938 - accuracy: 0.9743 - val_loss: 0.5247 - val_accuracy: 0.8293\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0958 - accuracy: 0.9674 - val_loss: 0.5404 - val_accuracy: 0.8360\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0971 - accuracy: 0.9731 - val_loss: 0.4891 - val_accuracy: 0.8307\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0846 - accuracy: 0.9737 - val_loss: 0.6149 - val_accuracy: 0.7787\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0681 - accuracy: 0.9806 - val_loss: 0.6193 - val_accuracy: 0.7507\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0797 - accuracy: 0.9766 - val_loss: 0.4270 - val_accuracy: 0.8213\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0810 - accuracy: 0.9766 - val_loss: 1.2184 - val_accuracy: 0.6840\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0947 - accuracy: 0.9703 - val_loss: 0.7983 - val_accuracy: 0.7533\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0871 - accuracy: 0.9731 - val_loss: 0.5654 - val_accuracy: 0.8267\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1084 - accuracy: 0.9657 - val_loss: 0.5131 - val_accuracy: 0.7973\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0875 - accuracy: 0.9737 - val_loss: 0.6420 - val_accuracy: 0.8053\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0806 - accuracy: 0.9749 - val_loss: 0.5968 - val_accuracy: 0.8053\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.0757 - accuracy: 0.9789 - val_loss: 0.4806 - val_accuracy: 0.8533\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0851 - accuracy: 0.9737 - val_loss: 0.6826 - val_accuracy: 0.7733\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1061 - accuracy: 0.9714 - val_loss: 0.3171 - val_accuracy: 0.9000\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1188 - accuracy: 0.9623 - val_loss: 0.2614 - val_accuracy: 0.9067\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0877 - accuracy: 0.9743 - val_loss: 0.2696 - val_accuracy: 0.9027\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0885 - accuracy: 0.9720 - val_loss: 0.3909 - val_accuracy: 0.8493\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0794 - accuracy: 0.9783 - val_loss: 0.7296 - val_accuracy: 0.7787\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0876 - accuracy: 0.9749 - val_loss: 0.6454 - val_accuracy: 0.7733\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0786 - accuracy: 0.9771 - val_loss: 0.4852 - val_accuracy: 0.8173\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0743 - accuracy: 0.9806 - val_loss: 0.3918 - val_accuracy: 0.8600\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.0845 - accuracy: 0.9777 - val_loss: 0.6253 - val_accuracy: 0.8133\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0750 - accuracy: 0.9760 - val_loss: 0.6055 - val_accuracy: 0.8013\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0794 - accuracy: 0.9783 - val_loss: 0.4692 - val_accuracy: 0.8520\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0788 - accuracy: 0.9771 - val_loss: 0.6488 - val_accuracy: 0.8173\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0959 - accuracy: 0.9703 - val_loss: 0.4284 - val_accuracy: 0.8453\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0751 - accuracy: 0.9766 - val_loss: 0.5629 - val_accuracy: 0.7960\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0710 - accuracy: 0.9783 - val_loss: 0.5671 - val_accuracy: 0.8280\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0803 - accuracy: 0.9789 - val_loss: 0.6572 - val_accuracy: 0.7840\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0803 - accuracy: 0.9749 - val_loss: 0.5117 - val_accuracy: 0.8373\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0751 - accuracy: 0.9760 - val_loss: 0.6343 - val_accuracy: 0.7627\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 19s 168ms/step - loss: 0.0804 - accuracy: 0.9777 - val_loss: 0.6171 - val_accuracy: 0.8227\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0759 - accuracy: 0.9800 - val_loss: 0.5547 - val_accuracy: 0.8293\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0743 - accuracy: 0.9783 - val_loss: 0.5062 - val_accuracy: 0.8360\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0788 - accuracy: 0.9754 - val_loss: 0.8941 - val_accuracy: 0.7480\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0837 - accuracy: 0.9766 - val_loss: 0.4774 - val_accuracy: 0.8240\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0617 - accuracy: 0.9829 - val_loss: 0.4238 - val_accuracy: 0.8467\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0714 - accuracy: 0.9777 - val_loss: 0.5562 - val_accuracy: 0.8107\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0810 - accuracy: 0.9777 - val_loss: 0.6358 - val_accuracy: 0.7827\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0830 - accuracy: 0.9726 - val_loss: 0.5851 - val_accuracy: 0.8160\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0717 - accuracy: 0.9789 - val_loss: 0.6155 - val_accuracy: 0.8093\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.0888 - accuracy: 0.9731 - val_loss: 0.4042 - val_accuracy: 0.8573\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0737 - accuracy: 0.9766 - val_loss: 0.7993 - val_accuracy: 0.7440\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0777 - accuracy: 0.9789 - val_loss: 0.7591 - val_accuracy: 0.7373\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0704 - accuracy: 0.9789 - val_loss: 0.9374 - val_accuracy: 0.7320\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0720 - accuracy: 0.9806 - val_loss: 0.6934 - val_accuracy: 0.7693\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0777 - accuracy: 0.9789 - val_loss: 0.7290 - val_accuracy: 0.7707\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0688 - accuracy: 0.9800 - val_loss: 0.5156 - val_accuracy: 0.7867\n",
      "Epoch 128/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0914 - accuracy: 0.9737 - val_loss: 0.4384 - val_accuracy: 0.8467\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0896 - accuracy: 0.9726 - val_loss: 0.6066 - val_accuracy: 0.7813\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0777 - accuracy: 0.9777 - val_loss: 0.6056 - val_accuracy: 0.7747\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.0612 - accuracy: 0.9817 - val_loss: 0.5398 - val_accuracy: 0.8253\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0828 - accuracy: 0.9766 - val_loss: 0.7966 - val_accuracy: 0.7493\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0729 - accuracy: 0.9811 - val_loss: 0.9306 - val_accuracy: 0.7240\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0624 - accuracy: 0.9817 - val_loss: 0.9123 - val_accuracy: 0.7080\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1009 - accuracy: 0.9720 - val_loss: 0.4580 - val_accuracy: 0.8493\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0793 - accuracy: 0.9766 - val_loss: 0.7427 - val_accuracy: 0.8253\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0860 - accuracy: 0.9720 - val_loss: 0.5368 - val_accuracy: 0.8533\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0880 - accuracy: 0.9749 - val_loss: 0.7403 - val_accuracy: 0.8280\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0662 - accuracy: 0.9823 - val_loss: 0.7316 - val_accuracy: 0.8160\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0835 - accuracy: 0.9743 - val_loss: 0.6044 - val_accuracy: 0.8213\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 19s 170ms/step - loss: 0.0730 - accuracy: 0.9794 - val_loss: 0.6063 - val_accuracy: 0.8187\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0671 - accuracy: 0.9777 - val_loss: 0.7155 - val_accuracy: 0.7840\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0558 - accuracy: 0.9823 - val_loss: 0.7274 - val_accuracy: 0.8200\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0598 - accuracy: 0.9794 - val_loss: 0.7407 - val_accuracy: 0.8227\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0633 - accuracy: 0.9829 - val_loss: 0.6426 - val_accuracy: 0.8480\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0695 - accuracy: 0.9794 - val_loss: 0.6027 - val_accuracy: 0.8400\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0618 - accuracy: 0.9806 - val_loss: 0.6740 - val_accuracy: 0.8440\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0628 - accuracy: 0.9783 - val_loss: 0.6325 - val_accuracy: 0.8240\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0584 - accuracy: 0.9840 - val_loss: 0.7481 - val_accuracy: 0.8107\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0728 - accuracy: 0.9760 - val_loss: 0.5912 - val_accuracy: 0.8360\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.0556 - accuracy: 0.9817 - val_loss: 0.5081 - val_accuracy: 0.8560\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0590 - accuracy: 0.9800 - val_loss: 0.8376 - val_accuracy: 0.7560\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0568 - accuracy: 0.9840 - val_loss: 0.6154 - val_accuracy: 0.8360\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0799 - accuracy: 0.9743 - val_loss: 0.3596 - val_accuracy: 0.8800\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0566 - accuracy: 0.9829 - val_loss: 0.4846 - val_accuracy: 0.8467\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0626 - accuracy: 0.9817 - val_loss: 0.6253 - val_accuracy: 0.8000\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0700 - accuracy: 0.9789 - val_loss: 0.6201 - val_accuracy: 0.8387\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0677 - accuracy: 0.9794 - val_loss: 0.7133 - val_accuracy: 0.7947\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0632 - accuracy: 0.9834 - val_loss: 0.6393 - val_accuracy: 0.8080\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0572 - accuracy: 0.9834 - val_loss: 1.0419 - val_accuracy: 0.7253\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.0733 - accuracy: 0.9811 - val_loss: 0.4150 - val_accuracy: 0.8480\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0600 - accuracy: 0.9823 - val_loss: 0.5170 - val_accuracy: 0.8227\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0544 - accuracy: 0.9846 - val_loss: 0.6375 - val_accuracy: 0.8053\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0741 - accuracy: 0.9817 - val_loss: 0.7265 - val_accuracy: 0.7653\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0557 - accuracy: 0.9811 - val_loss: 0.6761 - val_accuracy: 0.7733\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0651 - accuracy: 0.9794 - val_loss: 0.9229 - val_accuracy: 0.7533\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0671 - accuracy: 0.9806 - val_loss: 0.8108 - val_accuracy: 0.7813\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0629 - accuracy: 0.9817 - val_loss: 0.2096 - val_accuracy: 0.9227\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0724 - accuracy: 0.9800 - val_loss: 0.8728 - val_accuracy: 0.7600\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0662 - accuracy: 0.9800 - val_loss: 0.6646 - val_accuracy: 0.7893\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.0723 - accuracy: 0.9789 - val_loss: 0.5236 - val_accuracy: 0.8093\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0590 - accuracy: 0.9840 - val_loss: 0.6658 - val_accuracy: 0.8213\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0669 - accuracy: 0.9800 - val_loss: 0.8848 - val_accuracy: 0.7667\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0606 - accuracy: 0.9829 - val_loss: 0.9160 - val_accuracy: 0.7640\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0787 - accuracy: 0.9777 - val_loss: 0.7202 - val_accuracy: 0.7600\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0588 - accuracy: 0.9834 - val_loss: 0.7037 - val_accuracy: 0.7693\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0666 - accuracy: 0.9806 - val_loss: 0.6096 - val_accuracy: 0.8253\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0578 - accuracy: 0.9840 - val_loss: 0.8218 - val_accuracy: 0.7627\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0660 - accuracy: 0.9806 - val_loss: 0.7085 - val_accuracy: 0.7733\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0567 - accuracy: 0.9846 - val_loss: 0.9576 - val_accuracy: 0.7240\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 19s 169ms/step - loss: 0.0560 - accuracy: 0.9823 - val_loss: 0.7452 - val_accuracy: 0.7533\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0612 - accuracy: 0.9811 - val_loss: 0.5585 - val_accuracy: 0.8027\n",
      "Epoch 183/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0592 - accuracy: 0.9834 - val_loss: 0.8693 - val_accuracy: 0.7533\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0628 - accuracy: 0.9823 - val_loss: 0.4061 - val_accuracy: 0.8613\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0672 - accuracy: 0.9783 - val_loss: 0.6106 - val_accuracy: 0.8067\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0637 - accuracy: 0.9811 - val_loss: 0.7059 - val_accuracy: 0.8027\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0561 - accuracy: 0.9829 - val_loss: 0.5120 - val_accuracy: 0.8347\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0560 - accuracy: 0.9817 - val_loss: 0.3992 - val_accuracy: 0.8667\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0623 - accuracy: 0.9817 - val_loss: 0.3308 - val_accuracy: 0.8773\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0799 - accuracy: 0.9817 - val_loss: 0.5559 - val_accuracy: 0.8453\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 19s 168ms/step - loss: 0.1002 - accuracy: 0.9749 - val_loss: 0.4434 - val_accuracy: 0.8333\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0757 - accuracy: 0.9811 - val_loss: 0.3685 - val_accuracy: 0.8707\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0784 - accuracy: 0.9766 - val_loss: 0.6507 - val_accuracy: 0.7947\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0763 - accuracy: 0.9789 - val_loss: 0.4831 - val_accuracy: 0.8427\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0584 - accuracy: 0.9811 - val_loss: 0.6850 - val_accuracy: 0.8267\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0636 - accuracy: 0.9840 - val_loss: 0.6269 - val_accuracy: 0.8160\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0608 - accuracy: 0.9829 - val_loss: 0.2979 - val_accuracy: 0.8853\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0564 - accuracy: 0.9851 - val_loss: 0.5008 - val_accuracy: 0.8493\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0453 - accuracy: 0.9874 - val_loss: 0.6636 - val_accuracy: 0.8293\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0620 - accuracy: 0.9851 - val_loss: 0.4913 - val_accuracy: 0.8480\n",
      "Verification OK. All 2500 image tile UIDs match.\n",
      "Loaded 0 images\n",
      "Loaded 100 images\n",
      "Loaded 200 images\n",
      "Loaded 300 images\n",
      "Loaded 400 images\n",
      "Loaded 500 images\n",
      "Loaded 600 images\n",
      "Loaded 700 images\n",
      "Loaded 800 images\n",
      "Loaded 900 images\n",
      "Loaded 1000 images\n",
      "Loaded 1100 images\n",
      "Loaded 1200 images\n",
      "Loaded 1300 images\n",
      "Loaded 1400 images\n",
      "Loaded 1500 images\n",
      "Loaded 1600 images\n",
      "Loaded 1700 images\n",
      "Loaded 1800 images\n",
      "Loaded 1900 images\n",
      "Loaded 2000 images\n",
      "Loaded 2100 images\n",
      "Loaded 2200 images\n",
      "Loaded 2300 images\n",
      "Loaded 2400 images\n",
      "Finished preparing 2500 images and labels for training!\n",
      "X.shape: (2500, 224, 224, 5)\n",
      "y.shape: (2500,)\n",
      "Epoch 1/200\n",
      "  2/110 [..............................] - ETA: 50s - loss: 1.1367 - accuracy: 0.5938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0893s vs `on_train_batch_end` time: 0.7811s). Check your callbacks.\n",
      "110/110 [==============================] - 20s 183ms/step - loss: 0.6326 - accuracy: 0.7543 - val_loss: 1.2671 - val_accuracy: 0.3720\n",
      "Epoch 2/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.4709 - accuracy: 0.8114 - val_loss: 0.7495 - val_accuracy: 0.4040\n",
      "Epoch 3/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.4740 - accuracy: 0.8229 - val_loss: 0.5873 - val_accuracy: 0.6960\n",
      "Epoch 4/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.4601 - accuracy: 0.8240 - val_loss: 0.5849 - val_accuracy: 0.6800\n",
      "Epoch 5/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.4592 - accuracy: 0.8314 - val_loss: 1.0305 - val_accuracy: 0.5920\n",
      "Epoch 6/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.4890 - accuracy: 0.8411 - val_loss: 0.5782 - val_accuracy: 0.6507\n",
      "Epoch 7/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.3799 - accuracy: 0.8446 - val_loss: 0.5944 - val_accuracy: 0.6547\n",
      "Epoch 8/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.4282 - accuracy: 0.8463 - val_loss: 0.7641 - val_accuracy: 0.6533\n",
      "Epoch 9/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.4276 - accuracy: 0.8423 - val_loss: 0.5619 - val_accuracy: 0.6813\n",
      "Epoch 10/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.3718 - accuracy: 0.8634 - val_loss: 0.5755 - val_accuracy: 0.6813\n",
      "Epoch 11/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.3739 - accuracy: 0.8691 - val_loss: 1.0238 - val_accuracy: 0.6653\n",
      "Epoch 12/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.3609 - accuracy: 0.8600 - val_loss: 0.6717 - val_accuracy: 0.6680\n",
      "Epoch 13/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.3048 - accuracy: 0.8800 - val_loss: 0.5040 - val_accuracy: 0.7120\n",
      "Epoch 14/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.3128 - accuracy: 0.8766 - val_loss: 0.5141 - val_accuracy: 0.7133\n",
      "Epoch 15/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.3654 - accuracy: 0.8617 - val_loss: 0.5050 - val_accuracy: 0.7387\n",
      "Epoch 16/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.3659 - accuracy: 0.8640 - val_loss: 0.8426 - val_accuracy: 0.7147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.3179 - accuracy: 0.8697 - val_loss: 0.5945 - val_accuracy: 0.6760\n",
      "Epoch 18/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.3262 - accuracy: 0.8720 - val_loss: 0.6847 - val_accuracy: 0.6853\n",
      "Epoch 19/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.3451 - accuracy: 0.8709 - val_loss: 0.5703 - val_accuracy: 0.7093\n",
      "Epoch 20/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.3584 - accuracy: 0.8794 - val_loss: 0.8147 - val_accuracy: 0.6947\n",
      "Epoch 21/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.3330 - accuracy: 0.8766 - val_loss: 0.5443 - val_accuracy: 0.7613\n",
      "Epoch 22/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.3113 - accuracy: 0.8823 - val_loss: 0.7015 - val_accuracy: 0.7613\n",
      "Epoch 23/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.3462 - accuracy: 0.8640 - val_loss: 0.5238 - val_accuracy: 0.7507\n",
      "Epoch 24/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.3016 - accuracy: 0.8914 - val_loss: 0.6625 - val_accuracy: 0.7373\n",
      "Epoch 25/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.3039 - accuracy: 0.8954 - val_loss: 0.8005 - val_accuracy: 0.7027\n",
      "Epoch 26/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.3059 - accuracy: 0.8971 - val_loss: 0.4863 - val_accuracy: 0.7747\n",
      "Epoch 27/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2760 - accuracy: 0.8949 - val_loss: 0.7041 - val_accuracy: 0.7120\n",
      "Epoch 28/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2753 - accuracy: 0.8891 - val_loss: 0.7940 - val_accuracy: 0.7333\n",
      "Epoch 29/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.3310 - accuracy: 0.8823 - val_loss: 0.6657 - val_accuracy: 0.7613\n",
      "Epoch 30/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2949 - accuracy: 0.8977 - val_loss: 0.6003 - val_accuracy: 0.7907\n",
      "Epoch 31/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.3229 - accuracy: 0.8834 - val_loss: 0.6215 - val_accuracy: 0.7253\n",
      "Epoch 32/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2524 - accuracy: 0.9149 - val_loss: 0.6170 - val_accuracy: 0.7493\n",
      "Epoch 33/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2727 - accuracy: 0.9114 - val_loss: 0.7963 - val_accuracy: 0.7413\n",
      "Epoch 34/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2662 - accuracy: 0.9091 - val_loss: 0.7077 - val_accuracy: 0.7600\n",
      "Epoch 35/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2747 - accuracy: 0.9011 - val_loss: 0.6025 - val_accuracy: 0.7733\n",
      "Epoch 36/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2475 - accuracy: 0.9223 - val_loss: 0.5741 - val_accuracy: 0.8040\n",
      "Epoch 37/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2335 - accuracy: 0.9177 - val_loss: 0.6040 - val_accuracy: 0.7987\n",
      "Epoch 38/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2968 - accuracy: 0.9149 - val_loss: 0.4823 - val_accuracy: 0.7800\n",
      "Epoch 39/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.2272 - accuracy: 0.9240 - val_loss: 0.5332 - val_accuracy: 0.7587\n",
      "Epoch 40/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2818 - accuracy: 0.9194 - val_loss: 0.4510 - val_accuracy: 0.8067\n",
      "Epoch 41/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.2053 - accuracy: 0.9297 - val_loss: 0.5526 - val_accuracy: 0.8067\n",
      "Epoch 42/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2077 - accuracy: 0.9337 - val_loss: 0.4853 - val_accuracy: 0.8067\n",
      "Epoch 43/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2497 - accuracy: 0.9229 - val_loss: 0.6514 - val_accuracy: 0.8053\n",
      "Epoch 44/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.2143 - accuracy: 0.9337 - val_loss: 0.4816 - val_accuracy: 0.8267\n",
      "Epoch 45/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2259 - accuracy: 0.9349 - val_loss: 0.5860 - val_accuracy: 0.7893\n",
      "Epoch 46/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1976 - accuracy: 0.9320 - val_loss: 0.5598 - val_accuracy: 0.8147\n",
      "Epoch 47/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1984 - accuracy: 0.9274 - val_loss: 0.6243 - val_accuracy: 0.7933\n",
      "Epoch 48/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1866 - accuracy: 0.9389 - val_loss: 0.4074 - val_accuracy: 0.8440\n",
      "Epoch 49/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2261 - accuracy: 0.9429 - val_loss: 0.4094 - val_accuracy: 0.8440\n",
      "Epoch 50/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.2447 - accuracy: 0.9309 - val_loss: 0.4762 - val_accuracy: 0.8333\n",
      "Epoch 51/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1732 - accuracy: 0.9480 - val_loss: 0.4879 - val_accuracy: 0.8467\n",
      "Epoch 52/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1852 - accuracy: 0.9423 - val_loss: 0.4799 - val_accuracy: 0.8387\n",
      "Epoch 53/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1781 - accuracy: 0.9389 - val_loss: 0.4170 - val_accuracy: 0.8480\n",
      "Epoch 54/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1928 - accuracy: 0.9417 - val_loss: 0.6130 - val_accuracy: 0.8413\n",
      "Epoch 55/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1766 - accuracy: 0.9389 - val_loss: 0.5111 - val_accuracy: 0.8293\n",
      "Epoch 56/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2141 - accuracy: 0.9434 - val_loss: 1.3291 - val_accuracy: 0.8253\n",
      "Epoch 57/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.2095 - accuracy: 0.9297 - val_loss: 0.5879 - val_accuracy: 0.8320\n",
      "Epoch 58/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1426 - accuracy: 0.9589 - val_loss: 0.6072 - val_accuracy: 0.8413\n",
      "Epoch 59/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1503 - accuracy: 0.9566 - val_loss: 0.5358 - val_accuracy: 0.8413\n",
      "Epoch 60/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1536 - accuracy: 0.9509 - val_loss: 0.4118 - val_accuracy: 0.8440\n",
      "Epoch 61/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.1719 - accuracy: 0.9486 - val_loss: 0.6198 - val_accuracy: 0.8280\n",
      "Epoch 62/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1713 - accuracy: 0.9440 - val_loss: 0.6163 - val_accuracy: 0.8147\n",
      "Epoch 63/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1454 - accuracy: 0.9509 - val_loss: 0.6822 - val_accuracy: 0.8160\n",
      "Epoch 64/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1725 - accuracy: 0.9434 - val_loss: 0.5375 - val_accuracy: 0.8120\n",
      "Epoch 65/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1517 - accuracy: 0.9549 - val_loss: 0.6138 - val_accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1372 - accuracy: 0.9571 - val_loss: 0.5004 - val_accuracy: 0.8227\n",
      "Epoch 67/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1580 - accuracy: 0.9537 - val_loss: 0.3957 - val_accuracy: 0.8493\n",
      "Epoch 68/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1665 - accuracy: 0.9486 - val_loss: 0.5485 - val_accuracy: 0.8320\n",
      "Epoch 69/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1455 - accuracy: 0.9531 - val_loss: 0.6415 - val_accuracy: 0.8133\n",
      "Epoch 70/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1672 - accuracy: 0.9571 - val_loss: 0.5181 - val_accuracy: 0.8467\n",
      "Epoch 71/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.1616 - accuracy: 0.9520 - val_loss: 0.5815 - val_accuracy: 0.8227\n",
      "Epoch 72/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1649 - accuracy: 0.9537 - val_loss: 0.5335 - val_accuracy: 0.8227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1371 - accuracy: 0.9554 - val_loss: 0.4467 - val_accuracy: 0.8173\n",
      "Epoch 74/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1314 - accuracy: 0.9549 - val_loss: 0.5918 - val_accuracy: 0.8227\n",
      "Epoch 75/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1554 - accuracy: 0.9583 - val_loss: 0.6031 - val_accuracy: 0.8120\n",
      "Epoch 76/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1759 - accuracy: 0.9560 - val_loss: 0.4943 - val_accuracy: 0.8347\n",
      "Epoch 77/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1613 - accuracy: 0.9560 - val_loss: 0.7324 - val_accuracy: 0.7960\n",
      "Epoch 78/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1510 - accuracy: 0.9554 - val_loss: 0.6133 - val_accuracy: 0.8067\n",
      "Epoch 79/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1402 - accuracy: 0.9531 - val_loss: 0.7135 - val_accuracy: 0.8027\n",
      "Epoch 80/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1515 - accuracy: 0.9560 - val_loss: 0.7312 - val_accuracy: 0.7773\n",
      "Epoch 81/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.1266 - accuracy: 0.9629 - val_loss: 0.6885 - val_accuracy: 0.7880\n",
      "Epoch 82/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1709 - accuracy: 0.9474 - val_loss: 0.4818 - val_accuracy: 0.8213\n",
      "Epoch 83/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1369 - accuracy: 0.9600 - val_loss: 0.6074 - val_accuracy: 0.8120\n",
      "Epoch 84/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1126 - accuracy: 0.9663 - val_loss: 0.5587 - val_accuracy: 0.8227\n",
      "Epoch 85/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1567 - accuracy: 0.9566 - val_loss: 0.6409 - val_accuracy: 0.8080\n",
      "Epoch 86/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1293 - accuracy: 0.9623 - val_loss: 0.5168 - val_accuracy: 0.8360\n",
      "Epoch 87/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1414 - accuracy: 0.9577 - val_loss: 0.4397 - val_accuracy: 0.8493\n",
      "Epoch 88/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1250 - accuracy: 0.9606 - val_loss: 0.5506 - val_accuracy: 0.8320\n",
      "Epoch 89/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1278 - accuracy: 0.9606 - val_loss: 0.5474 - val_accuracy: 0.8227\n",
      "Epoch 90/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1417 - accuracy: 0.9640 - val_loss: 0.6188 - val_accuracy: 0.8120\n",
      "Epoch 91/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.1271 - accuracy: 0.9634 - val_loss: 0.5059 - val_accuracy: 0.8400\n",
      "Epoch 92/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1291 - accuracy: 0.9640 - val_loss: 0.6209 - val_accuracy: 0.8213\n",
      "Epoch 93/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1324 - accuracy: 0.9629 - val_loss: 0.4746 - val_accuracy: 0.8387\n",
      "Epoch 94/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1334 - accuracy: 0.9577 - val_loss: 0.7274 - val_accuracy: 0.7987\n",
      "Epoch 95/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1154 - accuracy: 0.9623 - val_loss: 0.4316 - val_accuracy: 0.8493\n",
      "Epoch 96/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1288 - accuracy: 0.9640 - val_loss: 0.5168 - val_accuracy: 0.8307\n",
      "Epoch 97/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1109 - accuracy: 0.9669 - val_loss: 0.5018 - val_accuracy: 0.8267\n",
      "Epoch 98/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1063 - accuracy: 0.9634 - val_loss: 0.6077 - val_accuracy: 0.8053\n",
      "Epoch 99/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1056 - accuracy: 0.9657 - val_loss: 0.6016 - val_accuracy: 0.8520\n",
      "Epoch 100/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1176 - accuracy: 0.9634 - val_loss: 0.5557 - val_accuracy: 0.8280\n",
      "Epoch 101/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.1077 - accuracy: 0.9646 - val_loss: 0.4878 - val_accuracy: 0.8373\n",
      "Epoch 102/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1192 - accuracy: 0.9669 - val_loss: 0.4850 - val_accuracy: 0.8267\n",
      "Epoch 103/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1184 - accuracy: 0.9629 - val_loss: 0.5739 - val_accuracy: 0.8160\n",
      "Epoch 104/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1329 - accuracy: 0.9606 - val_loss: 0.5785 - val_accuracy: 0.7907\n",
      "Epoch 105/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1100 - accuracy: 0.9623 - val_loss: 0.6103 - val_accuracy: 0.8173\n",
      "Epoch 106/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1123 - accuracy: 0.9691 - val_loss: 0.4491 - val_accuracy: 0.8427\n",
      "Epoch 107/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0993 - accuracy: 0.9697 - val_loss: 0.4855 - val_accuracy: 0.8240\n",
      "Epoch 108/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1044 - accuracy: 0.9634 - val_loss: 0.5444 - val_accuracy: 0.8093\n",
      "Epoch 109/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1067 - accuracy: 0.9646 - val_loss: 0.4410 - val_accuracy: 0.8493\n",
      "Epoch 110/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1172 - accuracy: 0.9617 - val_loss: 0.3873 - val_accuracy: 0.8560\n",
      "Epoch 111/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.1220 - accuracy: 0.9646 - val_loss: 0.5384 - val_accuracy: 0.8147\n",
      "Epoch 112/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1010 - accuracy: 0.9709 - val_loss: 0.6829 - val_accuracy: 0.7947\n",
      "Epoch 113/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1047 - accuracy: 0.9680 - val_loss: 0.7050 - val_accuracy: 0.8133\n",
      "Epoch 114/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1009 - accuracy: 0.9703 - val_loss: 0.5867 - val_accuracy: 0.8227\n",
      "Epoch 115/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1178 - accuracy: 0.9651 - val_loss: 0.4868 - val_accuracy: 0.8240\n",
      "Epoch 116/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1060 - accuracy: 0.9680 - val_loss: 0.5766 - val_accuracy: 0.8293\n",
      "Epoch 117/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1431 - accuracy: 0.9680 - val_loss: 0.5396 - val_accuracy: 0.8107\n",
      "Epoch 118/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.1198 - accuracy: 0.9651 - val_loss: 0.7139 - val_accuracy: 0.7960\n",
      "Epoch 119/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1175 - accuracy: 0.9686 - val_loss: 0.4155 - val_accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1181 - accuracy: 0.9634 - val_loss: 0.5875 - val_accuracy: 0.8267\n",
      "Epoch 121/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.1132 - accuracy: 0.9691 - val_loss: 0.5402 - val_accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1144 - accuracy: 0.9629 - val_loss: 0.4278 - val_accuracy: 0.8493\n",
      "Epoch 123/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1156 - accuracy: 0.9629 - val_loss: 0.5392 - val_accuracy: 0.8267\n",
      "Epoch 124/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1075 - accuracy: 0.9669 - val_loss: 0.6201 - val_accuracy: 0.8027\n",
      "Epoch 125/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0956 - accuracy: 0.9709 - val_loss: 0.6944 - val_accuracy: 0.8187\n",
      "Epoch 126/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0901 - accuracy: 0.9737 - val_loss: 0.5413 - val_accuracy: 0.8227\n",
      "Epoch 127/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0979 - accuracy: 0.9720 - val_loss: 0.4177 - val_accuracy: 0.8707\n",
      "Epoch 128/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1009 - accuracy: 0.9709 - val_loss: 0.4433 - val_accuracy: 0.8667\n",
      "Epoch 129/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1018 - accuracy: 0.9691 - val_loss: 0.7067 - val_accuracy: 0.7893\n",
      "Epoch 130/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1003 - accuracy: 0.9703 - val_loss: 0.7646 - val_accuracy: 0.7707\n",
      "Epoch 131/200\n",
      "110/110 [==============================] - 19s 168ms/step - loss: 0.1115 - accuracy: 0.9651 - val_loss: 0.5567 - val_accuracy: 0.8120\n",
      "Epoch 132/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1054 - accuracy: 0.9731 - val_loss: 0.5636 - val_accuracy: 0.8253\n",
      "Epoch 133/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1008 - accuracy: 0.9669 - val_loss: 0.5054 - val_accuracy: 0.8253\n",
      "Epoch 134/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0932 - accuracy: 0.9720 - val_loss: 0.6161 - val_accuracy: 0.8200\n",
      "Epoch 135/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0941 - accuracy: 0.9720 - val_loss: 0.4923 - val_accuracy: 0.8533\n",
      "Epoch 136/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0910 - accuracy: 0.9703 - val_loss: 0.5462 - val_accuracy: 0.8267\n",
      "Epoch 137/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1776 - accuracy: 0.9634 - val_loss: 0.6337 - val_accuracy: 0.7933\n",
      "Epoch 138/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0995 - accuracy: 0.9731 - val_loss: 0.8114 - val_accuracy: 0.7853\n",
      "Epoch 139/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1009 - accuracy: 0.9697 - val_loss: 0.4958 - val_accuracy: 0.8227\n",
      "Epoch 140/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1081 - accuracy: 0.9669 - val_loss: 0.5702 - val_accuracy: 0.8213\n",
      "Epoch 141/200\n",
      "110/110 [==============================] - 19s 168ms/step - loss: 0.1118 - accuracy: 0.9674 - val_loss: 0.4354 - val_accuracy: 0.8453\n",
      "Epoch 142/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1080 - accuracy: 0.9680 - val_loss: 0.5140 - val_accuracy: 0.8267\n",
      "Epoch 143/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0790 - accuracy: 0.9783 - val_loss: 0.4676 - val_accuracy: 0.8413\n",
      "Epoch 144/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0951 - accuracy: 0.9731 - val_loss: 0.3969 - val_accuracy: 0.8507\n",
      "Epoch 145/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1000 - accuracy: 0.9709 - val_loss: 0.4931 - val_accuracy: 0.8307\n",
      "Epoch 146/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0810 - accuracy: 0.9800 - val_loss: 0.4150 - val_accuracy: 0.8533\n",
      "Epoch 147/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0891 - accuracy: 0.9686 - val_loss: 0.4398 - val_accuracy: 0.8600\n",
      "Epoch 148/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0865 - accuracy: 0.9737 - val_loss: 0.5285 - val_accuracy: 0.8147\n",
      "Epoch 149/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0902 - accuracy: 0.9697 - val_loss: 0.5401 - val_accuracy: 0.8187\n",
      "Epoch 150/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.1006 - accuracy: 0.9674 - val_loss: 0.4050 - val_accuracy: 0.8493\n",
      "Epoch 151/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.1301 - accuracy: 0.9709 - val_loss: 0.5051 - val_accuracy: 0.8187\n",
      "Epoch 152/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0904 - accuracy: 0.9743 - val_loss: 0.5693 - val_accuracy: 0.8160\n",
      "Epoch 153/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0945 - accuracy: 0.9686 - val_loss: 0.4117 - val_accuracy: 0.8587\n",
      "Epoch 154/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0949 - accuracy: 0.9731 - val_loss: 0.4537 - val_accuracy: 0.8373\n",
      "Epoch 155/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0898 - accuracy: 0.9720 - val_loss: 0.6473 - val_accuracy: 0.8093\n",
      "Epoch 156/200\n",
      "110/110 [==============================] - 18s 163ms/step - loss: 0.0853 - accuracy: 0.9743 - val_loss: 0.4105 - val_accuracy: 0.8520\n",
      "Epoch 157/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0865 - accuracy: 0.9749 - val_loss: 0.5661 - val_accuracy: 0.8200\n",
      "Epoch 158/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0853 - accuracy: 0.9726 - val_loss: 0.5284 - val_accuracy: 0.8147\n",
      "Epoch 159/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0905 - accuracy: 0.9709 - val_loss: 0.3605 - val_accuracy: 0.8560\n",
      "Epoch 160/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0783 - accuracy: 0.9789 - val_loss: 0.4822 - val_accuracy: 0.8400\n",
      "Epoch 161/200\n",
      "110/110 [==============================] - 18s 168ms/step - loss: 0.0826 - accuracy: 0.9743 - val_loss: 0.5311 - val_accuracy: 0.8320\n",
      "Epoch 162/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1006 - accuracy: 0.9697 - val_loss: 0.5482 - val_accuracy: 0.8120\n",
      "Epoch 163/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0832 - accuracy: 0.9726 - val_loss: 0.6304 - val_accuracy: 0.8000\n",
      "Epoch 164/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0969 - accuracy: 0.9703 - val_loss: 0.5465 - val_accuracy: 0.8200\n",
      "Epoch 165/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0891 - accuracy: 0.9714 - val_loss: 0.5257 - val_accuracy: 0.8333\n",
      "Epoch 166/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0957 - accuracy: 0.9737 - val_loss: 0.6396 - val_accuracy: 0.8080\n",
      "Epoch 167/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0861 - accuracy: 0.9743 - val_loss: 0.5835 - val_accuracy: 0.8093\n",
      "Epoch 168/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0878 - accuracy: 0.9743 - val_loss: 0.5485 - val_accuracy: 0.8107\n",
      "Epoch 169/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0846 - accuracy: 0.9743 - val_loss: 0.6014 - val_accuracy: 0.8133\n",
      "Epoch 170/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0877 - accuracy: 0.9760 - val_loss: 0.4198 - val_accuracy: 0.8533\n",
      "Epoch 171/200\n",
      "110/110 [==============================] - 19s 168ms/step - loss: 0.0887 - accuracy: 0.9731 - val_loss: 0.5231 - val_accuracy: 0.8213\n",
      "Epoch 172/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0782 - accuracy: 0.9754 - val_loss: 0.3996 - val_accuracy: 0.8733\n",
      "Epoch 173/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0718 - accuracy: 0.9766 - val_loss: 0.5910 - val_accuracy: 0.8200\n",
      "Epoch 174/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0942 - accuracy: 0.9714 - val_loss: 0.3399 - val_accuracy: 0.8920\n",
      "Epoch 175/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1003 - accuracy: 0.9703 - val_loss: 0.3074 - val_accuracy: 0.8987\n",
      "Epoch 176/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0841 - accuracy: 0.9766 - val_loss: 0.3868 - val_accuracy: 0.8800\n",
      "Epoch 177/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.1090 - accuracy: 0.9697 - val_loss: 0.3880 - val_accuracy: 0.8747\n",
      "Epoch 178/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0999 - accuracy: 0.9697 - val_loss: 0.3444 - val_accuracy: 0.8880\n",
      "Epoch 179/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0944 - accuracy: 0.9749 - val_loss: 0.3305 - val_accuracy: 0.8867\n",
      "Epoch 180/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0835 - accuracy: 0.9737 - val_loss: 0.3168 - val_accuracy: 0.8893\n",
      "Epoch 181/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0837 - accuracy: 0.9749 - val_loss: 0.4545 - val_accuracy: 0.8693\n",
      "Epoch 182/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0968 - accuracy: 0.9720 - val_loss: 0.3881 - val_accuracy: 0.8813\n",
      "Epoch 183/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0879 - accuracy: 0.9720 - val_loss: 0.3768 - val_accuracy: 0.8773\n",
      "Epoch 184/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0793 - accuracy: 0.9749 - val_loss: 0.4333 - val_accuracy: 0.8707\n",
      "Epoch 185/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0797 - accuracy: 0.9726 - val_loss: 0.4281 - val_accuracy: 0.8680\n",
      "Epoch 186/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0931 - accuracy: 0.9754 - val_loss: 0.4535 - val_accuracy: 0.8800\n",
      "Epoch 187/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0879 - accuracy: 0.9754 - val_loss: 0.3156 - val_accuracy: 0.8893\n",
      "Epoch 188/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.1130 - accuracy: 0.9703 - val_loss: 0.4363 - val_accuracy: 0.8627\n",
      "Epoch 189/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0907 - accuracy: 0.9749 - val_loss: 0.3585 - val_accuracy: 0.8733\n",
      "Epoch 190/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0804 - accuracy: 0.9777 - val_loss: 0.4175 - val_accuracy: 0.8667\n",
      "Epoch 191/200\n",
      "110/110 [==============================] - 18s 167ms/step - loss: 0.0862 - accuracy: 0.9691 - val_loss: 0.4224 - val_accuracy: 0.8693\n",
      "Epoch 192/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0871 - accuracy: 0.9726 - val_loss: 0.4419 - val_accuracy: 0.8653\n",
      "Epoch 193/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0926 - accuracy: 0.9726 - val_loss: 0.4202 - val_accuracy: 0.8573\n",
      "Epoch 194/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0762 - accuracy: 0.9766 - val_loss: 0.3695 - val_accuracy: 0.8720\n",
      "Epoch 195/200\n",
      "110/110 [==============================] - 18s 165ms/step - loss: 0.0845 - accuracy: 0.9737 - val_loss: 0.3554 - val_accuracy: 0.8773\n",
      "Epoch 196/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0919 - accuracy: 0.9709 - val_loss: 0.4025 - val_accuracy: 0.8653\n",
      "Epoch 197/200\n",
      "110/110 [==============================] - 18s 166ms/step - loss: 0.0788 - accuracy: 0.9777 - val_loss: 0.4086 - val_accuracy: 0.8667\n",
      "Epoch 198/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0845 - accuracy: 0.9754 - val_loss: 0.4520 - val_accuracy: 0.8653\n",
      "Epoch 199/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0640 - accuracy: 0.9817 - val_loss: 0.5109 - val_accuracy: 0.8360\n",
      "Epoch 200/200\n",
      "110/110 [==============================] - 18s 164ms/step - loss: 0.0892 - accuracy: 0.9731 - val_loss: 0.6292 - val_accuracy: 0.8133\n"
     ]
    }
   ],
   "source": [
    "RESIZE_METHODS = ['bilinear', 'nearest', 'bicubic']\n",
    "PAN_MS_BOTH = ['pan', 'ms', 'both']\n",
    "LEARNING_RATES = [0.001, 0.0005, 0.0001]\n",
    "\n",
    "EPOCHS = 200\n",
    "\n",
    "for resize_method in RESIZE_METHODS:\n",
    "    for pan_ms_both in PAN_MS_BOTH:\n",
    "        if pan_ms_both == 'pan':\n",
    "            train_tile_bands = 1\n",
    "        elif pan_ms_both == 'ms':\n",
    "            train_tile_bands = 4\n",
    "        elif pan_ms_both == 'both':\n",
    "            train_tile_bands = 5\n",
    "        for learning_rate in LEARNING_RATES:\n",
    "                \n",
    "            X, y = prepare_for_training(label_df, tif_paths_pan, tif_paths_ms,\n",
    "                                        pan_or_ms_or_both=pan_ms_both,\n",
    "                                        pan_tile_size=TRAIN_TILE_SIZE, ms_tile_size=TRAIN_TILE_SIZE, \n",
    "                                        resize_method=resize_method)\n",
    "\n",
    "            model = build_model(augment=True, \n",
    "                                input_shape=(TRAIN_TILE_SIZE, TRAIN_TILE_SIZE, train_tile_bands), \n",
    "                                learning_rate=learning_rate)\n",
    "\n",
    "            pretrain_model_name = str('cloudsea-effb0-augm-' + resize_method \n",
    "                                      + '-' + pan_ms_both + '-' + str(learning_rate) + '-')\n",
    "            log_dir = pathlib.Path(str('logs/cloud-sea-classifier/fit/' + pretrain_model_name \n",
    "                                       + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')))\n",
    "            tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, \n",
    "                                                                  histogram_freq=10, \n",
    "                                                                  write_graph=False, \n",
    "                                                                  write_images=False,\n",
    "                                                                  update_freq='epoch')\n",
    "\n",
    "            checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath = str('models/cloud-sea-classifier/' + pretrain_model_name + '-{epoch:02d}-{val_loss:.6f}.h5'), \n",
    "                monitor = \"val_acc\",\n",
    "                save_best_only = False,\n",
    "                save_weights_only = True,\n",
    "                )\n",
    "\n",
    "            model.fit(X, y, batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "                      validation_split=VAL_SPLIT, initial_epoch=0,\n",
    "                      callbacks=[checkpoint_callback, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
