{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration and descriptive statistics of satellite imagery\n",
    "\n",
    "This jupyter notebook will parse, collate and analyze satellite imagery files from Maxar (former DigitalGlobe) The parsing of the metadata files (`DeliveryMetadata.xml`) are mainly general and should work for any Maxar product delivery. After parsing of the metadata files into pandas dataframes the code is mainly project specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "from rasterio.plot import reshape_as_image\n",
    "import geopandas\n",
    "\n",
    "import tensorflow as tf\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "from modules.metadata_reader import img_metadata_to_dict, add_names_to_metadata_dict, dict_to_df\n",
    "\n",
    "# Path to location where individual satellite images are located\n",
    "DATA_PATH = 'data/toulon-laspezia' \n",
    "DATA_PATH_IS_RELATIVE = True\n",
    "DATA_PATH_NPY = 'data/toulon-laspezia-npy' \n",
    "DATA_PATH_TILES = 'data/toulon-laspezia-tiles'\n",
    "\n",
    "# Name of metadata .xml file\n",
    "METADATA_NAME = 'DeliveryMetadata.xml'\n",
    "\n",
    "# Names of areas covered by satellite imagery\n",
    "AREAS = ['La_Spezia', 'Toulon'] # Spelled like the directory names\n",
    "\n",
    "# Speficy what the xmlns url on top of metadata .xml file is\n",
    "# (should be second line)\n",
    "XMLNS = 'http://xsd.digitalglobe.com/xsd/dm'\n",
    "\n",
    "# pandas options\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "#pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata parsing from xml to pandas dataframe\n",
    "\n",
    "Every satellite image delivery from Maxar contains a `DeliveryMetadata.xml` file with important specifications for both the multispectral and panchromatic images. The following functions finds all the `DeliveryMetadata.xml` files contained in all subdirectories of a directory and parses them into the *Pandas DataFrame* format which will be used for further descriptive statistics of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_metadata_pan, img_metadata_ms = img_metadata_to_dict(METADATA_NAME, \n",
    "                                                         DATA_PATH, XMLNS, \n",
    "                                                         path_is_relative = DATA_PATH_IS_RELATIVE)\n",
    "\n",
    "img_metadata_pan = add_names_to_metadata_dict(img_metadata_pan, AREAS)\n",
    "img_metadata_ms = add_names_to_metadata_dict(img_metadata_ms, AREAS)\n",
    "\n",
    "img_metadata_pan = dict_to_df(img_metadata_pan)\n",
    "img_metadata_ms = dict_to_df(img_metadata_ms)\n",
    "\n",
    "# Checking that string IDs and int IDs are equal in both dataframes (they should)\n",
    "assert all(img_metadata_ms.index == img_metadata_pan.index)\n",
    "assert all(img_metadata_ms['int_uid'] == img_metadata_pan['int_uid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup functions for UIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_int_uid(string_UIDs):\n",
    "    return img_metadata_pan.loc[string_UIDs]['int_uid'].tolist()\n",
    "\n",
    "def get_string_uid(int_UIDs):\n",
    "    # Could probably be neater\n",
    "    # Accepts list of ints and single int\n",
    "    if type(int_UIDs) == int:\n",
    "        int_UIDs = [int_UIDs]\n",
    "    l = []\n",
    "    for int_UID in int_UIDs:\n",
    "        l.append(img_metadata_pan[img_metadata_pan['int_uid'] == int_UID].index.tolist()[0])\n",
    "    if len(l) == 1:\n",
    "        return l[0]\n",
    "    else:\n",
    "        return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of panchromatic images:', len(img_metadata_pan))\n",
    "print('Number of multispectral images:', len(img_metadata_ms), '\\n')\n",
    "if list(img_metadata_pan.index.values) == list(img_metadata_ms.index.values):\n",
    "    print('Pass: Identical keys. Keys in panchromatic and multispectral dictionaries are identical.')\n",
    "else: print('Fail: Identical keys. Keys in panchromatic and multispectral dictionaries are not identical.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup and merging of the two dataframes\n",
    "\n",
    "It is cumbersome to work with two almost identical dataframes so we will merge them and in the process remove quite a number of columns with redundant or irrelevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_metadata(metadata_df_pan, metadata_df_ms):\n",
    "    \n",
    "    # Starting with the panchromatic metadata dataframe\n",
    "    df = metadata_df_pan.copy(deep = True)\n",
    "    \n",
    "    # Dropping the voluminous product columns. \n",
    "    # These contain paths and metadata to/of all files, but 90% of the files are not used\n",
    "    # and it is often a better strategy to look up files by 'glob' or similar functions\n",
    "    product_columns = df.columns[29:62].to_list()\n",
    "    #print(product_columns)\n",
    "    df.drop(columns = product_columns, inplace = True)\n",
    "    \n",
    "    # Dropping other columns\n",
    "    df.drop(columns = \n",
    "           ['band0',             # Redundant since it simply states 'Pan' for all rows\n",
    "            'cloudCover',        # The estimate is of very poor quality\n",
    "            'imageTypeSize',     # This value looks to be wrong as it is equal for all images\n",
    "            'imagingTilingType', # Not relevant info\n",
    "            'isMosaic',          # This seems wrong as no images are mosaics of several images\n",
    "            'mergingAlgorithm',  # Redundant since there is no band merging going on\n",
    "            'mergedBand',        # Redundant since there is no band merging going on\n",
    "            'strip0',            # A lot of duplicate info in this column\n",
    "            'n_bands',           # Redundant as this is always 1 for Pan\n",
    "            'n_products',        # Not relevant info\n",
    "            'n_strips',          # Redundant as this is always 1 as no images are \n",
    "            'lineNumber',        # Not relevant info\n",
    "            'incrementNumber'    # Not relevant info\n",
    "           ], inplace = True)\n",
    "    \n",
    "    # Checking whether earliest and latest are equal. If they are only one of the columns\n",
    "    # is needed and thus they are merged.\n",
    "    if df['earliestAcquisitionTime'].equals(df['latestAcquisitionTime']):\n",
    "        df.drop(columns = 'latestAcquisitionTime', inplace = True)\n",
    "        df.rename(columns = {'earliestAcquisitionTime': 'acquisitionTime'}, \n",
    "                  inplace = True)\n",
    "    else:\n",
    "        print('Columns earliestAcquisitionTime and latestAcquisitionTime are not equal. Keeping both.')\n",
    "    \n",
    "    # Renaming columns to prepare for merging with the multispectral dataframe.\n",
    "    df.rename(columns = \n",
    "              {'catalogIdentifier': 'pan_catalogIdentifier', \n",
    "               'processedProductId': 'pan_processedProductId', \n",
    "               'pixelHeight': 'pan_pixelHeight', \n",
    "               'pixelWidth': 'pan_pixelWidth', \n",
    "               'tif_path' : 'pan_tif_path'}, inplace = True)\n",
    "    \n",
    "    # Adding the relevant columns from the multispectral metadata dataframe\n",
    "    df['ms_catalogIdentifier'] = metadata_df_ms['catalogIdentifier']\n",
    "    df['ms_processedProductId'] = metadata_df_ms['processedProductId']\n",
    "    df['ms_pixelHeight'] = metadata_df_ms['pixelHeight']\n",
    "    df['ms_pixelWidth'] = metadata_df_ms['pixelWidth']\n",
    "    df['ms_tif_path'] = metadata_df_ms['tif_path']\n",
    "    df['ms_band0'] = metadata_df_ms['band0']\n",
    "    df['ms_band1'] = metadata_df_ms['band1']\n",
    "    df['ms_band2'] = metadata_df_ms['band2']\n",
    "    df['ms_band3'] = metadata_df_ms['band3']\n",
    "    df['ms_band4'] = metadata_df_ms['band4']\n",
    "    df['ms_band5'] = metadata_df_ms['band5']\n",
    "    df['ms_band6'] = metadata_df_ms['band6']\n",
    "    df['ms_band7'] = metadata_df_ms['band7']\n",
    "\n",
    "    # Reordering the columns for a more intuitive viewing experience\n",
    "    columns_order = ['int_uid', \n",
    "                     'area_name',\n",
    "                     'sensorVehicle', \n",
    "                     'pan_catalogIdentifier', \n",
    "                     'ms_catalogIdentifier', \n",
    "                     'pan_processedProductId', \n",
    "                     'ms_processedProductId',\n",
    "                     'orderNumber', \n",
    "                     'acquisitionTime', \n",
    "                     'productionDate', \n",
    "                     'updateDate',\n",
    "                     'bitsPerPixel', \n",
    "                     'imageFileFormat', \n",
    "                     'pan_pixelHeight', \n",
    "                     'pan_pixelWidth', \n",
    "                     'ms_pixelHeight', \n",
    "                     'ms_pixelWidth', \n",
    "                     'isDynamicRangeAdjusted', \n",
    "                     'processingLevel', \n",
    "                     'resamplingKernel', \n",
    "                     'datum', \n",
    "                     'mapProjection', \n",
    "                     'mapProjectionZone', \n",
    "                     'mapProjectionUnit',\n",
    "                     'offNadirAngle', \n",
    "                     'sunAzimuth', \n",
    "                     'sunElevation', \n",
    "                     'ms_band0', 'ms_band1', 'ms_band2', 'ms_band3', \n",
    "                     'ms_band4', 'ms_band5', 'ms_band6', 'ms_band7',\n",
    "                     'pan_tif_path', \n",
    "                     'ms_tif_path'\n",
    "                    ]\n",
    "    df = df.reindex(columns = columns_order)\n",
    "    \n",
    "    return df\n",
    "\n",
    "meta = merge_metadata(img_metadata_pan, img_metadata_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding geometry to metadata dataframe\n",
    "\n",
    "Crawls through the data directory looking for polygon vector files (shapefiles, `.shp`) that define the extent of each image. This geometry data is then used to convert the metadata dataframes to `geopandas.GeoDataFrame` objects, a geospatially enabled extension of `pandas.DataFrame`.\n",
    "\n",
    "The end result is that we can now do spatial queries directly using the dataframe. This will come in handy later when producing imagery tiles that adhere to the spatial boundaries of the imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_EPSG_to_metadata_df(metadata_df):\n",
    "    # EPSG is a datum/projection code\n",
    "    metadata_df['EPSG'] = [32631 if utm_zone == '31' \n",
    "                           else 32632 if utm_zone == '32' \n",
    "                           else None \n",
    "                           for utm_zone in metadata_df['mapProjectionZone']]\n",
    "    return metadata_df\n",
    "\n",
    "meta = add_EPSG_to_metadata_df(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_image_shape(image_UID, pan_or_ms):\n",
    "#    if pan_or_ms == 'pan':\n",
    "#        pan_or_ms = 'P2AS'\n",
    "#    elif pan_or_ms == 'ms':\n",
    "#        pan_or_ms = 'M2AS'\n",
    "#    else:\n",
    "#        print('pan_or_ms must be either \"pan\" or \"ms\"')\n",
    "#\n",
    "#    epsg = metadata_df.loc[image_UID, 'EPSG']\n",
    "#    \n",
    "#    data_path = pathlib.Path(DATA_PATH, image_UID)\n",
    "#    shp_paths = list(data_path.glob(str('**/*' + pan_or_ms + '*PIXEL_SHAPE.shp')))\n",
    "#    assert len(shp_paths) == 2\n",
    "#    for shp_path in shp_paths:\n",
    "#        shape = geopandas.read_file(shp_path)\n",
    "#        if shape.crs == 4326: #WGS84 geographic projection\n",
    "#            return shape.to_crs(epsg = epsg)\n",
    "        \n",
    "def metadata_df_to_geodf(metadata_df, pan_or_ms):\n",
    "    if pan_or_ms == 'pan':\n",
    "        pan_or_ms = 'P2AS'\n",
    "    elif pan_or_ms == 'ms':\n",
    "        pan_or_ms = 'M2AS'\n",
    "    else:\n",
    "        print('pan_or_ms must be either \"pan\" or \"ms\"')\n",
    "        \n",
    "    data_path = pathlib.Path(DATA_PATH)\n",
    "    shp_paths = list(data_path.glob(str('**/*' + pan_or_ms + '*PIXEL_SHAPE.shp')))\n",
    "    metadata_df['geometry'] = None\n",
    "    for shp_path in shp_paths:\n",
    "        image_UID = shp_path.parts[2]\n",
    "        epsg = metadata_df.loc[image_UID, 'EPSG']\n",
    "        shape = geopandas.read_file(shp_path)\n",
    "        if shape.crs == None: #4326 is WGS84 geographic projection\n",
    "            continue\n",
    "        #print(shape['geometry'])\n",
    "        shape = shape.to_crs(epsg = epsg)\n",
    "        metadata_df.at[image_UID, 'geometry'] = shape['geometry'][0]\n",
    "    \n",
    "    metadata_geodf = geopandas.GeoDataFrame(metadata_df, geometry = 'geometry')\n",
    "    return metadata_geodf\n",
    "\n",
    "meta = metadata_df_to_geodf(meta, 'pan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometry sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[meta['area_name'] == 'La_Spezia'].boundary.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[meta['area_name'] == 'Toulon'].boundary.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image areas (m²)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La Spezia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[meta['area_name'] == 'La_Spezia'].area.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[meta['area_name'] == 'La_Spezia'].area.astype('float32').sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toulon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[meta['area_name'] == 'Toulon'].area.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[meta['area_name'] == 'Toulon'].area.astype('float32').sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLOUDS_PATH = 'data/toulon-laspezia-clouds'\n",
    "\n",
    "clouds_laspezia = geopandas.read_file(pathlib.Path(CLOUDS_PATH, 'laspezia-clouds.shp'))\n",
    "clouds_toulon = geopandas.read_file(pathlib.Path(CLOUDS_PATH, 'toulon-clouds.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_area_to_metadata_gdf(metadata_gdf):\n",
    "    metadata_gdf['area_m2'] = metadata_gdf['geometry'].area.astype('float32')\n",
    "    return metadata_gdf\n",
    "\n",
    "meta = add_area_to_metadata_gdf(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_clouds_area_to_metadata_gdf(metadata_gdf, clouds_gdf):\n",
    "    for image_UID in clouds_gdf['image_id'].unique():\n",
    "        clouds_sum = 0.0\n",
    "        for polygon in clouds_gdf.loc[clouds_gdf['image_id'] == image_UID, 'geometry']:\n",
    "            #print(type(polygon.area))\n",
    "            clouds_sum += polygon.area\n",
    "        metadata_gdf.at[image_UID, 'clouds_area_m2'] = clouds_sum\n",
    "        \n",
    "    metadata_gdf = metadata_gdf.astype({'clouds_area_m2': 'float32'})\n",
    "    metadata_gdf['clouds_area_m2'].fillna(0.0, inplace = True)\n",
    "    \n",
    "    return metadata_gdf\n",
    "\n",
    "meta = add_clouds_area_to_metadata_gdf(meta, clouds_laspezia)\n",
    "meta = add_clouds_area_to_metadata_gdf(meta, clouds_toulon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cloud_ratio_to_metadata_gdf(metadata_gdf):\n",
    "    metadata_gdf['cloud_ratio'] = metadata_gdf['clouds_area_m2'] / metadata_gdf['area_m2']\n",
    "    return metadata_gdf\n",
    "\n",
    "meta = add_cloud_ratio_to_metadata_gdf(meta)\n",
    "\n",
    "meta['cloud_ratio'].hist(bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['cloud_ratio'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area and clouds statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_max_image_size_to_metadata_gdf(metadata_gdf):\n",
    "    for area_name in metadata_gdf['area_name'].unique():\n",
    "        \n",
    "        # Find the max area for each location\n",
    "        max_area_m2 = metadata_gdf.loc[metadata_gdf['area_name'] == area_name, 'area_m2'].max()\n",
    "        \n",
    "        # Add this to a column in the gdf\n",
    "        metadata_gdf.loc[metadata_gdf['area_name'] == area_name, 'area_m2_max'] = max_area_m2\n",
    "        #['area_m2_max'] = max_area_m2\n",
    "    \n",
    "    # Calculate an \"area_ratio\", a measure of how large an image is compared to the max sized image\n",
    "    # Low number means that the image is small and only cover a minor part of the area\n",
    "    metadata_gdf['area_ratio'] = metadata_gdf['area_m2']/metadata_gdf['area_m2_max']\n",
    "\n",
    "    return metadata_gdf\n",
    "\n",
    "meta = add_max_image_size_to_metadata_gdf(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['area_ratio'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(metadata_gdf, \n",
    "                         area_ratio_treshold, \n",
    "                         cloud_ratio_treshold, \n",
    "                         train_val_test_split,\n",
    "                         seed = 18):\n",
    "    df = metadata_gdf\n",
    "    df['train_val_test'] = None\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # WV03\n",
    "    print('Starting with', len(metadata_gdf), 'images')\n",
    "    print('Assigning all WV03 to training set...')\n",
    "    # There are not many of these and they are not well distributed between the areas so no effort will\n",
    "    # be done on evaluating on these images.\n",
    "    df.loc[df['sensorVehicle'] == 'WV03_VNIR', 'train_val_test'] = 'train'\n",
    "    print('Number of images left to assign:', \n",
    "          len(df[df['train_val_test'].isnull()]))\n",
    "    \n",
    "    # Randomly assign GE01 to either val or test sets\n",
    "    # These will not be used for training, but serve as a measure of how well the model can perform on \n",
    "    # a different sensor\n",
    "    print('Randomly assigning GE01 images to val or test sets')\n",
    "    for area_name in df['area_name'].unique():\n",
    "        n = len(df[(df['sensorVehicle'] == 'GE01') & (df['area_name'] == area_name)])\n",
    "        partition =  ['val'] * int(n/2) + ['test'] * (n - int(n/2))\n",
    "        np.random.shuffle(partition)\n",
    "        df.loc[(df['sensorVehicle'] == 'GE01') & (df['area_name'] == area_name), 'train_val_test'] = partition        \n",
    "    print('Number of images left to assign:', \n",
    "          len(df[df['train_val_test'].isnull()]))\n",
    "    \n",
    "    # WV02:\n",
    "    \n",
    "    print('Assigning very cloudy WV02 images to training set')\n",
    "    # Assign images with cloud ratio higher than threshold to training set\n",
    "    # In other words: Remove very cloudy images from validation and test set\n",
    "    df.loc[df['cloud_ratio'] > cloud_ratio_treshold, 'train_val_test'] = 'train'\n",
    "    print('Number of images left to assign:', \n",
    "          len(df[df['train_val_test'].isnull()]))\n",
    "    \n",
    "    print('Assigning very small WV02 images to training set')\n",
    "    # We want to make sure that val and test sets are representative and not dominated by\n",
    "    # small images that only cover parts of the overall image area\n",
    "    df.loc[df['area_ratio'] < area_ratio_treshold, 'train_val_test'] = 'train'\n",
    "    print('Number of images left to assign:', \n",
    "          len(df[df['train_val_test'].isnull()]))\n",
    "\n",
    "    print('Randomly assigning remaining WV02 images to val or test sets')\n",
    "    for area_name in df['area_name'].unique():\n",
    "        selection = (df['sensorVehicle'] == 'WV02') & (df['train_val_test'].isnull()) & (df['area_name'] == area_name)\n",
    "        n = len(df[selection])\n",
    "        n_val = int(n*train_val_test_split[1])\n",
    "        n_test = int(n*train_val_test_split[2])\n",
    "        n_train = n - (n_val + n_test)\n",
    "        partition =  ['val'] * n_val + ['test'] * n_test + ['train'] * n_train\n",
    "        np.random.shuffle(partition)\n",
    "        df.loc[selection, 'train_val_test'] = partition\n",
    "\n",
    "    print('Number of images left to assign:', \n",
    "          len(df[df['train_val_test'].isnull()]))\n",
    "    print('Finished')\n",
    "    return df\n",
    "    \n",
    "    \n",
    "meta = train_val_test_split(meta, \n",
    "                            area_ratio_treshold = 0.5, \n",
    "                            cloud_ratio_treshold = 1, \n",
    "                            train_val_test_split = [0.5, 0.25, 0.25],\n",
    "                            seed = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['train_val_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms multispectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_factors = ['pixelWidth', \n",
    "                'pixelHeight', \n",
    "                'n_bands',\n",
    "                'offNadirAngle', \n",
    "                'sunAzimuth', \n",
    "                'sunElevation']\n",
    "hist_ms = img_metadata_ms[hist_factors].hist(figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_pan = img_metadata_pan[hist_factors].hist(figsize=(15,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contingency table Sensor x Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.crosstab(img_metadata_pan['area_name'], \n",
    "                    img_metadata_pan['sensorVehicle'], \n",
    "                    margins=True)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clouds?\n",
    "*TODO: Get a measure of clod coverage in every specific image. Either automatically based on available algorithms or manually since the number of images are limited.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate actual area covered by each image\n",
    "*TODO: Many images do not cover the whole area of interest. By using the parsed metadata dataframe and shape geometry supplied with every image it is possible to calculate the actual area. This number may nuance distribution of images across areas, sensors and clouds.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly select two images for early trials\n",
    "\n",
    "Before deciding on final train/validation/test split we randomly select two images from Toulon taken by the WorldView02 (WV02) sensor. These two images will in the future be inclued in the training partition. We do this in order to get started with early trials without compromising the validity of test results by experimenting on images that in the future will be used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toulon_wv02_pan = img_metadata_pan[(img_metadata_pan['sensorVehicle'] == 'WV02')\n",
    "                                   & (img_metadata_pan['area_name'] == 'Toulon')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "img_names = sorted(toulon_wv02_pan.index.values)\n",
    "np.random.shuffle(img_names)\n",
    "images_for_early_trials = img_names[:2]\n",
    "images_for_early_trials"
   ]
  }
 ],
 "metadata": {
  "keep_output": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
