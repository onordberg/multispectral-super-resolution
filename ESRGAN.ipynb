{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESRGAN on satellite data\n",
    "\n",
    "https://arxiv.org/pdf/1809.00219.pdf\n",
    "\n",
    "https://paperswithcode.com/paper/esrgan-enhanced-super-resolution-generative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "import geopandas\n",
    "import pickle\n",
    "import functools\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Conv2D, LeakyReLU, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Check GPUs:\",\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            # Prevent TensorFlow from allocating all memory of all GPUs:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to location where individual satellite images are located\n",
    "DATA_PATH = 'data/toulon-laspezia' \n",
    "\n",
    "# Paths to the tiled imagery\n",
    "DATA_PATH_TILES = 'data/toulon-laspezia-tiles'\n",
    "DATA_PATH_TILES_TRAIN = str(DATA_PATH_TILES + '/train')\n",
    "DATA_PATH_TILES_VAL = str(DATA_PATH_TILES + '/val')\n",
    "DATA_PATH_TILES_TEST = str(DATA_PATH_TILES + '/test')\n",
    "\n",
    "# Loading the metadata geopandas df produced when generating tiles to disk\n",
    "with open(str(DATA_PATH_TILES + '/metadata_tile_allocation.pickle'), 'rb') as file:\n",
    "    meta = pickle.load(file)\n",
    "    \n",
    "N_IMAGES = len(meta.index)\n",
    "N_IMAGES_TRAIN = meta['train_val_test'].value_counts()['train']\n",
    "N_IMAGES_VAL = meta['train_val_test'].value_counts()['val']\n",
    "N_IMAGES_TEST = meta['train_val_test'].value_counts()['test']\n",
    "print('Number of satellite images - train:', N_IMAGES_TRAIN, \n",
    "      ', val:', N_IMAGES_VAL, ', test:', N_IMAGES_TEST)\n",
    "\n",
    "N_TILES_TRAIN = meta.loc[meta['train_val_test'] == 'train', 'n_tiles'].sum()\n",
    "N_TILES_VAL = meta.loc[meta['train_val_test'] == 'val', 'n_tiles'].sum()\n",
    "N_TILES_TEST = meta.loc[meta['train_val_test'] == 'test', 'n_tiles'].sum()\n",
    "print('Number of satellite image tiles - train:', N_TILES_TRAIN, \n",
    "      ', val:', N_TILES_VAL, ', test:', N_TILES_TEST)\n",
    "\n",
    "PAN_WIDTH, PAN_HEIGHT = (384, 384)\n",
    "\n",
    "SR_FACTOR = 4\n",
    "MS_WIDTH, MS_HEIGHT = (int(PAN_WIDTH/SR_FACTOR), int(PAN_HEIGHT/SR_FACTOR))\n",
    "\n",
    "# Should be derived automatically, but added here as a quick fix\n",
    "PAN_BANDS = 1\n",
    "MS_BANDS = 8\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "WV02_BANDS = meta.loc[meta['sensorVehicle'] == 'WV02', ['ms_band0', 'ms_band1', \n",
    "                                                        'ms_band2', 'ms_band3', \n",
    "                                                        'ms_band4', 'ms_band5',\n",
    "                                                        'ms_band6', 'ms_band7',]].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow tile generator from disk\n",
    "\n",
    "Using `tf.data` API to construct a `Dataset` generator reading and preprocessing tiles from disk.\n",
    "\n",
    "Best practices from https://www.tensorflow.org/guide/data, including multithreading, prefetching, shuffling, batching and caching.\n",
    "\n",
    "`rasterio` is used to read geotiffs. the `decode_geotiff()` function is run inside a `tf.py_function()` wrapper ensuring that this function is also run in the computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_geotiff(image_path):\n",
    "    image_path = pathlib.Path(image_path.numpy().decode())\n",
    "    with rasterio.open(image_path) as src:\n",
    "        img = src.read()\n",
    "    img = rasterio.plot.reshape_as_image(img) # from channels first to channels last\n",
    "    return img\n",
    "\n",
    "def preprocess_images(img, ms_or_pan):\n",
    "    if ms_or_pan == 'ms':\n",
    "        h, w = MS_HEIGHT, MS_WIDTH\n",
    "    elif ms_or_pan == 'pan':\n",
    "        h, w = PAN_HEIGHT, PAN_WIDTH\n",
    "        \n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.reshape(img, [h, w, -1]) # To avoid issue with extra dimension\n",
    "    return img\n",
    "\n",
    "def upsample_images(ms_img, pan_img):\n",
    "    ms_img = tf.ensure_shape(ms_img, [MS_HEIGHT, MS_WIDTH, MS_BANDS])\n",
    "    ms_img = tf.image.resize(ms_img, [PAN_HEIGHT, PAN_WIDTH])\n",
    "    return ms_img, pan_img\n",
    "\n",
    "def process_path(ms_tile_path):\n",
    "    img_string_UID = tf.strings.split(ms_tile_path, os.sep)[-3]\n",
    "    tile_UID = tf.strings.split(tf.strings.split(ms_tile_path, os.sep)[-1], '.')[0]\n",
    "    \n",
    "    ms_img = tf.py_function(decode_geotiff, [ms_tile_path], [tf.int16])\n",
    "    pan_tile_path = tf.strings.regex_replace(ms_tile_path, '\\\\\\\\ms\\\\\\\\', '\\\\\\\\pan\\\\\\\\')\n",
    "    pan_img = tf.py_function(decode_geotiff, [pan_tile_path], [tf.int16])\n",
    "    \n",
    "    ms_img = preprocess_images(ms_img, 'ms')\n",
    "    pan_img = preprocess_images(pan_img, 'pan')\n",
    "    \n",
    "    return ms_img, pan_img\n",
    "\n",
    "# https://www.tensorflow.org/tutorials/load_data/images\n",
    "def prepare_for_training(ds, batch_size, cache=True, shuffle_buffer_size=100):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    # Repeat forever\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(batch_size)\n",
    "    \n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_from_tif_tiles(tiles_path, batch_size, upsampling = False, \n",
    "                           cache = True, shuffle_buffer_size = 1000):\n",
    "    \n",
    "    ds = tf.data.Dataset.list_files(str(pathlib.Path(tiles_path)/'*/ms*.tif'))\n",
    "    ds = ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    # upsampling through bicubic convolution before SR is required for SRCNN\n",
    "    if upsampling:\n",
    "        ds = ds.map(upsample_images, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    ds = prepare_for_training(ds, batch_size, cache, shuffle_buffer_size)\n",
    "    return ds\n",
    "\n",
    "# SRCNN needs upsampling!\n",
    "ds_train = dataset_from_tif_tiles(DATA_PATH_TILES_TRAIN, BATCH_SIZE, \n",
    "                                  upsampling = False, shuffle_buffer_size = N_TILES_TRAIN)\n",
    "ds_val = dataset_from_tif_tiles(DATA_PATH_TILES_VAL, BATCH_SIZE, \n",
    "                                upsampling = False, shuffle_buffer_size = N_TILES_VAL)\n",
    "ds_test = dataset_from_tif_tiles(DATA_PATH_TILES_TEST, BATCH_SIZE, \n",
    "                                 upsampling = False, shuffle_buffer_size = N_TILES_TEST)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def show_batch(image_batch):\n",
    "    ms = image_batch[0].numpy()\n",
    "    pan = image_batch[1].numpy()\n",
    "    print('ms batch shape', ms.shape)\n",
    "    print('pan batch shape', pan.shape)\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    for i in range(8):\n",
    "        i = i * 2\n",
    "        ax_ms = plt.subplot(4,4,i+1, label = 'ms')\n",
    "        \n",
    "        ms_image = ms[i,:,:,2] # Just showing channel 2 as grayscale\n",
    "        pan_image = pan[i,:,:,0]\n",
    "\n",
    "        #plt.imshow(ms_image)\n",
    "        ax_ms.imshow(ms_image, cmap = 'gray')\n",
    "        \n",
    "        ax_pan = plt.subplot(4,4,i+2, label = 'pan')\n",
    "\n",
    "        ax_pan.imshow(pan_image, cmap = 'gray')\n",
    "        \n",
    "show_batch(next(iter(ds_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics and bicubic upsampling\n",
    "\n",
    "Bicubic upsampling both as a function and a fixed (untrainable) Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(img1, img2):\n",
    "    return tf.image.psnr(img1, img2, max_val=1.0)\n",
    "\n",
    "def ssim(img1, img2):\n",
    "    return tf.image.ssim(img1, img2, max_val=1.0)\n",
    "\n",
    "def psnr_np(img1, img2):\n",
    "    img1 = np.expand_dims(img1, -1)\n",
    "    img2 = np.expand_dims(img2, -1)\n",
    "    return tf.image.psnr(img1, img2, max_val=1.0)\n",
    "\n",
    "def ssim_np(img1, img2):\n",
    "    img1 = tf.convert_to_tensor(np.expand_dims(img1, -1), dtype = tf.float32)\n",
    "    img2 = tf.convert_to_tensor(np.expand_dims(img2, -1), dtype = tf.float32)\n",
    "    return tf.image.ssim(img1, img2, max_val=1.0)\n",
    "\n",
    "def bicubic_upsample(imgs, upsample_factor):\n",
    "    #print(imgs.shape)\n",
    "    imgs = tf.expand_dims(imgs, -1)\n",
    "    imgs = tf.image.resize(imgs, [imgs.shape[1]*upsample_factor, imgs.shape[2]*upsample_factor], \n",
    "                           method=tf.image.ResizeMethod.BICUBIC, preserve_aspect_ratio=False,\n",
    "                           antialias=False, name=None)\n",
    "    #print(imgs.shape)\n",
    "    imgs = tf.squeeze(imgs)\n",
    "    return imgs\n",
    "\n",
    "def bicubic_model(size, upsample_factor, channels_in, channels_out):\n",
    "    inputs = Input([size, size, channels_in], name='input_image')\n",
    "    x = Lambda(lambda x:\n",
    "               tf.expand_dims(tf.math.reduce_mean(x, axis = -1), axis = -1))(inputs)\n",
    "    x = Lambda(lambda x: \n",
    "               tf.image.resize(x, [size*upsample_factor, size*upsample_factor], \n",
    "               method=tf.image.ResizeMethod.BICUBIC, preserve_aspect_ratio=False,\n",
    "               antialias=False, name=None))(x)\n",
    "    return Model(inputs, x)\n",
    "\n",
    "bicubic = bicubic_model(MS_HEIGHT, SR_FACTOR, MS_BANDS, PAN_BANDS)\n",
    "bicubic.compile(loss='mean_absolute_error', metrics = [psnr, ssim])\n",
    "bicubic.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Residual-in-Residual Dense Block (RRDB) model\n",
    "\n",
    "Code currently heavily based on https://github.com/peteryuX/esrgan-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _regularizer(weights_decay=5e-4):\n",
    "    return tf.keras.regularizers.l2(weights_decay)\n",
    "\n",
    "\n",
    "def _kernel_init(scale=1.0, seed=None):\n",
    "    \"\"\"He normal initializer with scale.\"\"\"\n",
    "    scale = 2. * scale\n",
    "    return tf.keras.initializers.VarianceScaling(\n",
    "        scale=scale, mode='fan_in', distribution=\"truncated_normal\", seed=seed)\n",
    "\n",
    "\n",
    "class BatchNormalization(tf.keras.layers.BatchNormalization):\n",
    "    \"\"\"Make trainable=False freeze BN for real (the og version is sad).\n",
    "       ref: https://github.com/zzh8829/yolov3-tf2\n",
    "    \"\"\"\n",
    "    def __init__(self, axis=-1, momentum=0.9, epsilon=1e-5, center=True,\n",
    "                 scale=True, name=None, **kwargs):\n",
    "        super(BatchNormalization, self).__init__(\n",
    "            axis=axis, momentum=momentum, epsilon=epsilon, center=center,\n",
    "            scale=scale, name=name, **kwargs)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        if training is None:\n",
    "            training = tf.constant(False)\n",
    "        training = tf.logical_and(training, self.trainable)\n",
    "        return super().call(x, training)\n",
    "\n",
    "\n",
    "class ResDenseBlock_5C(tf.keras.layers.Layer):\n",
    "    \"\"\"Residual Dense Block\"\"\"\n",
    "    def __init__(self, nf=64, gc=32, res_beta=0.2, wd=0., name='RDB5C',\n",
    "                 **kwargs):\n",
    "        super(ResDenseBlock_5C, self).__init__(name=name, **kwargs)\n",
    "        # gc: growth channel, i.e. intermediate channels\n",
    "        self.res_beta = res_beta\n",
    "        lrelu_f = functools.partial(LeakyReLU, alpha=0.2)\n",
    "        _Conv2DLayer = functools.partial(\n",
    "            Conv2D, kernel_size=3, padding='same',\n",
    "            kernel_initializer=_kernel_init(0.1), bias_initializer='zeros',\n",
    "            kernel_regularizer=_regularizer(wd))\n",
    "        self.conv1 = _Conv2DLayer(filters=gc, activation=lrelu_f())\n",
    "        self.conv2 = _Conv2DLayer(filters=gc, activation=lrelu_f())\n",
    "        self.conv3 = _Conv2DLayer(filters=gc, activation=lrelu_f())\n",
    "        self.conv4 = _Conv2DLayer(filters=gc, activation=lrelu_f())\n",
    "        self.conv5 = _Conv2DLayer(filters=nf, activation=lrelu_f())\n",
    "\n",
    "    def call(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(tf.concat([x, x1], 3))\n",
    "        x3 = self.conv3(tf.concat([x, x1, x2], 3))\n",
    "        x4 = self.conv4(tf.concat([x, x1, x2, x3], 3))\n",
    "        x5 = self.conv5(tf.concat([x, x1, x2, x3, x4], 3))\n",
    "        return x5 * self.res_beta + x\n",
    "\n",
    "\n",
    "class ResInResDenseBlock(tf.keras.layers.Layer):\n",
    "    \"\"\"Residual in Residual Dense Block\"\"\"\n",
    "    def __init__(self, nf=64, gc=32, res_beta=0.2, wd=0., name='RRDB',\n",
    "                 **kwargs):\n",
    "        super(ResInResDenseBlock, self).__init__(name=name, **kwargs)\n",
    "        self.res_beta = res_beta\n",
    "        self.rdb_1 = ResDenseBlock_5C(nf, gc, res_beta=res_beta, wd=wd)\n",
    "        self.rdb_2 = ResDenseBlock_5C(nf, gc, res_beta=res_beta, wd=wd)\n",
    "        self.rdb_3 = ResDenseBlock_5C(nf, gc, res_beta=res_beta, wd=wd)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.rdb_1(x)\n",
    "        out = self.rdb_2(out)\n",
    "        out = self.rdb_3(out)\n",
    "        return out * self.res_beta + x\n",
    "\n",
    "\n",
    "def RRDB_Model(size, channels_in, channels_out, cfg_net, gc=32, wd=0., name='RRDB_model'):\n",
    "    \"\"\"Residual-in-Residual Dense Block based Model \"\"\"\n",
    "    nf, nb = cfg_net['nf'], cfg_net['nb']\n",
    "    lrelu_f = functools.partial(LeakyReLU, alpha=0.2)\n",
    "    rrdb_f = functools.partial(ResInResDenseBlock, nf=nf, gc=gc, wd=wd)\n",
    "    conv_f = functools.partial(Conv2D, kernel_size=3, padding='same',\n",
    "                               bias_initializer='zeros',\n",
    "                               kernel_initializer=_kernel_init(),\n",
    "                               kernel_regularizer=_regularizer(wd))\n",
    "    rrdb_truck_f = tf.keras.Sequential(\n",
    "        [rrdb_f(name=\"RRDB_{}\".format(i)) for i in range(nb)],\n",
    "        name='RRDB_trunk')\n",
    "\n",
    "    # extraction\n",
    "    x = inputs = Input([size, size, channels_in], name='input_image')\n",
    "    fea = conv_f(filters=nf, name='conv_first')(x)\n",
    "    fea_rrdb = rrdb_truck_f(fea)\n",
    "    trunck = conv_f(filters=nf, name='conv_trunk')(fea_rrdb)\n",
    "    fea = fea + trunck\n",
    "\n",
    "    # upsampling\n",
    "    size_fea_h = tf.shape(fea)[1] if size is None else size\n",
    "    size_fea_w = tf.shape(fea)[2] if size is None else size\n",
    "    fea_resize = tf.image.resize(fea, [size_fea_h * 2, size_fea_w * 2],\n",
    "                                 method='nearest', name='upsample_nn_1')\n",
    "    fea = conv_f(filters=nf, activation=lrelu_f(), name='upconv_1')(fea_resize)\n",
    "    fea_resize = tf.image.resize(fea, [size_fea_h * 4, size_fea_w * 4],\n",
    "                                 method='nearest', name='upsample_nn_2')\n",
    "    fea = conv_f(filters=nf, activation=lrelu_f(), name='upconv_2')(fea_resize)\n",
    "    fea = conv_f(filters=nf, activation=lrelu_f(), name='conv_hr')(fea)\n",
    "    out = conv_f(filters=channels_out, name='conv_last')(fea)\n",
    "\n",
    "    return Model(inputs, out, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rrdb_model(optimizer = Adam(lr=0.000010), loss = 'mean_absolute_error', \n",
    "                     n_filters = 64, n_blocks = 23, metrics = [psnr, ssim]):\n",
    "    \n",
    "    cfg_net = {'nf': n_filters, 'nb': n_blocks}\n",
    "    rrdb = RRDB_Model(MS_HEIGHT, MS_BANDS, 1, cfg_net)\n",
    "    rrdb.compile(optimizer=optimizer, loss=loss, metrics = metrics)\n",
    "    return rrdb\n",
    "\n",
    "pretrain_model =  build_rrdb_model(optimizer = Adam(lr=0.000010), loss = 'mean_absolute_error', \n",
    "                                   n_filters = 64, n_blocks = 23, metrics = [psnr, ssim])\n",
    "pretrain_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining the model with PSNR loss\n",
    "\n",
    "This is done in the ESRGAN paper and the rationale behind is that you want a reasonable starting point for your GAN training later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = pathlib.Path('logs/fit/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = 'models/esrgan-sat-m1-2-{epoch:02d}-{val_loss:.6f}.h5', \n",
    "    monitor = \"val_loss\",\n",
    "    save_best_only = True,\n",
    "    save_weights_only = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_model.load_weights('models/esrgan-psnr-final.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "EPOCHS = 200\n",
    "\n",
    "history = pretrain_model.fit(ds_train, \n",
    "                             epochs = EPOCHS, \n",
    "                             validation_data = ds_val,\n",
    "                             steps_per_epoch = 200, \n",
    "                             validation_steps = 200, \n",
    "                             callbacks=[tensorboard_callback, checkpoint_callback]\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrain_model.save_weights(\"models/esrgan-psnr-final.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation after pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stretch(image, individual_bands = True):\n",
    "    image_out = np.empty(image.shape)\n",
    "    if individual_bands:\n",
    "        for i in range(image.shape[2]):\n",
    "            image_out[:,:,i] = (image[:,:,i] - np.min(image[:,:,i])) / (np.max(image[:,:,i]) - np.min(image[:,:,i]))\n",
    "    else:\n",
    "        image_out = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "    return image_out\n",
    "\n",
    "def pansharpen(ms, pan, sensor = 'WV02', method = 'brovey', fourth_band = 'nir', \n",
    "               w = [0.2]*5, stretch_output = True):\n",
    "    ms = ms[:,:,:]\n",
    "    pan = pan[:,:]\n",
    "    \n",
    "    scale = int(pan.shape[0]/ms.shape[0])\n",
    "\n",
    "    ms_ups = tf.image.resize(ms, [ms.shape[0]*scale, ms.shape[1]*scale], \n",
    "                         method=tf.image.ResizeMethod.BICUBIC, preserve_aspect_ratio=False,\n",
    "                         antialias=False, name=None)\n",
    "\n",
    "    # Convert to ndarray if tensor\n",
    "    if isinstance(pan, tf.python.framework.ops.EagerTensor):\n",
    "        pan = pan.numpy()\n",
    "    if isinstance(ms_ups, tf.python.framework.ops.EagerTensor):\n",
    "        ms_ups = ms_ups.numpy()\n",
    "    \n",
    "    if sensor == 'WV02':\n",
    "        r = ms_ups[:,:,4]\n",
    "        g = ms_ups[:,:,2]\n",
    "        b = ms_ups[:,:,1]\n",
    "        if fourth_band == 'red_edge':\n",
    "            i = ms_ups[:,:,5]\n",
    "        elif fourth_band == 'nir':\n",
    "            i = ms_ups[:,:,6]\n",
    "        elif fourth_band == 'nir2':\n",
    "            i = ms_ups[:,:,7]\n",
    "        \n",
    "    if method == 'brovey':\n",
    "        dnf = (pan - w[3]*i)/(w[0]*r + w[1]*g + w[2]*b)\n",
    "        r = np.expand_dims(r * dnf, -1)\n",
    "        g = np.expand_dims(g * dnf, -1)\n",
    "        b = np.expand_dims(b * dnf, -1)\n",
    "        i = np.expand_dims(i * dnf, -1)\n",
    "        img_out = np.concatenate([r, g, b], axis = 2)\n",
    "        #print(img_out.shape)\n",
    "    \n",
    "    if stretch_output:\n",
    "        img_out = stretch(img_out)\n",
    "        \n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms_to_rgb(ms, sensor = 'WV02'):\n",
    "    if sensor == 'WV02':\n",
    "        rgb = [np.expand_dims(ms[:,:,4], -1), \n",
    "               np.expand_dims(ms[:,:,2], -1), \n",
    "               np.expand_dims(ms[:,:,1], -1)]\n",
    "    elif sensor == 'GE01':\n",
    "        rgb = [np.expand_dims(ms[:,:,2], -1), \n",
    "               np.expand_dims(ms[:,:,1], -1), \n",
    "               np.expand_dims(ms[:,:,0], -1)]\n",
    "    elif sensor == 'WV03_VNIR':\n",
    "        rgb = [np.expand_dims(ms[:,:,1], -1), \n",
    "               np.expand_dims(ms[:,:,2], -1), \n",
    "               np.expand_dims(ms[:,:,3], -1)]\n",
    "    else:\n",
    "        raise ValueError('Only WV02, GE01 and WV03_VNIR band configurations implemented') \n",
    "    \n",
    "    rgb = np.concatenate(rgb, axis = 2)\n",
    "    rgb = stretch(rgb)\n",
    "    return rgb\n",
    "\n",
    "def plot_subplot(ax, img, title, gray = False, metrics = False):\n",
    "    ax.set_title(title)\n",
    "    if gray:\n",
    "        ax.imshow(img, cmap = 'gray')\n",
    "    else:\n",
    "        ax.imshow(img)\n",
    "        \n",
    "    # TODO: Implement metrics in title\n",
    "    #axs[0,1].set_title('MS Bicubic Upsampling ' + \n",
    "    #                   '\\n PSNR: ' + \n",
    "    #                   str(psnr_np(bicubic[i], pan[i]).numpy()) + \n",
    "    #                   '\\n SSIM: ' +\n",
    "    #                   str(ssim_np(bicubic[i], pan[i]).numpy()))\n",
    "    #axs[0,1].imshow(bicubic[i], cmap = cmap)\n",
    "    return ax\n",
    "    \n",
    "def plot_comparison(ds, pretrain_model = False, gan_model = False, bicubic = True, \n",
    "                    rgb = True, pansharp = False, sensor = 'WV02', save_path = False):\n",
    "    imgs, plot, gray, metrics = {}, {}, {}, {}\n",
    "    batch = next(iter(ds)) # Batch size = 1\n",
    "    \n",
    "    imgs['ms'] = batch[0][0].numpy()\n",
    "    imgs['ms_mean'] = tf.math.reduce_mean(imgs['ms'], axis = -1).numpy()\n",
    "    plot['ms_mean'], gray['ms_mean'] = True, True\n",
    "    \n",
    "    if rgb:\n",
    "        imgs['ms_rgb'] = ms_to_rgb(imgs['ms'], sensor = 'WV02')\n",
    "        plot['ms_rgb'], gray['ms_rgb'] = True, False\n",
    "    \n",
    "    if bicubic:\n",
    "        imgs['bicubic'] = tf.image.resize(imgs['ms'], \n",
    "                                          [imgs['ms'].shape[0]*SR_FACTOR, imgs['ms'].shape[1]*SR_FACTOR], \n",
    "                                          method=tf.image.ResizeMethod.BICUBIC).numpy()\n",
    "\n",
    "        imgs['bicubic_mean'] = tf.math.reduce_mean(imgs['bicubic'], axis = -1).numpy()\n",
    "        plot['bicubic_mean'], gray['bicubic_mean'] = True, True\n",
    "        if rgb:\n",
    "            imgs['bicubic_rgb'] = ms_to_rgb(imgs['bicubic'], sensor = 'WV02')\n",
    "            plot['bicubic_rgb'], gray['bicubic_rgb'] = True, False\n",
    "    \n",
    "    if not isinstance(pretrain_model, bool):\n",
    "        imgs['sr_pretrain'] = pretrain_model.predict(batch)[0,:,:,0]\n",
    "        plot['sr_pretrain'], gray['sr_pretrain'] = True, True\n",
    "        \n",
    "    if not isinstance(gan_model, bool):\n",
    "        imgs['sr_gan'] = gan_model.predict(batch)[0,:,:,0]\n",
    "        plot['sr_gan'] = True\n",
    "        gray['sr_gan'] = True\n",
    "        \n",
    "    imgs['pan'] = batch[1].numpy()[0,:,:,0]\n",
    "    plot['pan'], gray['pan'] = True, True\n",
    "    \n",
    "    if pansharp:\n",
    "        if not isinstance(pretrain_model, bool):\n",
    "            imgs['sr_pretrain_pansharp'] = pansharpen(imgs['ms'], imgs['sr_pretrain'], sensor = 'WV02', \n",
    "                                                      method = 'brovey', fourth_band = 'nir', \n",
    "                                                      w = [0.2]*5, stretch_output = True)\n",
    "            plot['sr_pretrain_pansharp'], gray['sr_pretrain_pansharp'] = True, False\n",
    "\n",
    "        if not isinstance(gan_model, bool):\n",
    "            imgs['sr_gan_pansharp'] = pansharpen(imgs['ms'], imgs['sr_gan'], sensor = 'WV02', \n",
    "                                                      method = 'brovey', fourth_band = 'nir', \n",
    "                                                      w = [0.2]*5, stretch_output = True)\n",
    "            plot['sr_gan_pansharp'], gray['sr_gan_pansharp'] = True, False\n",
    "\n",
    "        imgs['real_pansharp'] = pansharpen(imgs['ms'], imgs['pan'], sensor = 'WV02', \n",
    "                                                  method = 'brovey', fourth_band = 'nir', \n",
    "                                                  w = [0.2]*5, stretch_output = True)\n",
    "        plot['real_pansharp'], gray['real_pansharp'] = True, False\n",
    "    \n",
    "    n_subplots = sum(plot.values())\n",
    "    print('Plotting', n_subplots, 'subplots')\n",
    "    for img_name in plot.keys():\n",
    "        print(img_name, imgs[img_name].shape)\n",
    "    n_cols = 3\n",
    "    n_rows = math.ceil(n_subplots/n_cols)\n",
    "\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, constrained_layout = True, \n",
    "                            figsize = (n_cols*10, n_rows*10))\n",
    "    fig.suptitle('Satellite image tiles - Comparisons between multispectral, panchromatic and super-resolution images')\n",
    "    fig.patch.set_facecolor('white')\n",
    "    subplot_keys = list(plot.keys())\n",
    "    k = 0\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_cols):\n",
    "            img_name = subplot_keys[k]\n",
    "            plot_subplot(axs[i,j], imgs[img_name], img_name, gray[img_name])\n",
    "            k += 1\n",
    "            if k >= len(subplot_keys):\n",
    "                break\n",
    "                \n",
    "    if not isinstance(save_path, bool):\n",
    "        fig.savefig(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(ds_val, pretrain_model, gan_model = False, rgb = True, pansharp = True, sensor = 'WV02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(ds_val))\n",
    "sr = rrdb.predict(batch)\n",
    "p = pansharpen(batch[0], batch[1], sensor = 'WV02', method = 'brovey', \n",
    "                          fourth_band = 'nir', w = [0.2]*5)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(p)\n",
    "plt.show()\n",
    "\n",
    "p_sr = pansharpen(batch[0], sr, sensor = 'WV02', method = 'brovey', \n",
    "                          fourth_band = 'nir', w = [0.2]*5)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(p_sr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    #plot_comparisons(rrdb, ds_train, n_comparisons = 1)\n",
    "    plot_comparisons(rrdb, ds_val, n_comparisons = 1)\n",
    "    #plot_comparisons(rrdb, ds_test, n_comparisons = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bicubic.evaluate(ds_val, steps = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrdb.evaluate(ds_val, steps = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN training\n",
    "\n",
    "Code currently heavily based on https://github.com/peteryuX/esrgan-tf2. Lacks a lot when it comes to monitoring (Tensorboard).\n",
    "\n",
    "Currently uses perceptual loss of an intermediate layer in a VGG19 model trained on ImageNet. This is probably suboptimal for the satellite imagery domain. Considering using a BigEarthNet VGG19 model instead http://bigearth.net/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import preprocess_input, VGG19\n",
    "\n",
    "vgg = VGG19(input_shape=(None, None, 3), include_top=False)\n",
    "fea_extrator = tf.keras.Model(vgg.input, vgg.layers[20].output)\n",
    "\n",
    "def PixelLoss(criterion='l1'):\n",
    "    \"\"\"pixel loss\"\"\"\n",
    "    if criterion == 'l1':\n",
    "        return tf.keras.losses.MeanAbsoluteError()\n",
    "    elif criterion == 'l2':\n",
    "        return tf.keras.losses.MeanSquaredError()\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            'Loss type {} is not recognized.'.format(criterion))\n",
    "\n",
    "\n",
    "def ContentLoss(criterion='l1', output_layer=54, before_act=True):\n",
    "    \"\"\"content loss\"\"\"\n",
    "    if criterion == 'l1':\n",
    "        loss_func = tf.keras.losses.MeanAbsoluteError()\n",
    "    elif criterion == 'l2':\n",
    "        loss_func = tf.keras.losses.MeanSquaredError()\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            'Loss type {} is not recognized.'.format(criterion))\n",
    "    #vgg = VGG19(input_shape=(None, None, 3), include_top=False)\n",
    "\n",
    "    if output_layer == 22:  # Low level feature\n",
    "        pick_layer = 5\n",
    "    elif output_layer == 54:  # Hight level feature\n",
    "        pick_layer = 20\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            'VGG output layer {} is not recognized.'.format(criterion))\n",
    "\n",
    "    if before_act:\n",
    "        vgg.layers[pick_layer].activation = None\n",
    "\n",
    "    #fea_extrator = tf.keras.Model(vgg.input, vgg.layers[pick_layer].output)\n",
    "\n",
    "    @tf.function\n",
    "    def content_loss(hr, sr):\n",
    "        print(sr.shape, hr.shape)\n",
    "        sr_rgb = tf.image.grayscale_to_rgb(sr)\n",
    "        hr_rgb = tf.image.grayscale_to_rgb(hr)\n",
    "        print(sr_rgb.shape, hr_rgb.shape)\n",
    "        # the input scale range is [0, 1] (vgg is [0, 255]).\n",
    "        # 12.75 is rescale factor for vgg featuremaps.\n",
    "        preprocess_sr = preprocess_input(sr_rgb * 255.) / 12.75\n",
    "        preprocess_hr = preprocess_input(hr_rgb * 255.) / 12.75\n",
    "        print(preprocess_sr.shape, preprocess_hr.shape)\n",
    "        sr_features = fea_extrator(preprocess_sr)\n",
    "        hr_features = fea_extrator(preprocess_hr)\n",
    "\n",
    "        return loss_func(hr_features, sr_features)\n",
    "\n",
    "    return content_loss\n",
    "\n",
    "\n",
    "def DiscriminatorLoss(gan_type='ragan'):\n",
    "    \"\"\"discriminator loss\"\"\"\n",
    "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    sigma = tf.sigmoid\n",
    "\n",
    "    def discriminator_loss_ragan(hr, sr):\n",
    "        return 0.5 * (\n",
    "            cross_entropy(tf.ones_like(hr), sigma(hr - tf.reduce_mean(sr))) +\n",
    "            cross_entropy(tf.zeros_like(sr), sigma(sr - tf.reduce_mean(hr))))\n",
    "\n",
    "    def discriminator_loss(hr, sr):\n",
    "        real_loss = cross_entropy(tf.ones_like(hr), sigma(hr))\n",
    "        fake_loss = cross_entropy(tf.zeros_like(sr), sigma(sr))\n",
    "        return real_loss + fake_loss\n",
    "\n",
    "    if gan_type == 'ragan':\n",
    "        return discriminator_loss_ragan\n",
    "    elif gan_type == 'gan':\n",
    "        return discriminator_loss\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            'Discriminator loss type {} is not recognized.'.format(gan_type))\n",
    "\n",
    "\n",
    "def GeneratorLoss(gan_type='ragan'):\n",
    "    \"\"\"generator loss\"\"\"\n",
    "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    sigma = tf.sigmoid\n",
    "\n",
    "    def generator_loss_ragan(hr, sr):\n",
    "        return 0.5 * (\n",
    "            cross_entropy(tf.ones_like(sr), sigma(sr - tf.reduce_mean(hr))) +\n",
    "            cross_entropy(tf.zeros_like(hr), sigma(hr - tf.reduce_mean(sr))))\n",
    "\n",
    "    def generator_loss(hr, sr):\n",
    "        return cross_entropy(tf.ones_like(sr), sigma(sr))\n",
    "\n",
    "    if gan_type == 'ragan':\n",
    "        return generator_loss_ragan\n",
    "    elif gan_type == 'gan':\n",
    "        return generator_loss\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            'Generator loss type {} is not recognized.'.format(gan_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DiscriminatorVGG(size, channels, nf=64, wd=0.,\n",
    "                     name='Discriminator_VGG'):\n",
    "    \"\"\"Discriminator VGG\"\"\"\n",
    "    lrelu_f = functools.partial(LeakyReLU, alpha=0.2)\n",
    "    conv_k3s1_f = functools.partial(Conv2D,\n",
    "                                    kernel_size=3, strides=1, padding='same',\n",
    "                                    kernel_initializer=_kernel_init(),\n",
    "                                    kernel_regularizer=_regularizer(wd))\n",
    "    conv_k4s2_f = functools.partial(Conv2D,\n",
    "                                    kernel_size=4, strides=2, padding='same',\n",
    "                                    kernel_initializer=_kernel_init(),\n",
    "                                    kernel_regularizer=_regularizer(wd))\n",
    "    dese_f = functools.partial(Dense, kernel_regularizer=_regularizer(wd))\n",
    "\n",
    "    x = inputs = Input(shape=(size, size, channels))\n",
    "\n",
    "    x = conv_k3s1_f(filters=nf, name='conv0_0')(x)\n",
    "    x = conv_k4s2_f(filters=nf, use_bias=False, name='conv0_1')(x)\n",
    "    x = lrelu_f()(BatchNormalization(name='bn0_1')(x))\n",
    "\n",
    "    x = conv_k3s1_f(filters=nf * 2, use_bias=False, name='conv1_0')(x)\n",
    "    x = lrelu_f()(BatchNormalization(name='bn1_0')(x))\n",
    "    x = conv_k4s2_f(filters=nf * 2, use_bias=False, name='conv1_1')(x)\n",
    "    x = lrelu_f()(BatchNormalization(name='bn1_1')(x))\n",
    "\n",
    "    x = conv_k3s1_f(filters=nf * 4, use_bias=False, name='conv2_0')(x)\n",
    "    x = lrelu_f()(BatchNormalization(name='bn2_0')(x))\n",
    "    x = conv_k4s2_f(filters=nf * 4, use_bias=False, name='conv2_1')(x)\n",
    "    x = lrelu_f()(BatchNormalization(name='bn2_1')(x))\n",
    "\n",
    "    x = conv_k3s1_f(filters=nf * 8, use_bias=False, name='conv3_0')(x)\n",
    "    x = lrelu_f()(BatchNormalization(name='bn3_0')(x))\n",
    "    x = conv_k4s2_f(filters=nf * 8, use_bias=False, name='conv3_1')(x)\n",
    "    x = lrelu_f()(BatchNormalization(name='bn3_1')(x))\n",
    "\n",
    "    x = conv_k3s1_f(filters=nf * 8, use_bias=False, name='conv4_0')(x)\n",
    "    x = lrelu_f()(BatchNormalization(name='bn4_0')(x))\n",
    "    x = conv_k4s2_f(filters=nf * 8, use_bias=False, name='conv4_1')(x)\n",
    "    x = lrelu_f()(BatchNormalization(name='bn4_1')(x))\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = dese_f(units=100, activation=lrelu_f(), name='linear1')(x)\n",
    "    out = dese_f(units=1, name='linear2')(x)\n",
    "\n",
    "    return Model(inputs, out, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual GAN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_model =  build_rrdb_model(n_filters = 64, n_blocks = 23, metrics = [psnr, ssim])\n",
    "#gan_model.summary()\n",
    "\n",
    "# Loading pre-trained weights from pretrain_model\n",
    "gan_model.load_weights('models/esrgan-psnr-final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_esrgan(psnr_model, dataset, steps, learning_rate_G, learning_rate_D):\n",
    "    # define network\n",
    "    generator = psnr_model\n",
    "    #generator.summary(line_length=80)\n",
    "    discriminator = DiscriminatorVGG(PAN_HEIGHT, PAN_BANDS)\n",
    "    #discriminator.summary(line_length=80)\n",
    "\n",
    "\n",
    "    # define optimizer\n",
    "    #learning_rate_G = MultiStepLR(cfg['lr_G'], cfg['lr_steps'], cfg['lr_rate'])\n",
    "    #learning_rate_D = MultiStepLR(cfg['lr_D'], cfg['lr_steps'], cfg['lr_rate'])\n",
    "    optimizer_G = tf.keras.optimizers.Adam(learning_rate=learning_rate_G)\n",
    "    optimizer_D = tf.keras.optimizers.Adam(learning_rate=learning_rate_D)\n",
    "\n",
    "    # define losses function\n",
    "    pixel_loss_fn = PixelLoss(criterion='l1')\n",
    "    fea_loss_fn = ContentLoss(criterion='l1')\n",
    "    gen_loss_fn = GeneratorLoss(gan_type='ragan')\n",
    "    dis_loss_fn = DiscriminatorLoss(gan_type='ragan')\n",
    "    \n",
    "    # define training step function\n",
    "    @tf.function\n",
    "    def train_step(lr, hr):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            sr = generator(lr, training=True)\n",
    "            hr_output = discriminator(hr, training=True)\n",
    "            sr_output = discriminator(sr, training=True)\n",
    "\n",
    "            losses_G = {}\n",
    "            losses_D = {}\n",
    "            losses_G['reg'] = tf.reduce_sum(generator.losses)\n",
    "            losses_D['reg'] = tf.reduce_sum(discriminator.losses)\n",
    "            losses_G['pixel'] = 0.01 * pixel_loss_fn(hr, sr)\n",
    "            losses_G['feature'] = 1.0 * fea_loss_fn(hr, sr)\n",
    "            losses_G['gan'] = 0.005 * gen_loss_fn(hr_output, sr_output)\n",
    "            losses_D['gan'] = dis_loss_fn(hr_output, sr_output)\n",
    "            total_loss_G = tf.add_n([l for l in losses_G.values()])\n",
    "            total_loss_D = tf.add_n([l for l in losses_D.values()])\n",
    "\n",
    "        grads_G = tape.gradient(\n",
    "            total_loss_G, generator.trainable_variables)\n",
    "        grads_D = tape.gradient(\n",
    "            total_loss_D, discriminator.trainable_variables)\n",
    "        optimizer_G.apply_gradients(\n",
    "            zip(grads_G, generator.trainable_variables))\n",
    "        optimizer_D.apply_gradients(\n",
    "            zip(grads_D, discriminator.trainable_variables))\n",
    "\n",
    "        return total_loss_G, total_loss_D, losses_G, losses_D\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    for lr, hr in dataset.take(steps):\n",
    "        total_loss_G, total_loss_D, losses_G, losses_D = train_step(lr, hr)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(i, total_loss_G, total_loss_D)\n",
    "\n",
    "        i += 1\n",
    "        \n",
    "    print(\"\\n [*] training done!\")\n",
    "    \n",
    "#train_esrgan(gan_model, ds_train, 20000, 0.0001, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gan_model.save_weights(\"models/esrgan-gan-final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gan_model.load_weights(\"models/esrgan-gan-final.h5\")\n",
    "gan_model.load_weights(\"models/esrgan-gan-final2-lr-halving3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation after GAN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(ds_val, pretrain_model, gan_model = gan_model, rgb = True, pansharp = True, sensor = 'WV02', \n",
    "                save_path = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save a bunch of comparison plots to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    plot_comparison(ds_val, pretrain_model, gan_model = gan_model, rgb = True, pansharp = True, sensor = 'WV02', \n",
    "                save_path = str('results/comparison-plots/2020-10-07-pretrain-and-gan-' + str(i).zfill(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "keep_output": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
